# GASPhotoAIManager - Merged Codebase for AI Analysis
# Generated: Sun, Nov 30, 2025  4:07:46 PM
# This file is for AI Studio import. Original files are preserved.

//===============================================================================
// FILE: package.json
//===============================================================================
{
  "name": "construction-album-maker",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "lucide-react": "^0.554.0",
    "@google/genai": "^1.30.0"
  },
  "devDependencies": {
    "@types/node": "^22.14.0",
    "@vitejs/plugin-react": "^5.0.0",
    "typescript": "~5.8.2",
    "vite": "^6.2.0"
  }
}

//===============================================================================
// FILE: index.html
//===============================================================================
<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>工事写真帳メーカー - Construction Album Maker</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/exceljs@4.4.0/dist/exceljs.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/FileSaver.js/2.0.5/FileSaver.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/exif-js"></script>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&display=swap');

    body {
      font-family: 'Noto Sans JP', sans-serif;
    }

    /* Screen Styles for the Sheet Preview */
    .sheet-preview {
      width: 210mm;
      min-height: 297mm;
      background: white;
      margin: 0 auto 2rem auto;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
      position: relative;
      box-sizing: border-box;
    }

    /* PDF Generation Mode Overrides */
    /* These styles activate when the 'pdf-mode' class is added to the container during export */
    .pdf-mode .sheet-preview {
      /* Force exact height slightly less than A4 to prevent micro-spillover causing blank pages */
      height: 295mm !important;
      min-height: 295mm !important;
      max-height: 295mm !important;
      width: 210mm !important;

      /* Remove screen-only styling */
      margin: 0 !important;
      box-shadow: none !important;
      border: none !important;

      /* Clip any content that might push boundaries */
      overflow: hidden !important;

      /* Ensure clean breaks */
      page-break-after: always !important;
      page-break-inside: avoid !important;
    }

    /* Prevent the last page from creating an empty page after it */
    .pdf-mode .sheet-preview:last-child {
      page-break-after: avoid !important;
    }

    /* PDF Visibility Helpers:
         Allows switching between 'Input' (Edit) and 'Div' (Print) 
         to ensure text wraps correctly in PDF. 
      */
    .pdf-visible {
      display: none;
    }

    .pdf-mode .pdf-visible {
      display: block !important;
    }

    .pdf-mode .pdf-hidden {
      display: none !important;
    }
  </style>


</head>

<body class="bg-gray-100 text-gray-900 antialiased">
  <div id="root">
    <div style="padding: 20px; font-family: sans-serif;">
      <h1>工事写真帳メーカーを読み込み中...</h1>
      <p>If this message persists, there may be a JavaScript error.</p>
    </div>
  </div>
  <script type="module" src="/index.tsx"></script>
</body>

</html>

//===============================================================================
// FILE: types.ts
//===============================================================================

export interface PhotoMetadata {
  fileName: string;
  originalFile?: File; // Optional because it might be missing after JSON import, but persisted in IDB
  base64: string; // Resized for display/AI
  mimeType: string;
  fileSize?: number; // Used for cache key generation without File object
  lastModified?: number; // Used for cache key generation without File object
}

export type AppMode = 'construction' | 'general';

// 写真管理基準（国土交通省）による正式な写真区分
export type PhotoCategory =
  | "着手前及び完成写真"
  | "施工状況写真"
  | "安全管理写真"
  | "使用材料写真"
  | "品質管理写真"
  | "出来形管理写真"
  | "災害写真"
  | "事故写真"
  | "その他";

export interface AIAnalysisResult {
  fileName: string;
  workType: string; // 工種 (Construction Type) OR Category
  variety?: string; // 種別 (Variety) OR Sub-category
  detail?: string; // 細別 (Detail)
  station: string; // 測点 OR Location/Time
  remarks: string; // 備考 (黒板の記載内容の正規化) OR Title/Key Point
  description: string; // 記事/説明
  hasBoard: boolean; // 黒板有無
  detectedText: string; // OCR text
  editedFields?: string[]; // Track which fields were manually modified by the user

  // Pairing Logic Cache
  sceneId?: string; // Unique ID grouping photos of the same location (Visual or Logical)
  phase?: 'before' | 'after' | 'status' | 'unknown'; // The phase within that scene
  visualAnchors?: string; // NEW: Verbalized description of background landmarks (e.g., "White house left, Pole right")
  reasoning?: string; // NEW: AI's thought process explaining the classification
}

export interface PhotoRecord extends PhotoMetadata {
  analysis?: AIAnalysisResult;
  status: 'pending' | 'processing' | 'done' | 'error';
  date?: number; // Capture timestamp
  fromCache?: boolean; // Indicates if the analysis came from local IndexedDB
}

export interface ProcessingStats {
  total: number;
  processed: number;
  success: number;
  failed: number;
  cached: number; // Count of records retrieved from cache
}

export interface LogEntry {
  timestamp: string;
  message: string;
  type: 'info' | 'success' | 'error' | 'json';
  details?: any; // For JSON objects
}


//===============================================================================
// FILE: utils/constructionMaster.ts
//===============================================================================
﻿
export const CONSTRUCTION_HIERARCHY = {
  "直接工事費": {
    "着手前及び完成写真": {
      "舗装工": {
        "舗装打換え工": {
          "表層工": {
            "aliases": ["着手前", "完了", "竣工"]
          }
        },
        "未舗装部舗装工": {
          "表層工": {
            "aliases": ["着手前", "完了", "竣工"]
          }
        },
        "瀝青安定処理路盤工": {
          "表層工": {
            "aliases": ["着手前", "完了", "竣工"]
          }
        }
      }
    },
    "施工状況写真": {
      "構造物撤去工": {
        "構造物取壊し工": {
          "コンクリート構造物取壊し": {
            "取壊し状況": {},
            "コンクリート（有筋）処分前": {},
            "コンクリート（有筋）処分中": {},
            "コンクリート（有筋）処分後": {},
            "処分前": {},
            "処分中": {},
            "処分後": {},
            "積込状況": {}
          }
        }
      },
      "道路土工": {
        "掘削工": {
          "掘削状況": {},
          "掘削完了": {}
        },
        "路床工": {
          "路床整正状況": {},
          "路床転圧状況": {},
          "路床完了": {}
        },
        "法面工": {
          "法面整形状況": {},
          "植生工施工状況": {}
        }
      },
      "舗装工": {
        "舗装打換え工": {
          "舗装版切断": {
            "As舗装版切断状況": {},
            "既設舗装版切断状況": {},
            "完了": {}
          },
          "舗装版破砕": {
            "剥取状況": {},
            "積込状況": {},
            "既設舗装厚さ確認": {},
            "完了": {}
          },
          "上層路盤工": {
            "補足材搬入状況 M-40": {},
            "補足材搬入状況 RC-40": {},
            "補足材搬入状況 RM-40": {},
            "不陸整正状況": {},
            "転圧状況": {},
            "路盤完了状況": {}
          },
          "表層工": {
            "プライムコート乳剤散布状況": {},
            "プライムコート養生砂散布状況": {},
            "プライムコート養生砂清掃状況": {},
            "端部乳剤塗布状況": {},
            "舗設状況": {},
            "初期転圧状況": {},
            "2次転圧状況": {},
            "施工完了": {}
          }
        },
        "未舗装部舗装工": {
          "上層路盤工": {
            "鋤取り状況": {},
            "補足材搬入状況 M-40": {},
            "補足材搬入状況 RC-40": {},
            "補足材搬入状況 RM-40": {},
            "不陸整正状況": {},
            "転圧状況": {},
            "路盤完了状況": {}
          },
          "表層工": {
            "プライムコート乳剤散布状況": {},
            "プライムコート養生砂散布状況": {},
            "プライムコート養生砂清掃状況": {},
            "端部乳剤塗布状況": {},
            "舗設状況": {},
            "初期転圧状況": {},
            "2次転圧状況": {},
            "施工完了": {}
          }
        },
        "瀝青安定処理路盤工": {
          "上層路盤工": {
            "補足材搬入状況 M-40": {},
            "補足材搬入状況 RC-40": {},
            "補足材搬入状況 RM-40": {},
            "不陸整正状況": {},
            "転圧状況": {},
            "路盤完了状況": {}
          },
          "表層工": {
            "プライムコート乳剤散布状況": {},
            "プライムコート養生砂散布状況": {},
            "プライムコート養生砂清掃状況": {},
            "端部乳剤塗布状況": {},
            "施工完了": {}
          }
        }
      },
      "区画線工": {
        "区画線工": {
          "溶融式区画線": {
            "清掃状況": {},
            "プライマー散布状況": {},
            "区画線設置状況": {},
            "完了": {}
          }
        }
      },
      "排水構造物工": {
        "作業土工": {
          "床掘り": {
            "掘削状況": {},
            "掘削完了": {}
          },
          "埋戻し": {
            "土砂埋戻し 転圧状況": {},
            "敷均し、転圧状況": {},
            "下層路盤 材料搬入状況 RC-40": {},
            "下層路盤 転圧状況": {},
            "上層路盤 敷均し状況": {},
            "上層路盤M-40 転圧状況": {},
            "完了": {}
          },
          "基礎砕石工": {
            "RC-40 搬入状況": {},
            "基礎砕石敷均し状況": {},
            "基礎砕石転圧状況": {},
            "完了": {}
          },
          "基礎コンクリート工": {
            "型枠設置完了": {},
            "打設前": {},
            "打設完了": {},
            "打設状況": {},
            "打設厚さ確認": {},
            "打設幅確認": {}
          }
        },
        "集水桝工": {
          "集水枡底版": {
            "集水桝底版 打設前確認": {},
            "底版コンクリート 打設前確認": {},
            "底版コンクリート 打設完了": {}
          },
          "プレキャスト集水桝": {
            "据付状況": {},
            "完了": {}
          }
        },
        "側溝工": {
          "側溝蓋": {
            "側溝蓋 打設前確認": {},
            "側溝蓋 打設完了": {},
            "天端コンクリート 打設前確認": {},
            "天端コンクリート 打設完了": {},
            "天端コンクリート 打設状況": {}
          },
          "プレキャストU型側溝": {
            "側溝300　据付状況": {},
            "G付側溝300　据付状況": {},
            "敷モルタル敷均し状況": {},
            "据付状況": {},
            "完了": {}
          }
        },
        "集水桝・マンホール工": {
          "人孔蓋撤去": {
            "鉄蓋処分状況": {},
            "既設人孔撤去状況": {},
            "完了": {}
          },
          "人孔蓋据付": {
            "調整ブロック設置状況": {},
            "据付状況": {},
            "高さ調整完了": {}
          },
          "人孔内部清掃": {
            "清掃状況": {},
            "清掃完了": {}
          },
          "調整蓋据付": {
            "据付状況": {},
            "完了": {}
          },
          "調整リングブロック設置": {
            "設置状況": {},
            "完了": {}
          },
          "転落防止蓋設置": {
            "設置状況": {},
            "完了": {}
          }
        }
      },
      "人孔改良工": {
        "集水桝・マンホール工": {
          "人孔蓋撤去": {
            "鉄蓋処分状況": {},
            "既設人孔撤去状況": {},
            "完了": {}
          },
          "人孔蓋据付": {
            "調整ブロック設置状況": {},
            "据付状況": {},
            "高さ調整完了": {}
          },
          "人孔内部清掃": {
            "清掃状況": {},
            "清掃完了": {}
          },
          "調整ブロック設置": {
            "調整ブロック設置状況": {},
            "完了": {}
          },
          "調整部撤去": {
            "調整部撤去状況": {},
            "完了": {}
          },
          "無収縮モルタル充填": {
            "無収縮モルタル充填状況": {},
            "完了": {}
          }
        },
        "舗装打換え工": {
          "舗装板切断": {
            "舗装板切断状況": {},
            "完了": {}
          },
          "舗装板破砕": {
            "舗装板破砕状況": {},
            "完了": {}
          },
          "既設舗装版撤去": {
            "既設舗装版撤去状況": {},
            "完了": {}
          },
          "上層路盤": {
            "上層路盤施工状況": {},
            "完了": {}
          },
          "表層（プライムコート）": {
            "プライムコート施工状況": {},
            "完了": {}
          },
          "表層（温度管理）": {
            "温度管理状況": {}
          },
          "表層（舗設）": {
            "舗設状況": {},
            "施工完了": {}
          }
        },
        "人孔蓋据付撤去工": {
          "既設人孔蓋撤去": {
            "既設人孔撤去状況": {},
            "撤去完了": {}
          },
          "既設受枠撤去": {
            "既設受枠撤去状況": {},
            "撤去完了": {}
          },
          "鉄蓋処分": {
            "鉄蓋処分状況": {},
            "処分完了": {}
          },
          "人孔蓋転落防止設置": {
            "人孔蓋転落防止設置状況": {},
            "設置完了": {}
          },
          "調整ブロック設置": {
            "調整ブロック設置状況": {},
            "設置完了": {}
          },
          "調整金具取付": {
            "調整金具パッキン取付状況": {},
            "調整金具パッキン使用": {},
            "固定用ボルト設置状況": {},
            "取付完了": {}
          },
          "人孔高さ調整": {
            "人孔(上部)高さ調整完了": {},
            "高さ調整状況": {}
          },
          "人孔内部清掃": {
            "人孔内清掃前状況": {},
            "人孔内清掃完了": {},
            "人孔内コンクリート撤去清掃状況": {}
          },
          "舗装版切断": {
            "舗装版切断状況": {},
            "完了": {}
          },
          "舗装版破砕積込": {
            "舗装版破砕積込状況": {},
            "積込完了": {}
          },
          "コンクリートはつり工": {
            "はつり工状況": {},
            "はつり工完了": {}
          },
          "汚泥吸排車": {
            "汚泥吸排状況": {},
            "汚泥吸排完了": {}
          },
          "表層工": {
            "表層工施工状況": {},
            "表層工完了": {}
          }
        }
      },
      "仮設工": {
        "交通管理工": {
          "交通誘導員配置": {
            "誘導員配置状況": {},
            "規制配置状況": {}
          },
          "保安施設設置": {
            "保安施設設置状況": {},
            "保安施設撤去状況": {},
            "完了": {}
          }
        }
      }
    },
    "安全管理写真": {
       "安全施設工": {
         "保安施設": {
           "看板設置状況": {},
           "バリケード設置状況": {},
           "点灯状況": {}
         }
       },
       "安全衛生": {
         "朝礼状況": {},
         "KY活動状況": {},
         "新規入場者教育状況": {}
       }
    },
    "使用材料写真": {
       "舗装工": {
         "舗装打換え工": {
            "表層工": {
              "材料検収状況": {},
              "搬入状況": {}
            }
         }
       }
    },
    "品質管理写真": {
      "舗装工": {
        "舗装打換え工": {
          "上層路盤工": {
            "現場密度測定工": {
              "aliases": ["密度測定", "RI計器"]
            }
          },
          "表層工": {
            "温度測定工": {
              "aliases": ["温度管理", "出荷時温度", "到着時温度", "舗設時温度"]
            }
          }
        }
      }
    },
    "出来形管理写真": {
      "舗装工": {
        "舗装打換え工": {
          "上層路盤工": {
            "不陸整正出来形": {
              "aliases": ["路盤出来形", "出来形検測", "路盤", "基準高下がり", "基準高"]
            },
            "不陸整正出来形・管理値": {},
            "不陸整正出来形・接写": {},
            "砕石厚測定": {}
          }
        }
      },
      "排水構造物工": {
        "作業土工": {
          "床掘り": {
            "掘削工出来形測定": {}
          },
          "埋戻し": {
            "土砂埋戻し出来形測定": {},
            "下層路盤出来形測定": {},
            "上層路盤出来形測定": {},
            "路床出来形測定": {}
          },
          "基礎砕石工": {
            "基礎砕石工出来形測定": {}
          },
          "基礎コンクリート工": {
            "基礎コンクリート出来形測定": {}
          }
        },
        "集水桝工": {
          "集水枡底版": {
            "集水桝底版出来形測定": {}
          },
          "プレキャスト集水桝": {
            "プレキャスト集水桝出来形測定": {}
          }
        },
        "側溝工": {
          "側溝蓋": {
            "側溝蓋出来形測定": {}
          },
          "プレキャストU型側溝": {
            "プレキャストU型側溝出来形測定": {}
          }
        }
      }
    }
  }
};

// 写真区分の一覧（国土交通省写真管理基準による正式名称）
export const PHOTO_CATEGORIES = [
  "着手前及び完成写真",
  "施工状況写真",
  "安全管理写真",
  "使用材料写真",
  "品質管理写真",
  "出来形管理写真",
  "災害写真",
  "事故写真",
  "その他"
] as const;

export type PhotoCategoryType = typeof PHOTO_CATEGORIES[number];

// 備考テキストから写真区分を推定する
export function inferPhotoCategory(remarkText: string): PhotoCategoryType {
  if (remarkText.includes("着手前") || remarkText.includes("完成") || remarkText.includes("竣工")) {
    return "着手前及び完成写真";
  }
  // 品質管理は出来形より先にチェック（「密度測定」は品質管理）
  if (remarkText.includes("品質") || remarkText.includes("温度") || remarkText.includes("密度")) {
    return "品質管理写真";
  }
  if (remarkText.includes("出来形") || remarkText.includes("測定")) {
    return "出来形管理写真";
  }
  if (remarkText.includes("材料") || remarkText.includes("検収") || remarkText.includes("搬入")) {
    return "使用材料写真";
  }
  if (remarkText.includes("安全") || remarkText.includes("朝礼") || remarkText.includes("KY")) {
    return "安全管理写真";
  }
  return "施工状況写真";
}


//===============================================================================
// FILE: utils/translations.ts
//===============================================================================


export const TRANS = {
  en: {
    appTitle: "Construction Album Maker",
    tagline: "",
    uploadTitle: "",
    uploadDesc: "",
    putPhotos: "Upload Photos",
    resumeLabel: "RESUME SESSION",
    resumeBtn: "View Album",
    clearBtn: "Clear",
    previewTitle: "Album Preview",
    total: "Total",
    done: "Done",
    backHome: "Back",
    deleteData: "Close",
    newFolder: "New",
    exportExcel: "Excel",
    exportPDF: "PDF",
    analyzing: "ANALYZING...",
    waiting: "Waiting...",
    permissionError: "API Permission Denied. Please check your API Key settings.",
    noImages: "No image files found.",
    resetConfirm: "Close the current album view? (Data is cached)",
    pdfError: "Failed to generate PDF.",
    excelError: "Excel generation failed.",
    cacheHit: (n: number) => `Restored ${n} photos!`,
    exportJson: "Backup Data",
    importJson: "Restore Data",
    dataMgmt: "Data",
    dropHere: "Drop files here",
    identifyingTargets: "AI identifying relevant photos...",
    // Modes
    modeConstruction: "Construction",
    modeGeneral: "General",
    // Labels (Dynamic)
    labelWorkType: "Category",
    labelVariety: "Sub-Category",
    labelDetail: "Detail",
    labelCategory: "Category",
    labelStation: "Location",
    labelLocation: "Location",
    labelDate: "Date",
    labelRemarks: "Title",
    labelTitle: "Title / Key Point",
    labelDescription: "Description",
    // Refine Modal
    refineTitle: "Refine / Rules",
    refineDesc: "Add custom instructions or select from presets.",
    refinePlaceholder: "e.g., 'Change Category to Family Trip'",
    saveRuleLabel: "Rule Name",
    ruleNamePlaceholder: "Rule Name",
    savedRulesTitle: "Saved Rules",
    btnRefine: "Run Analysis",
    btnUpdateRule: "Update",
    btnSaveRule: "Save",
    cancelEdit: "Cancel",
    or: "OR",
    newRule: "New",
    loadPreset: "Presets",
    searchPlaceholder: "Search...",
    noRulesYet: "No rules saved.",
    btnReanalyzeAll: "Re-analyze All (Preserve Edits)",
    // Limit Modal
    limitTitle: "Too many photos",
    limitDesc: (n: number) => `Selected ${n} photos. Limit to 30 for stability.`,
    startLabel: "Start index:",
    rangeLabel: `Count (Max 30):`,
    rangePreview: (s: number, e: number) => `#${s} - #${e}`,
    btnProcess: "Start",
    btnCancel: "Cancel",
    // Pairing
    btnPairing: "Auto-Pair (Before/After)",
    pairingProcessing: "Finding Pairs...",
    pairingRefining: "Checking history (Before/After context)...",
    pairingSuccess: "Sorted into Before/After pairs!",
    pairingNoPairs: "No clear pairs found.",
    layout2up: "2 Photos/Page",
    layout3up: "3 Photos/Page",
    autoPairLabel: "Auto-sort Before/After pairs"
  },
  ja: {
    appTitle: "工事写真帳メーカー",
    tagline: "",
    uploadTitle: "",
    uploadDesc: "",
    putPhotos: "写真をアップロード",
    resumeLabel: "前回の続きから",
    resumeBtn: "アルバムを表示",
    clearBtn: "クリア",
    previewTitle: "アルバムプレビュー",
    total: "全枚数",
    done: "完了",
    backHome: "戻る",
    deleteData: "閉じる",
    newFolder: "新規",
    exportExcel: "Excel出力",
    exportPDF: "PDF出力",
    analyzing: "解析中...",
    waiting: "待機中...",
    permissionError: "API権限エラー。APIキーを確認してください。",
    noImages: "画像が見つかりませんでした。",
    resetConfirm: "現在の画面を閉じますか？（データは保持されます）",
    pdfError: "PDF生成失敗",
    excelError: "Excel生成失敗",
    cacheHit: (n: number) => `${n}枚を復元しました`,
    exportJson: "データ保存",
    importJson: "データ復元",
    dataMgmt: "データ管理",
    dropHere: "ここにドロップ",
    identifyingTargets: "指示に関連する写真を特定中...",
    // Modes
    modeConstruction: "工事写真",
    modeGeneral: "一般写真",
    // Labels (Dynamic)
    labelWorkType: "工種",
    labelVariety: "種別",
    labelDetail: "細別",
    labelCategory: "カテゴリ",
    labelStation: "測点",
    labelLocation: "場所",
    labelDate: "日時",
    labelRemarks: "備考",
    labelTitle: "タイトル・要点",
    labelDescription: "記事",
    // Refine Modal
    refineTitle: "AI校正・ルール設定",
    refineDesc: "指示を入力するか、ルールを選択してください。",
    refinePlaceholder: "例：カテゴリを「家族旅行」に統一",
    saveRuleLabel: "ルール名",
    ruleNamePlaceholder: "ルール名を入力",
    savedRulesTitle: "保存済みルール",
    btnRefine: "再解析",
    btnUpdateRule: "更新",
    btnSaveRule: "保存",
    cancelEdit: "中止",
    or: "または",
    newRule: "新規",
    loadPreset: "プリセット",
    searchPlaceholder: "検索...",
    noRulesYet: "保存されたルールはありません",
    btnReanalyzeAll: "全件再解析 (手修正を維持)",
    // Limit Modal
    limitTitle: "枚数制限",
    limitDesc: (n: number) => `${n}枚選択されています。安定動作のため30枚以下にしてください。`,
    startLabel: "開始位置:",
    rangeLabel: "枚数 (最大30):",
    rangePreview: (s: number, e: number) => `${s}枚目 ～ ${e}枚目`,
    btnProcess: "開始",
    btnCancel: "キャンセル",
    // Pairing
    btnPairing: "着手前・完了ペアリング",
    pairingProcessing: "ペアリング解析中...",
    pairingRefining: "着手前の状況から工種を判定中...",
    pairingSuccess: "着手前・完了のペア順に並び替えました（2枚/頁）",
    pairingNoPairs: "明確なペアが見つかりませんでした",
    layout2up: "2枚/ページ",
    layout3up: "3枚/ページ",
    autoPairLabel: "着手前・完了写真を自動ペアリング"
  }
};

//===============================================================================
// FILE: utils/imageUtils.ts
//===============================================================================
// Declare EXIF global from exif-js script
declare const EXIF: any;

export const getPhotoDate = (file: File): Promise<number> => {
  return new Promise((resolve) => {
    // Default to lastModified if EXIF fails
    const defaultDate = file.lastModified;

    if (typeof EXIF === 'undefined') {
      resolve(defaultDate);
      return;
    }

    EXIF.getData(file, function(this: any) {
      const dateStr = EXIF.getTag(this, "DateTimeOriginal");
      if (dateStr) {
        // Format is usually "YYYY:MM:DD HH:MM:SS"
        // Needs conversion to be parsed by Date
        try {
          const [datePart, timePart] = dateStr.split(' ');
          const [y, m, d] = datePart.split(':');
          const [h, min, s] = timePart.split(':');
          const dateObj = new Date(parseInt(y), parseInt(m) - 1, parseInt(d), parseInt(h), parseInt(min), parseInt(s));
          resolve(dateObj.getTime());
        } catch (e) {
          resolve(defaultDate);
        }
      } else {
        resolve(defaultDate);
      }
    });
  });
};

// Resizes an image to a maximum dimension to save bandwidth/tokens and convert to base64
// Reduced default from 2048 to 1600 for mobile stability (still ~450dpi for A4 3-up layout)
export const processImageForAI = (file: File, maxDimension: number = 1600): Promise<{ base64: string; mimeType: string }> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = (readerEvent) => {
      const img = new Image();
      img.onload = () => {
        let width = img.width;
        let height = img.height;

        if (width > height) {
          if (width > maxDimension) {
            height *= maxDimension / width;
            width = maxDimension;
          }
        } else {
          if (height > maxDimension) {
            width *= maxDimension / height;
            height = maxDimension;
          }
        }

        const canvas = document.createElement('canvas');
        canvas.width = width;
        canvas.height = height;
        const ctx = canvas.getContext('2d');
        if (!ctx) {
          reject(new Error("Could not get canvas context"));
          return;
        }

        ctx.drawImage(img, 0, 0, width, height);
        
        // Gemini prefers standard base64 without the prefix for the API part, 
        // but for display we need the prefix. We return standard data URL.
        // Compressed to 0.7 to allow larger batches (e.g., 15 photos) without timeout/payload issues
        const dataUrl = canvas.toDataURL('image/jpeg', 0.7); 
        resolve({
          base64: dataUrl,
          mimeType: 'image/jpeg'
        });
      };
      img.onerror = () => reject(new Error("Failed to load image"));
      if (readerEvent.target?.result) {
        img.src = readerEvent.target.result as string;
      }
    };
    reader.onerror = () => reject(new Error("Failed to read file"));
    reader.readAsDataURL(file);
  });
};

export const extractBase64Data = (dataUrl: string): string => {
  return dataUrl.split(',')[1];
};

//===============================================================================
// FILE: utils/storage.ts
//===============================================================================


import { PhotoRecord, AIAnalysisResult } from "../types";
import { fsCache } from './fileSystemCache';

const DB_NAME = 'ConstructionPhotoManagerDB';
const DB_VERSION = 3; // Version 3 handles File storage in Session Store implicitly
const STORE_SESSION = 'projectData';
const STORE_CACHE = 'analysisCache'; // Persistent pool for analysis results
const STORE_RULES = 'analysisRules'; // New: Store for custom prompt rules
const KEY_SESSION = 'currentSession';

export interface AnalysisRule {
  id: string;
  name: string;
  instruction: string;
  tags?: string[];
}

const openDB = (): Promise<IDBDatabase> => {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open(DB_NAME, DB_VERSION);

    request.onupgradeneeded = (event) => {
      const db = (event.target as IDBOpenDBRequest).result;

      // Session Store (Current working state)
      if (!db.objectStoreNames.contains(STORE_SESSION)) {
        db.createObjectStore(STORE_SESSION);
      }

      // Cache Store (Persistent Pool)
      if (!db.objectStoreNames.contains(STORE_CACHE)) {
        db.createObjectStore(STORE_CACHE);
      }

      // New Store for Rules
      if (!db.objectStoreNames.contains(STORE_RULES)) {
        db.createObjectStore(STORE_RULES, { keyPath: 'id' });
      }
    };

    request.onsuccess = (event) => {
      resolve((event.target as IDBOpenDBRequest).result);
    };

    request.onerror = (event) => {
      reject((event.target as IDBOpenDBRequest).error);
    };
  });
};

// --- Session Management (Current View) ---

export const saveProjectData = async (photos: PhotoRecord[]): Promise<void> => {
  if (photos.length === 0) return;

  // We NOW store the full record including the File object (supported by IDB).
  // This ensures that on reload, the 'originalFile' is preserved.
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_SESSION, 'readwrite');
    const store = transaction.objectStore(STORE_SESSION);
    const request = store.put(photos, KEY_SESSION);
    request.onsuccess = () => resolve();
    request.onerror = () => reject(request.error);
  });
};

export const loadProjectData = async (): Promise<PhotoRecord[] | null> => {
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_SESSION, 'readonly');
    const store = transaction.objectStore(STORE_SESSION);
    const request = store.get(KEY_SESSION);
    request.onsuccess = () => resolve(request.result as PhotoRecord[] || null);
    request.onerror = () => reject(request.error);
  });
};

export const clearProjectData = async (): Promise<void> => {
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_SESSION, 'readwrite');
    const store = transaction.objectStore(STORE_SESSION);
    const request = store.delete(KEY_SESSION);
    request.onsuccess = () => resolve();
    request.onerror = () => reject(request.error);
  });
};

// --- Persistent Analysis Cache (Data Pool) ---

/**
 * Generates a unique key for the file based on its immutable properties.
 * Can handle a raw File object OR a PhotoRecord with metadata.
 */
const getFileKey = (input: File | PhotoRecord): string => {
  let name = "";
  let size = 0;
  let modified = 0;

  // Priority 1: Raw File Object
  if (input instanceof File) {
    name = input.name;
    size = input.size;
    modified = input.lastModified;
  }
  // Priority 2: PhotoRecord with originalFile (Ensures consistency if record missing explicit metadata)
  else if (input.originalFile) {
    name = input.fileName; // fileName matches originalFile.name
    size = input.originalFile.size;
    modified = input.originalFile.lastModified;
  }
  // Priority 3: PhotoRecord explicit metadata
  else {
    name = input.fileName;
    // Fallback to 0 if not present (legacy data compatibility)
    size = input.fileSize || 0;
    modified = input.lastModified || 0;
  }

  // Composite key: Name + Size + ModifiedTime ensures uniqueness for specific file versions
  return `${name}_${size}_${modified}`;
};

export const getCachedAnalysis = async (input: File | PhotoRecord): Promise<AIAnalysisResult | null> => {
  // 先にFile System Cacheを確認（利用可能な場合）
  if (fsCache.isAvailable() && !(input instanceof File)) {
    const fsCached = await fsCache.getCachedAnalysis(input);
    if (fsCached) {
      console.log('Retrieved from file system cache');
      return fsCached;
    }
  }

  // IndexedDBから取得
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_CACHE, 'readonly');
    const store = transaction.objectStore(STORE_CACHE);
    const key = getFileKey(input);
    const request = store.get(key);

    request.onsuccess = () => {
      resolve(request.result as AIAnalysisResult || null);
    };
    request.onerror = () => {
      console.warn("Cache lookup failed", request.error);
      resolve(null);
    };
  });
};

export const cacheAnalysis = async (input: File | PhotoRecord, result: AIAnalysisResult): Promise<void> => {
  // File System Cacheにも保存（利用可能な場合）
  if (fsCache.isAvailable() && !(input instanceof File)) {
    await fsCache.cacheAnalysis(input, result);
  }

  // IndexedDBにも保存
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_CACHE, 'readwrite');
    const store = transaction.objectStore(STORE_CACHE);
    const key = getFileKey(input);
    const request = store.put(result, key);

    request.onsuccess = () => resolve();
    request.onerror = () => reject(request.error);
  });
};

export const clearAnalysisCache = async (): Promise<void> => {
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_CACHE, 'readwrite');
    const store = transaction.objectStore(STORE_CACHE);
    const request = store.clear();
    request.onsuccess = () => resolve();
    request.onerror = () => reject(request.error);
  });
};

// --- Rules Management (New) ---

export const saveRule = async (rule: AnalysisRule): Promise<void> => {
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_RULES, 'readwrite');
    const store = transaction.objectStore(STORE_RULES);
    const request = store.put(rule);
    request.onsuccess = () => resolve();
    request.onerror = () => reject(request.error);
  });
};

export const getRules = async (): Promise<AnalysisRule[]> => {
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_RULES, 'readonly');
    const store = transaction.objectStore(STORE_RULES);
    const request = store.getAll();
    request.onsuccess = () => resolve(request.result as AnalysisRule[]);
    request.onerror = () => reject(request.error);
  });
};

export const deleteRule = async (id: string): Promise<void> => {
  const db = await openDB();
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(STORE_RULES, 'readwrite');
    const store = transaction.objectStore(STORE_RULES);
    const request = store.delete(id);
    request.onsuccess = () => resolve();
    request.onerror = () => reject(request.error);
  });
};

// --- Export / Import Utilities ---

export const exportDataToJson = (photos: PhotoRecord[]): string => {
  const dataToExport = photos.map(p => {
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    const { originalFile, ...rest } = p;
    return rest;
  });
  return JSON.stringify(dataToExport, null, 2);
};

export const importDataFromJson = (jsonStr: string): PhotoRecord[] => {
  try {
    const parsed = JSON.parse(jsonStr);
    if (!Array.isArray(parsed)) throw new Error("Invalid JSON format");
    return parsed as PhotoRecord[];
  } catch (e) {
    console.error("Import failed", e);
    throw e;
  }
};

export const exportRulesToJson = (rules: AnalysisRule[]): string => {
  return JSON.stringify(rules, null, 2);
};

export const importRulesFromJson = (jsonStr: string): AnalysisRule[] => {
  try {
    const parsed = JSON.parse(jsonStr);
    if (!Array.isArray(parsed)) throw new Error("Invalid Rules JSON format");
    return parsed as AnalysisRule[];
  } catch (e) {
    console.error("Import rules failed", e);
    throw e;
  }
};

//===============================================================================
// FILE: utils/fileSystemCache.ts
//===============================================================================
/**
 * File System Access API を使用したローカルファイルキャッシュ
 * ブラウザから直接ローカルファイルシステムにアクセスして永続化
 */

import { PhotoRecord, AIAnalysisResult } from '../types';

// キャッシュファイル名の規則
const CACHE_FILE_PREFIX = 'photo_cache_';
const CACHE_INDEX_FILE = '.cache_index.json';

export interface CacheIndex {
  version: string;
  lastUpdated: string;
  files: {
    [key: string]: {
      fileName: string;
      hash: string;
      cachedAt: string;
    };
  };
}

export interface CacheEntry {
  photoHash: string;
  fileName: string;
  analysis: AIAnalysisResult;
  cachedAt: string;
}

// ファイルハッシュを生成（簡易版）
const generateHash = async (base64: string): Promise<string> => {
  // base64の最初の1000文字 + サイズでハッシュ生成
  const sample = base64.substring(0, 1000) + base64.length;
  const encoder = new TextEncoder();
  const data = encoder.encode(sample);
  const hashBuffer = await crypto.subtle.digest('SHA-256', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  return hashHex.substring(0, 16); // 16文字に短縮
};

class FileSystemCache {
  private directoryHandle: FileSystemDirectoryHandle | null = null;
  private cacheIndex: CacheIndex | null = null;

  /**
   * キャッシュディレクトリを選択または作成
   */
  async selectCacheDirectory(): Promise<boolean> {
    try {
      // @ts-ignore - File System Access APIは型定義が不完全
      this.directoryHandle = await window.showDirectoryPicker({
        mode: 'readwrite',
        startIn: 'documents'
      });

      await this.loadOrCreateIndex();
      return true;
    } catch (error) {
      console.error('Failed to select cache directory:', error);
      return false;
    }
  }

  /**
   * 既存のハンドルから復元（ページリロード時用）
   */
  async restoreFromHandle(handle: FileSystemDirectoryHandle): Promise<boolean> {
    try {
      // 権限を再確認
      // @ts-ignore
      const permission = await handle.queryPermission({ mode: 'readwrite' });
      if (permission === 'granted') {
        this.directoryHandle = handle;
        await this.loadOrCreateIndex();
        return true;
      }

      // 権限を再要求
      // @ts-ignore
      const requestPermission = await handle.requestPermission({ mode: 'readwrite' });
      if (requestPermission === 'granted') {
        this.directoryHandle = handle;
        await this.loadOrCreateIndex();
        return true;
      }
    } catch (error) {
      console.error('Failed to restore directory handle:', error);
    }
    return false;
  }

  /**
   * インデックスファイルの読み込みまたは作成
   */
  private async loadOrCreateIndex(): Promise<void> {
    if (!this.directoryHandle) return;

    try {
      const fileHandle = await this.directoryHandle.getFileHandle(CACHE_INDEX_FILE);
      const file = await fileHandle.getFile();
      const text = await file.text();
      this.cacheIndex = JSON.parse(text);
    } catch {
      // インデックスファイルが存在しない場合は新規作成
      this.cacheIndex = {
        version: '1.0',
        lastUpdated: new Date().toISOString(),
        files: {}
      };
      await this.saveIndex();
    }
  }

  /**
   * インデックスファイルの保存
   */
  private async saveIndex(): Promise<void> {
    if (!this.directoryHandle || !this.cacheIndex) return;

    try {
      const fileHandle = await this.directoryHandle.getFileHandle(
        CACHE_INDEX_FILE,
        { create: true }
      );
      // @ts-ignore
      const writable = await fileHandle.createWritable();
      await writable.write(JSON.stringify(this.cacheIndex, null, 2));
      await writable.close();
    } catch (error) {
      console.error('Failed to save cache index:', error);
    }
  }

  /**
   * 写真の解析結果をキャッシュ
   */
  async cacheAnalysis(photo: PhotoRecord, analysis: AIAnalysisResult): Promise<void> {
    if (!this.directoryHandle || !this.cacheIndex) return;

    try {
      const hash = await generateHash(photo.base64);
      const cacheFileName = `${CACHE_FILE_PREFIX}${hash}.json`;

      const entry: CacheEntry = {
        photoHash: hash,
        fileName: photo.fileName,
        analysis,
        cachedAt: new Date().toISOString()
      };

      // キャッシュファイルを保存
      const fileHandle = await this.directoryHandle.getFileHandle(
        cacheFileName,
        { create: true }
      );
      // @ts-ignore
      const writable = await fileHandle.createWritable();
      await writable.write(JSON.stringify(entry, null, 2));
      await writable.close();

      // インデックスを更新
      this.cacheIndex.files[hash] = {
        fileName: photo.fileName,
        hash,
        cachedAt: entry.cachedAt
      };
      this.cacheIndex.lastUpdated = new Date().toISOString();
      await this.saveIndex();

      console.log(`Cached analysis for ${photo.fileName}`);
    } catch (error) {
      console.error('Failed to cache analysis:', error);
    }
  }

  /**
   * キャッシュから解析結果を取得
   */
  async getCachedAnalysis(photo: PhotoRecord): Promise<AIAnalysisResult | null> {
    if (!this.directoryHandle || !this.cacheIndex) return null;

    try {
      const hash = await generateHash(photo.base64);

      // インデックスにエントリが存在するか確認
      if (!this.cacheIndex.files[hash]) {
        return null;
      }

      const cacheFileName = `${CACHE_FILE_PREFIX}${hash}.json`;

      // キャッシュファイルを読み込み
      const fileHandle = await this.directoryHandle.getFileHandle(cacheFileName);
      const file = await fileHandle.getFile();
      const text = await file.text();
      const entry: CacheEntry = JSON.parse(text);

      console.log(`Retrieved cached analysis for ${photo.fileName}`);
      return entry.analysis;
    } catch (error) {
      console.error('Failed to retrieve cached analysis:', error);
      return null;
    }
  }

  /**
   * すべてのキャッシュをクリア
   */
  async clearAllCache(): Promise<void> {
    if (!this.directoryHandle || !this.cacheIndex) return;

    try {
      // すべてのキャッシュファイルを削除
      for (const hash of Object.keys(this.cacheIndex.files)) {
        const cacheFileName = `${CACHE_FILE_PREFIX}${hash}.json`;
        try {
          await this.directoryHandle.removeEntry(cacheFileName);
        } catch {
          // ファイルが存在しない場合は無視
        }
      }

      // インデックスをリセット
      this.cacheIndex.files = {};
      this.cacheIndex.lastUpdated = new Date().toISOString();
      await this.saveIndex();

      console.log('All cache cleared');
    } catch (error) {
      console.error('Failed to clear cache:', error);
    }
  }

  /**
   * キャッシュ統計を取得
   */
  getCacheStats(): { totalFiles: number; lastUpdated: string } | null {
    if (!this.cacheIndex) return null;

    return {
      totalFiles: Object.keys(this.cacheIndex.files).length,
      lastUpdated: this.cacheIndex.lastUpdated
    };
  }

  /**
   * ディレクトリハンドルを保存（セッション間で永続化）
   */
  async saveHandleToIndexedDB(): Promise<void> {
    if (!this.directoryHandle) return;

    try {
      const db = await this.openHandleDB();
      const tx = db.transaction(['handles'], 'readwrite');
      const store = tx.objectStore('handles');
      await store.put(this.directoryHandle, 'cacheDirectory');
      console.log('Directory handle saved to IndexedDB');
    } catch (error) {
      console.error('Failed to save handle:', error);
    }
  }

  /**
   * ディレクトリハンドルを復元
   */
  async loadHandleFromIndexedDB(): Promise<boolean> {
    try {
      const db = await this.openHandleDB();
      const tx = db.transaction(['handles'], 'readonly');
      const store = tx.objectStore('handles');
      const request = store.get('cacheDirectory');

      return new Promise((resolve) => {
        request.onsuccess = async () => {
          const handle = request.result;
          if (handle) {
            const restored = await this.restoreFromHandle(handle);
            resolve(restored);
          } else {
            resolve(false);
          }
        };
        request.onerror = () => resolve(false);
      });
    } catch (error) {
      console.error('Failed to load handle:', error);
      return false;
    }
  }

  /**
   * ハンドル保存用のIndexedDBを開く
   */
  private openHandleDB(): Promise<IDBDatabase> {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open('FileSystemHandles', 1);

      request.onupgradeneeded = (event) => {
        const db = (event.target as IDBOpenDBRequest).result;
        if (!db.objectStoreNames.contains('handles')) {
          db.createObjectStore('handles');
        }
      };

      request.onsuccess = () => resolve(request.result);
      request.onerror = () => reject(request.error);
    });
  }

  /**
   * File System Access APIがサポートされているか確認
   */
  static isSupported(): boolean {
    // @ts-ignore
    return 'showDirectoryPicker' in window;
  }
}

// シングルトンインスタンス
export const fileSystemCache = new FileSystemCache();

// 既存のstorage.tsと互換性のあるインターフェース
export const fsCache = {
  isAvailable: FileSystemCache.isSupported,

  selectDirectory: async (): Promise<boolean> => {
    return await fileSystemCache.selectCacheDirectory();
  },

  cacheAnalysis: async (photo: PhotoRecord, analysis: AIAnalysisResult): Promise<void> => {
    await fileSystemCache.cacheAnalysis(photo, analysis);
  },

  getCachedAnalysis: async (photo: PhotoRecord): Promise<AIAnalysisResult | null> => {
    return await fileSystemCache.getCachedAnalysis(photo);
  },

  clearCache: async (): Promise<void> => {
    await fileSystemCache.clearAllCache();
  },

  getStats: () => {
    return fileSystemCache.getCacheStats();
  },

  saveHandle: async (): Promise<void> => {
    await fileSystemCache.saveHandleToIndexedDB();
  },

  restoreHandle: async (): Promise<boolean> => {
    return await fileSystemCache.loadHandleFromIndexedDB();
  }
};

//===============================================================================
// FILE: utils/layoutConfig.ts
//===============================================================================

import { AIAnalysisResult } from "../types";

export interface FieldDefinition {
  id: string; // Unique ID for key mapping
  key: keyof AIAnalysisResult | 'date'; // Data key
  labelKey: string; // Translation key in TRANS
  rowSpan: number; // Height weight (1 unit approx 28px)
  heightClass: string; // Tailwind class for Web View
  multiline: boolean; // Textarea vs Input
  readOnly?: boolean;
}

/**
 * SHARED LAYOUT DEFINITION
 * Total Rows: 12 (Standard block size for 3-up on A4)
 * Base Row Height: ~28px (21pt in Excel)
 */
export const LAYOUT_FIELDS: FieldDefinition[] = [
  { 
    id: 'f_date',
    key: 'date', 
    labelKey: 'labelDate', 
    rowSpan: 1, 
    heightClass: 'h-[28px]', 
    multiline: false,
    readOnly: true
  },
  { 
    id: 'f_workType',
    key: 'workType', 
    labelKey: 'labelWorkType', 
    rowSpan: 1, 
    heightClass: 'h-[28px]', 
    multiline: false 
  },
  { 
    id: 'f_variety',
    key: 'variety', 
    labelKey: 'labelVariety', 
    rowSpan: 1, 
    heightClass: 'h-[28px]', 
    multiline: false 
  },
  { 
    id: 'f_detail',
    key: 'detail', 
    labelKey: 'labelDetail', 
    rowSpan: 1, 
    heightClass: 'h-[28px]', 
    multiline: false 
  },
  { 
    id: 'f_station',
    key: 'station', 
    labelKey: 'labelStation', 
    rowSpan: 1, 
    heightClass: 'h-[28px]', 
    multiline: false 
  },
  { 
    id: 'f_remarks',
    key: 'remarks', 
    labelKey: 'labelRemarks', 
    rowSpan: 2, 
    heightClass: 'h-[56px]', // 2 rows * 28px = 56px
    multiline: true 
  },
  { 
    id: 'f_description',
    key: 'description', 
    labelKey: 'labelDescription', 
    rowSpan: 5, 
    heightClass: 'flex-1', // Takes remaining space (approx 140px)
    multiline: true 
  }
];

export const ROWS_PER_PHOTO = 12;


//===============================================================================
// FILE: utils/excelGenerator.ts
//===============================================================================
import { PhotoRecord, AppMode, AIAnalysisResult } from "../types";
import { extractBase64Data } from "./imageUtils";
import { LAYOUT_FIELDS, ROWS_PER_PHOTO } from "./layoutConfig";
import { TRANS } from "./translations";

// Declare global variables for loaded scripts
declare const ExcelJS: any;
declare const saveAs: any;

// Helper to get actual dimensions of the base64 image string
const getImageDimensions = (base64: string): Promise<{ w: number; h: number }> => {
  return new Promise((resolve, reject) => {
    const img = new Image();
    img.onload = () => resolve({ w: img.width, h: img.height });
    img.onerror = (e) => reject(e);
    img.src = base64;
  });
};

export const generateExcel = async (
  records: PhotoRecord[], 
  appMode: AppMode = 'construction',
  photosPerPage: 2 | 3 = 3
) => {
  if (typeof ExcelJS === 'undefined') {
    alert("Excel generation library is not loaded.");
    return;
  }

  // Use current language for headers, or default to JA since this is primarily Japanese layout
  const txt = TRANS['ja']; 

  // Create a new workbook
  const workbook = new ExcelJS.Workbook();
  const sheet = workbook.addWorksheet(appMode === 'construction' ? '工事写真帳' : 'Photo Album', {
    pageSetup: { 
      paperSize: 9, // 9 = A4
      orientation: 'portrait',
      fitToPage: false,
      margins: {
        left: 0.7, right: 0.7, top: 0.75, bottom: 0.75,
        header: 0.3, footer: 0.3
      }
    },
    views: [{ showGridLines: false }]
  });

  // --- Layout Constants ---
  const isTwoUp = photosPerPage === 2;
  
  // Adjusted column widths for 2-up to maximize photo size
  // 3-up (Standard): A=65, B=8, C=25 (Total approx 98)
  // 2-up (Large Photo): A=80, B=6, C=14 (Total approx 100)
  const COL_A_WIDTH_CHARS = isTwoUp ? 80 : 65; 
  
  const PIXELS_PER_COL_UNIT = 7.1; // Tuned for ExcelJS default font
  
  const ROW_HEIGHT_PTS = 21; 
  const PIXELS_PER_PT = 96.0 / 72.0; // Standard DPI conversion
  
  // Calculate Rows per Photo Block based on layout
  // 3-up = 12 rows (default)
  // 2-up = 18 rows (approx 1.5x height to fill page)
  const rowsPerBlock = photosPerPage === 2 ? 18 : ROWS_PER_PHOTO;
  
  const BOX_WIDTH_PX = COL_A_WIDTH_CHARS * PIXELS_PER_COL_UNIT; 
  const BOX_HEIGHT_PX = rowsPerBlock * ROW_HEIGHT_PTS * PIXELS_PER_PT; 

  // Setup Column Widths
  if (isTwoUp) {
    sheet.columns = [
      { width: 80 }, // Column A (Image) - Wider for 2-up
      { width: 6 },  // Column B (Label) - Narrower
      { width: 14 }  // Column C (Value) - Narrower
    ];
  } else {
    sheet.columns = [
      { width: 65 }, // Column A
      { width: 8 },  // Column B
      { width: 25 }  // Column C
    ];
  }

  // Set default font
  sheet.eachRow((row: any) => {
    row.font = { name: 'Meiryo', size: 10 };
  });

  let currentRow = 1;

  for (let i = 0; i < records.length; i++) {
    const record = records[i];

    // Page Break Logic
    if (i > 0 && i % photosPerPage === 0) {
      sheet.getRow(currentRow).addPageBreak();
      currentRow++; // Spacer row
    }

    const startRow = currentRow;
    const endRow = startRow + rowsPerBlock - 1; 

    // Explicitly set row heights
    for (let r = startRow; r <= endRow; r++) {
      sheet.getRow(r).height = ROW_HEIGHT_PTS;
    }

    // --- 1. Image Section (Column A) ---
    // Merge Column A for the image
    sheet.mergeCells(startRow, 1, endRow, 1); // A{startRow}:A{endRow}
    const imgCell = sheet.getCell(startRow, 1);
    imgCell.border = {
      top: { style: 'thin', color: { argb: 'FFCCCCCC' } },
      left: { style: 'thin', color: { argb: 'FFCCCCCC' } },
      right: { style: 'thin', color: { argb: 'FFCCCCCC' } },
      bottom: { style: 'thin', color: { argb: 'FFCCCCCC' } }
    };

    const base64Data = extractBase64Data(record.base64);
    const imageId = workbook.addImage({
      base64: base64Data,
      extension: 'jpeg',
    });

    try {
      // 1. Get Actual Image Dimensions to preserve Aspect Ratio
      const { w: imgW, h: imgH } = await getImageDimensions(record.base64);
      
      // 2. Calculate Scale to Fit Box (Contain)
      const scaleW = (BOX_WIDTH_PX * 0.96) / imgW; // 96% to leave small padding
      const scaleH = (BOX_HEIGHT_PX * 0.96) / imgH;
      const scale = Math.min(scaleW, scaleH); // Contain logic

      const finalW = imgW * scale;
      const finalH = imgH * scale;

      // 3. Calculate Centering Offsets (in Pixels)
      const xOffsetPx = (BOX_WIDTH_PX - finalW) / 2;
      const yOffsetPx = (BOX_HEIGHT_PX - finalH) / 2;

      // 4. Place Image using Absolute Positioning (Pixels)
      const absX = xOffsetPx; // Column A starts at 0px
      const absY = ((startRow - 1) * ROW_HEIGHT_PTS * PIXELS_PER_PT) + yOffsetPx;

      sheet.addImage(imageId, {
        x: absX,
        y: absY,
        width: finalW,
        height: finalH,
        editAs: 'absolute'
      });

    } catch (e) {
      console.warn("Could not calculate image dimensions, falling back.", e);
      sheet.addImage(imageId, {
        tl: { col: 0.05, row: startRow - 1 + 0.5 },
        ext: { width: 400, height: 300 }, 
        editAs: 'oneCell' 
      });
    }

    // --- 2. Info Section (Columns B & C) ---
    // Helper function for creating fields
    const createField = (r: number, label: string, value: string, rowSpan: number) => {
      // Scale rowSpan if using 2-up layout to fill vertical space
      // 3-up total row span = 12. 
      // 2-up total row span = 18. Scale factor = 1.5.
      let finalRowSpan = rowSpan;
      if (photosPerPage === 2) {
         // Distribute extra rows to Remarks (often longer) and Description
         // Base Layout: Date(1), Type(1), Variety(1), Detail(1), Station(1), Remarks(2), Desc(5) = 12
         // 2-up Layout target: 18.
         // Mapping:
         // Date(1), Type(1), Variety(1), Detail(1), Station(1) -> Keep 1 (Total 5)
         // Remarks(2) -> 4
         // Description(5) -> 9
         // Total: 5 + 4 + 9 = 18.
         if (label === txt.labelRemarks) finalRowSpan = 4;
         if (label === txt.labelDescription) finalRowSpan = 9;
      }

      // Label Cell (Col 2 / B)
      const labelCell = sheet.getCell(r, 2);
      labelCell.value = label;
      labelCell.font = { bold: true, size: 9, color: { argb: 'FF555555' } };
      labelCell.alignment = { vertical: 'middle', horizontal: 'center' };
      labelCell.fill = { type: 'pattern', pattern: 'solid', fgColor: { argb: 'FFF5F5F5' } };
      labelCell.border = {
        top: { style: 'hair', color: { argb: 'FFAAAAAA' } },
        left: { style: 'hair', color: { argb: 'FFAAAAAA' } },
        right: { style: 'hair', color: { argb: 'FFAAAAAA' } },
        bottom: { style: 'hair', color: { argb: 'FFAAAAAA' } }
      };

      // Value Cell (Col 3 / C)
      const valueCell = sheet.getCell(r, 3);
      valueCell.value = value;
      valueCell.alignment = { vertical: 'middle', horizontal: 'left', wrapText: true };
      valueCell.font = { size: 11 }; 
      valueCell.border = {
        top: { style: 'hair', color: { argb: 'FFCCCCCC' } },
        right: { style: 'hair', color: { argb: 'FFCCCCCC' } },
        bottom: { style: 'hair', color: { argb: 'FFCCCCCC' } }
      };

      if (finalRowSpan > 1) {
        // Merge cells vertically
        sheet.mergeCells(r, 2, r + finalRowSpan - 1, 2); 
        sheet.mergeCells(r, 3, r + finalRowSpan - 1, 3); 
      }
      
      return finalRowSpan;
    };

    // Iterate through Shared Layout Configuration
    let currentFieldRow = startRow;
    
    LAYOUT_FIELDS.forEach((field) => {
      // Resolve Value
      let val = "";
      if (field.key === 'date') {
         val = record.date 
           ? new Date(record.date).toLocaleString('ja-JP', { year: 'numeric', month: '2-digit', day: '2-digit', hour: '2-digit', minute: '2-digit' }) 
           : "";
      } else {
         val = record.analysis ? (record.analysis[field.key as keyof AIAnalysisResult] as string || "") : "";
      }

      // Resolve Label
      const label = txt[field.labelKey as keyof typeof txt] as string;

      const usedSpan = createField(currentFieldRow, label, val, field.rowSpan);
      currentFieldRow += usedSpan;
    });

    currentRow = endRow + 2; 
  }

  try {
    const buffer = await workbook.xlsx.writeBuffer();
    const blob = new Blob([buffer], { type: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' });
    const dateStr = new Date().toISOString().slice(0, 10);
    saveAs(blob, `PhotoAlbum_${dateStr}.xlsx`);
  } catch (error) {
    console.error("Excel generation failed:", error);
    alert("Excel file generation failed.");
  }
};

//===============================================================================
// FILE: utils/xmlGenerator.ts
//===============================================================================

import { PhotoRecord } from "../types";

// Helper to escape XML characters
const escapeXml = (unsafe: string): string => {
  return unsafe.replace(/[<>&'"]/g, (c) => {
    switch (c) {
      case '<': return '&lt;';
      case '>': return '&gt;';
      case '&': return '&amp;';
      case '\'': return '&apos;';
      case '"': return '&quot;';
      default: return c;
    }
  });
};

export const generatePhotoXML = (records: PhotoRecord[]): string => {
  const dateStr = new Date().toISOString();
  
  let xml = '<?xml version="1.0" encoding="UTF-8"?>\n';
  xml += '<!DOCTYPE 工事写真情報 SYSTEM "PHOTO.DTD">\n';
  xml += '<工事写真情報>\n';
  xml += '  <電子納品要領基準>案/2010</電子納品要領基準>\n';
  xml += `  <作成日>${dateStr}</作成日>\n`;
  
  xml += '  <写真情報>\n';
  
  records.forEach((record, index) => {
    if (record.status !== 'done' || !record.analysis) return;
    
    // Sort number: 1-based index padded to 3 digits usually, but simple integer is ok
    const sortNum = index + 1;
    
    xml += '    <写真>\n';
    xml += `      <整理番号>${sortNum}</整理番号>\n`;
    xml += `      <工種>${escapeXml(record.analysis.workType || "")}</工種>\n`;
    xml += `      <種別>${escapeXml(record.analysis.variety || "")}</種別>\n`;
    xml += `      <細別>${escapeXml(record.analysis.detail || "")}</細別>\n`;
    xml += `      <撮影箇所>${escapeXml(record.analysis.station || "")}</撮影箇所>\n`;
    xml += `      <写真タイトル>${escapeXml(record.analysis.remarks || "")}</写真タイトル>\n`;
    xml += `      <写真説明>${escapeXml(record.analysis.description || "")}</写真説明>\n`;
    xml += `      <写真ファイル名>${escapeXml(record.fileName)}</写真ファイル名>\n`;
    xml += '    </写真>\n';
  });

  xml += '  </写真情報>\n';
  xml += '</工事写真情報>';
  
  return xml;
};

export const getDtdContent = (): string => {
  // A minimal DTD for PHOTO.XML validation context
  return `
<!ELEMENT 工事写真情報 (電子納品要領基準, 作成日, 写真情報)>
<!ELEMENT 電子納品要領基準 (#PCDATA)>
<!ELEMENT 作成日 (#PCDATA)>
<!ELEMENT 写真情報 (写真*)>
<!ELEMENT 写真 (整理番号, 工種, 種別, 細別, 撮影箇所, 写真タイトル, 写真説明, 写真ファイル名)>
<!ELEMENT 整理番号 (#PCDATA)>
<!ELEMENT 工種 (#PCDATA)>
<!ELEMENT 種別 (#PCDATA)>
<!ELEMENT 細別 (#PCDATA)>
<!ELEMENT 撮影箇所 (#PCDATA)>
<!ELEMENT 写真タイトル (#PCDATA)>
<!ELEMENT 写真説明 (#PCDATA)>
<!ELEMENT 写真ファイル名 (#PCDATA)>
  `.trim();
};

//===============================================================================
// FILE: utils/zipGenerator.ts
//===============================================================================
import { PhotoRecord } from "../types";
import { generatePhotoXML, getDtdContent } from "./xmlGenerator";
import { extractBase64Data } from "./imageUtils";

// Declare JSZip global
declare const JSZip: any;

export const generateZip = async (records: PhotoRecord[]): Promise<Blob> => {
  if (typeof JSZip === 'undefined') {
    throw new Error("JSZip library is not loaded.");
  }

  const zip = new JSZip();
  
  // Standard Folder Structure:
  // ROOT/
  //   PHOTO/
  //     PHOTO.XML
  //     PHOTO.DTD
  //     PIC/
  //       IMAGE1.JPG
  //       IMAGE2.JPG
  
  const photoDir = zip.folder("PHOTO");
  const picDir = photoDir.folder("PIC");

  // 1. Add Images
  const validRecords = records.filter(r => r.status === 'done' && r.analysis);
  
  validRecords.forEach(photo => {
    const base64Data = extractBase64Data(photo.base64);
    // Add file to PIC folder
    picDir.file(photo.fileName, base64Data, { base64: true });
  });

  // 2. Add XML
  const xmlContent = generatePhotoXML(validRecords);
  photoDir.file("PHOTO.XML", xmlContent);

  // 3. Add DTD
  const dtdContent = getDtdContent();
  photoDir.file("PHOTO.DTD", dtdContent);

  // Generate ZIP blob
  const content = await zip.generateAsync({ type: "blob" });
  return content;
};


//===============================================================================
// FILE: services/geminiService.ts
//===============================================================================
﻿
import { GoogleGenAI, Type, Schema } from "@google/genai";
import { PhotoRecord, AIAnalysisResult, AppMode, LogEntry } from "../types";
import { extractBase64Data } from "../utils/imageUtils";
import { formatHierarchyForPrompt, getSelectorPrompt, getHierarchySubset, getWorkTypes } from "../utils/workHierarchy";

// Configuration
// QUALITY FIRST: Using high-performance models for accuracy
const PRIMARY_MODEL = "gemini-3-pro-preview";
const COMPLEX_MODEL = "gemini-3-pro-preview";
const FALLBACK_MODEL = "gemini-2.5-flash";
const SELECTOR_MODEL = "gemini-2.5-flash"; // Fast model for work type selection
const MAX_RETRIES = 3;
const RETRY_DELAY_MS = 2000;

// Sleep helper
const sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

// Profiler helper
const formatDuration = (ms: number): string => {
  if (ms < 1000) return `${ms.toFixed(0)}ms`;
  return `${(ms / 1000).toFixed(2)}s`;
};

const getSystemInstruction = (appMode: AppMode, customInstruction?: string, hierarchy?: object) => {
  if (appMode === 'general') {
    return `
You are a professional photo archivist. Analyze the image and provide structured metadata.
1. Category: Main subject (e.g., Landscape, Family, Work).
2. Sub-category: Specifics (e.g., Mountain, Birthday, Office).
3. Location: Inferred or read from text.
4. Description: A concise caption explaining the photo.
${customInstruction ? `\nUSER OVERRIDE INSTRUCTION: ${customInstruction}` : ""}
    `.trim();
  }

  // Construction Mode
  return `
You are a Japanese construction site supervisor creating a formal photo ledger (蟾･莠句・逵溷ｸｳ).
The hierarchy provided is a STRICT SUBSET of the MLIT (Ministry of Land, Infrastructure, Transport and Tourism) standards.

**CRITICAL CONSTRAINT**: 
You MUST NOT use any Work Types, Varieties, or Details that are not explicitly defined in the provided MASTER DATA JSON. 
Even if you recognize a standard MLIT term, if it is not in the JSON, do not use it. Map to the closest existing node.

--- MASTER DATA HIERARCHY ---
${JSON.stringify(hierarchy || formatHierarchyForPrompt(), null, 2)}

--- HIERARCHY MAPPING RULES (STRICT) ---
The hierarchy is defined by depth levels. You must traverse from the Root to the Leaf and map the keys to the specific columns below.

**Hierarchy Structure** (Simplified - No Photo Category Branching):
*   **Level 1 (Root)**: Work Type (工種) -> Output to **'workType'**.
*   **Level 2**: Variety (種別) -> Output to **'variety'**.
*   **Level 3**: Detail (細別) -> Output to **'detail'**.
*   **Level 4 (Leaf)**: Remarks (備考) -> Output to **'remarks'**.

Photo categories are determined automatically based on the remarks field.

**STEP 1: Select Level 2 (Photo Category) - PRIORITIZATION RULE**
You must FIRST check if the photo is a static "Before" or "Completion" scene (Landscape/Scenery).
Only classify as "Construction Status" if there is clear evidence of **ACTIVE WORK**.

1.  **"逹謇句燕蜿翫・螳梧・蜀咏悄"** (Before & Completion) [PRIORITY 1 - DEFAULT]:
    *   **Definition**: Static photos of the site condition.
    *   **Pre-Construction (逹謇句燕)**: Old asphalt, cracked pavement, raw earth, grass/weeds. The site is untouched before work begins.
    *   **Completion (螳梧・/遶｣蟾･)**: Brand new black asphalt, fresh concrete, clean white lines, swept/clean surface.
    *   **Key Feature**: NO active heavy machinery operating, NO workers performing tasks. 
    *   **Note**: The presence of a measuring pole/ribbon ALONE does NOT make it "Status". If nobody is holding it or working, it is likely "Before" or "Completion".

2.  **"譁ｽ蟾･迥ｶ豕∝・逵・** (Construction Status) [PRIORITY 2 - REQUIRES ACTION]:
    *   **Definition**: Photos of the work in progress.
    *   **Visuals**: Heavy machinery (Excavators, Rollers) IN MOTION, dump trucks dumping, workers with shovels/rakes/tools actually working.
    *   **Midway States**: Piles of rubble, half-dug holes, measuring dimensions *during* the process (e.g., checking depth while digging).
    *   **CRITICAL DISTINCTION - SPRAYING**:
        *   **Emulsion Spraying (荵ｳ蜑､謨｣蟶・**: Worker holding a **THIN NOZZLE/HOSE** connected to a tank/truck. Liquid spray.
        *   **Curing Sand Spraying (鬢顔函遐よ淵蟶・**: Worker using a **SHOVEL** or **BROAD SPREADER**. Sand cannot be sprayed from a thin nozzle.
        *   *Note*: Do NOT rely solely on surface color (black vs gray) as both can look similar. Look at the **EQUIPMENT**.

3.  **"螳牙・邂｡逅・・逵・**: Signs, cones, morning assembly.
4.  **"菴ｿ逕ｨ譚先侭蜀咏悄"**: Material checks.
5.  **"蜩∬ｳｪ邂｡逅・・逵・**: Thermometers, density meters.
6.  **"蜃ｺ譚･蠖｢邂｡逅・・逵・**: Ribbons/Rulers measuring finished dimensions.

**STEP 2: Traverse & Map Columns**
Traverse the hierarchy directly:
*   **workType**: The key at Level 1 (e.g., "舗装工").
*   **variety**: The key at Level 2 (e.g., "舗装打換え工").
*   **detail**: The key at Level 3 (e.g., "表層工").
*   **remarks**: The key at Level 4 (e.g., "舗設状況", "着手前", "転圧状況").

**STEP 3: Remarks (蛯呵・ Logic**
*   **If Category is "逹謇句燕蜿翫・螳梧・蜀咏悄"**:
    *   **remarks** MUST be either "逹謇句燕" (Before) or "遶｣蟾･" (Completion/Finished).
    *   Do NOT put "逹謇句燕" in the 'detail' or 'variety' columns.
*   **If Category is "譁ｽ蟾･迥ｶ豕∝・逵・**:
    *   Use the Leaf Node Key (e.g., "霆｢蝨ｧ迥ｶ豕・) as the remarks.
    *   Normalize text: "霆｢蝨ｧ荳ｭ" -> "霆｢蝨ｧ迥ｶ豕・.

**STEP 4: Description (險倅ｺ・**
*   If the description would just repeat the remarks or work type, return an empty string "".
*   Only add text if it provides *unique* visual information (e.g., specific machinery names, weather conditions if relevant to quality).

**STEP 5: Station (貂ｬ轤ｹ)**
*   There are two types of station formats:
    1. **Location-based (preferred)**: Location names such as "蟆丞ｱｱ逕ｺ1359莉倩ｿ・, "縲・・ｺ､蟾ｮ轤ｹ莉倩ｿ・, etc.
    2. **Route-based**: Pinpoint markers like "No.0+50", "No.1+23.5", etc.
*   If a location name is visible or can be inferred from the blackboard/surroundings, use that as the station.
*   If only the "No.X+XX" format is visible, extract it exactly.
*   If the station cannot be determined, return an empty string "" (NOT "null", "荳肴・", "unknown", etc.).
*   **Important for road construction**: For lot numbers (地番), use only the main number without sub-lot numbers (枝番). Example: "小山町1359" is correct, "小山町1359-5" is incorrect (too specific for road work spanning multiple lots). Add "付近" or "地先" if appropriate.

**OUTPUT FORMAT**:
JSON only.
keys: workType, variety, detail, station, remarks, description, hasBoard, detectedText.

${customInstruction ? `\nUSER OVERRIDE INSTRUCTION: ${customInstruction}` : ""}
  `.trim();
};



/**
 * セレクターエージェント: 画像群から工種を判定
 * 軽量モデルで高速に工種を特定し、本解析で使う階層サブセットを決定
 */
export const selectWorkTypes = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error' | 'json', details?: any) => void
): Promise<string[]> => {
  const startTime = performance.now();
  const genAI = new GoogleGenAI({ apiKey });

  // サンプル画像を選択（最初と最後、中間から数枚）
  const sampleCount = Math.min(3, records.length);
  const sampleIndices: number[] = [];
  if (records.length <= 3) {
    sampleIndices.push(...records.map((_, i) => i));
  } else {
    sampleIndices.push(0); // 最初
    sampleIndices.push(Math.floor(records.length / 2)); // 中間
    sampleIndices.push(records.length - 1); // 最後
  }

  const samples = sampleIndices.map(i => records[i]);
  const inputs = samples.map(r => ({
    inlineData: {
      data: extractBase64Data(r.base64),
      mimeType: r.mimeType
    }
  }));

  const selectorPrompt = getSelectorPrompt();
  const availableWorkTypes = getWorkTypes();

  const prompt = `
あなたは建設現場の写真を分類する専門家です。
以下の${samples.length}枚のサンプル画像を見て、このバッチに含まれる工種を判定してください。

**利用可能な工種と代表的な備考:**
${selectorPrompt}

**タスク:**
1. 各画像を観察し、どの工種に該当するか判断
2. このバッチ全体で使われている工種のリストを返す

**重要:**
- 複数の工種が混在している場合は全て含める
- 判断できない場合は最も近い工種を選択
- 利用可能な工種: ${availableWorkTypes.join(', ')}

**出力形式 (JSON):**
{ "workTypes": ["舗装工", ...] }
`;

  try {
    const result = await genAI.models.generateContent({
      model: SELECTOR_MODEL,
      contents: [{ role: 'user', parts: [...inputs, { text: prompt }] }],
      config: {
        responseMimeType: "application/json",
        temperature: 0.1
      }
    });

    const text = result.text || "{}";
    const json = JSON.parse(text.replace(/```json/g, '').replace(/```/g, '').trim());
    const selectedTypes = (json.workTypes || []).filter((t: string) => availableWorkTypes.includes(t));

    const elapsed = performance.now() - startTime;
    onLog?.(`[SELECTOR] ${formatDuration(elapsed)}: Selected ${selectedTypes.length} work types: ${selectedTypes.join(', ')}`, 'info');

    // 何も選択されなかった場合はフォールバック
    if (selectedTypes.length === 0) {
      onLog?.('[SELECTOR] No work types selected, using all types', 'info');
      return availableWorkTypes;
    }

    return selectedTypes;
  } catch (e: any) {
    onLog?.(`[SELECTOR] Error: ${e.message}, falling back to all types`, 'error');
    return availableWorkTypes;
  }
};

/**
 * 工種に基づいた階層サブセットを取得
 */
export const getFilteredHierarchy = (workTypes: string[]): object => {
  if (workTypes.length === 0 || workTypes.length === getWorkTypes().length) {
    return formatHierarchyForPrompt();
  }
  return getHierarchySubset(workTypes);
};

export const identifyTargetPhotos = async (
  photos: PhotoRecord[],
  instruction: string,
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error' | 'json', details?: any) => void
): Promise<string[]> => {
  const startTime = performance.now();
  const genAI = new GoogleGenAI({ apiKey });

  const photoSummaries = photos.map(p => ({
    fileName: p.fileName,
    currentAnalysis: p.analysis ? {
      workType: p.analysis.workType,
      remarks: p.analysis.remarks,
      description: p.analysis.description
    } : "Not analyzed"
  }));

  const prompt = `
    User Instruction: "${instruction}"
    
    Given the following list of photos and their current analysis, identify which fileNames should be re-analyzed to satisfy the instruction.
    Return a JSON object with a key "targetFiles" containing an array of strings (fileNames).
    
    Photos:
    ${JSON.stringify(photoSummaries, null, 2)}
  `;

  try {
    const result = await genAI.models.generateContent({
      model: PRIMARY_MODEL, // Use Pro for better logic interpretation
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      config: {
        responseMimeType: "application/json"
      }
    });

    const json = JSON.parse(result.text || "{}");
    const totalTime = performance.now() - startTime;
    onLog?.(`[PROFILER] identifyTargetPhotos: Total=${formatDuration(totalTime)}, Found ${json.targetFiles?.length || 0} targets`, "info");
    return json.targetFiles || [];
  } catch (e) {
    console.error("Identify targets failed", e);
    return [];
  }
};

export const normalizeDataConsistency = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error' | 'json', details?: any) => void
): Promise<PhotoRecord[]> => {
  const completedRecords = records.filter(r => r.status === 'done' && r.analysis);
  if (completedRecords.length === 0) return records;

  const genAI = new GoogleGenAI({ apiKey });

  const dataSnapshot = completedRecords.map(r => ({
    fileName: r.fileName,
    workType: r.analysis!.workType,
    variety: r.analysis!.variety,
    detail: r.analysis!.detail,
    station: r.analysis!.station,
    remarks: r.analysis!.remarks
  }));

  onLog?.("Running consistency normalization pass with Gemini 3 Pro...", "info");

  const prompt = `
    You are a data consistency expert for construction photos.
    Review the following list of records.
    
    TASKS:
    1. **Normalize Station Names (貂ｬ轤ｹ)**: 
       - Fix OCR errors (e.g., "No.0+00" vs "No.0.00" -> unify to "No.X+XX").
       
    2. **Fix Hierarchy Errors**:
       - Ensure "Detail" (邏ｰ蛻･) is NOT a status verb (e.g. "螳御ｺ・, "迥ｶ豕・, "遒ｺ隱・, "謗伜炎", "霆｢蝨ｧ").
       - If "Detail" looks like a status, move it to "Remarks" and clear "Detail".
       - Example: Detail="謗伜炎迥ｶ豕・ -> Change Detail="", Remarks="謗伜炎迥ｶ豕・.

    3. **Normalize Remarks**:
       - Ensure consistent terminology.
    
    INPUT DATA:
    ${JSON.stringify(dataSnapshot, null, 2)}
    
    OUTPUT:
    Return JSON: { "corrections": [ { "fileName": "...", "workType": "...", "variety": "...", "detail": "...", "station": "...", "remarks": "..." } ] }
    Only include records that need changing.
  `;

  let modelToUse = COMPLEX_MODEL;
  let attempt = 0;

  while (attempt < MAX_RETRIES) {
    try {
      const result = await genAI.models.generateContent({
        model: modelToUse,
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        config: {
          responseMimeType: "application/json"
        }
      });

      const text = result.text;
      if (!text) throw new Error("No text response");

      const json = JSON.parse(text);
      onLog?.("Normalization Result Received", "json", json);

      const corrections = json.corrections as { fileName: string, workType?: string, variety?: string, detail?: string, station: string, remarks: string }[];

      if (!corrections || corrections.length === 0) {
        onLog?.("No consistency corrections needed.", "success");
        return records;
      }

      // Apply corrections
      const updatedRecords = records.map(r => {
        const fix = corrections.find(c => c.fileName === r.fileName);
        if (fix && r.analysis) {
          return {
            ...r,
            analysis: {
              ...r.analysis,
              workType: fix.workType !== undefined ? fix.workType : r.analysis.workType,
              variety: fix.variety !== undefined ? fix.variety : r.analysis.variety,
              detail: fix.detail !== undefined ? fix.detail : r.analysis.detail,
              station: fix.station,
              remarks: fix.remarks
            }
          };
        }
        return r;
      });

      onLog?.(`Applied consistency corrections to ${corrections.length} records.`, "success");
      return updatedRecords;

    } catch (e: any) {
      attempt++;
      onLog?.(`Normalization Error (${modelToUse}) - ${attempt}/${MAX_RETRIES}`, "error", e.message);

      if (attempt < MAX_RETRIES) {
        modelToUse = PRIMARY_MODEL;
        await sleep(RETRY_DELAY_MS);
      } else {
        onLog?.("Normalization failed (Non-fatal)", "error");
        return records;
      }
    }
  }
  return records;
};

/**
 * NEW: Visual Anchoring & Clustering
 * Instead of opaque IDs, we generate specific descriptions of background anchors.
 */
/**
 * NEW: Visual Anchoring & Clustering
 * Optimized to use cache for visual feature extraction.
 */
export const assignSceneIds = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error' | 'json', details?: any) => void
): Promise<{ fileName: string, sceneId: string, phase: 'before' | 'after' | 'status', visualAnchors: string }[]> => {

  const genAI = new GoogleGenAI({ apiKey });

  // Step 1: Feature Extraction (Visual Anchors)
  // Only run for photos that don't have visualAnchors yet.
  const needsExtraction = records.filter(r => !r.analysis?.visualAnchors);
  const cachedFeatures = records.filter(r => r.analysis?.visualAnchors).map(r => ({
    fileName: r.fileName,
    visualAnchors: r.analysis!.visualAnchors!,
    phase: r.analysis!.phase || 'status'
  }));

  let newFeatures: { fileName: string, visualAnchors: string, phase: 'before' | 'after' | 'status' }[] = [];

  if (needsExtraction.length > 0) {
    onLog?.(`Extracting visual features for ${needsExtraction.length} new photos...`, 'info');

    // Process in batches of 5 to avoid payload limits
    const BATCH_SIZE = 5;
    for (let i = 0; i < needsExtraction.length; i += BATCH_SIZE) {
      const batch = needsExtraction.slice(i, i + BATCH_SIZE);

      const inputs = batch.map(r => ({
        fileName: r.fileName,
        image: {
          inlineData: {
            data: extractBase64Data(r.base64),
            mimeType: r.mimeType
          }
        }
      }));

      const promptParts: any[] = [];
      promptParts.push({
        text: `
        蜷・・逵溘・縲瑚レ譎ｯ縺ｮ迚ｹ蠕ｴ(visualAnchors)縲阪→縲悟ｷ･莠区ｮｵ髫・phase)縲阪ｒ謚ｽ蜃ｺ縺励※縺上□縺輔＞縲・        
        **繧ｿ繧ｹ繧ｯ1: 閭梧勹縺ｮ迚ｹ蠕ｴ (visualAnchors)**
        - 蝣ｴ謇繧堤音螳壹☆繧九◆繧√・諱剃ｹ・噪縺ｪ迚ｹ蠕ｴ繧定ｨ倩ｿｰ・亥ｻｺ迚ｩ縲・崕譟ｱ縲∝ｱｱ縲・％霍ｯ蠖｢迥ｶ縺ｪ縺ｩ・峨・        - 蜿ｯ螟芽ｦ∫ｴ・郁ｻ翫∽ｺｺ縲∝､ｩ豌暦ｼ峨・髯､螟悶・        - 邁｡貎斐↓・井ｾ具ｼ壹悟ｷｦ縺ｫ逋ｽ縺・ｮｶ縲∝･･縺ｫ襍､縺・恚譚ｿ縲搾ｼ峨・
        **繧ｿ繧ｹ繧ｯ2: 蟾･莠区ｮｵ髫・(phase)**
        - "before": 逹謇句燕・域悴闊苓｣・∝商縺・・陬・・尅闕会ｼ・        - "after": 螳御ｺ・ｾ鯉ｼ域眠縺励＞繧｢繧ｹ繝輔ぃ繝ｫ繝医√″繧後＞縺ｪ逋ｽ邱夲ｼ・        - "status": 譁ｽ蟾･荳ｭ・磯㍾讖溘∽ｽ懈･ｭ蜩｡縲∵侍蜑贋ｸｭ・・
        **蜃ｺ蜉帛ｽ｢蠑・*:
        {
          "features": [
            { "fileName": "...", "visualAnchors": "...", "phase": "..." }
          ]
        }
      `});

      inputs.forEach(input => {
        promptParts.push(input.image);
        promptParts.push({ text: `[${input.fileName}]\n` });
      });

      try {
        const result = await genAI.models.generateContent({
          model: COMPLEX_MODEL,
          contents: [{ role: 'user', parts: promptParts }],
          config: { responseMimeType: "application/json" }
        });

        const text = result.text || "{}";
        const json = JSON.parse(text.replace(/```json/g, '').replace(/```/g, '').trim());
        if (json.features) {
          newFeatures = [...newFeatures, ...json.features];
        }
      } catch (e: any) {
        onLog?.(`Feature extraction failed for batch ${i}`, 'error', e.message);
      }
    }
  } else {
    onLog?.("Using cached visual features for all photos.", 'success');
  }

  const allFeatures = [...cachedFeatures, ...newFeatures];

  // Step 2: Clustering (Text-only)
  // Group photos based on visualAnchors descriptions.
  if (allFeatures.length === 0) return [];

  onLog?.(`Clustering ${allFeatures.length} photos based on visual anchors...`, 'info');

  const clusteringPrompt = `
    莉･荳九・蜀咏悄繝ｪ繧ｹ繝医ｒ縲∬レ譎ｯ縺ｮ迚ｹ蠕ｴ(visualAnchors)縺ｫ蝓ｺ縺･縺・※謦ｮ蠖ｱ蝣ｴ謇縺斐→縺ｫ繧ｰ繝ｫ繝ｼ繝怜喧縺励※縺上□縺輔＞縲・    
    **繝ｫ繝ｼ繝ｫ**:
    - 迚ｹ蠕ｴ縺御ｼｼ縺ｦ縺・ｋ蜀咏悄縺ｯ蜷後§蝣ｴ謇(sceneId)縺ｨ縺吶ｋ縲・    - sceneId縺ｯ "S1", "S2" 縺ｮ繧医≧縺ｫ騾｣逡ｪ繧呈険繧九・    - phase (before/after/status) 縺ｯ蜈･蜉帛､繧偵◎縺ｮ縺ｾ縺ｾ菫晄戟縺吶ｋ縲・
    **蜈･蜉帙ョ繝ｼ繧ｿ**:
    ${JSON.stringify(allFeatures, null, 2)}

    **蜃ｺ蜉帛ｽ｢蠑・*:
    {
      "assignments": [
        { "fileName": "...", "sceneId": "...", "phase": "...", "visualAnchors": "..." }
      ]
    }
  `;

  try {
    const result = await genAI.models.generateContent({
      model: PRIMARY_MODEL, // Text-only is fast and cheap
      contents: [{ role: 'user', parts: [{ text: clusteringPrompt }] }],
      config: { responseMimeType: "application/json" }
    });

    const text = result.text || "{}";
    const json = JSON.parse(text.replace(/```json/g, '').replace(/```/g, '').trim());
    return json.assignments || [];

  } catch (e: any) {
    onLog?.("Clustering failed.", 'error', e.message);
    // Fallback: Return features as is with unique IDs
    return allFeatures.map((f, i) => ({
      fileName: f.fileName,
      visualAnchors: f.visualAnchors,
      phase: (f.phase === 'unknown' ? 'status' : f.phase) as 'before' | 'after' | 'status',
      sceneId: `S${i}`
    }));
  }
};

// Deprecated old sorting function, kept as stub if needed or removed
export const sortPhotosByScene = async () => [];

export const refinePairContext = async (
  sortedRecords: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error' | 'json', details?: any) => void
): Promise<PhotoRecord[]> => {
  // Logic remains similar but now relies on Scene IDs if available
  // For now, we trust the "Phase" from assignSceneIds more.
  return sortedRecords;
};

export const analyzePhotoBatch = async (
  records: PhotoRecord[],
  instruction: string,
  batchSize: number,
  appMode: AppMode,
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error' | 'json', details?: any) => void,
  onIndividualResult?: (fileName: string, result: AIAnalysisResult) => void,
  shouldAbort?: () => boolean,
  onReasoningStream?: (text: string) => void
): Promise<AIAnalysisResult[]> => {
  const batchStartTime = performance.now();
  const genAI = new GoogleGenAI({ apiKey });

  onLog?.(`[PROFILER] Batch start: ${records.length} photos, model=${PRIMARY_MODEL}`, "info");

  // Use selector to determine work types (only for construction mode)
  let filteredHierarchy: object | undefined;
  if (appMode === 'construction' && records.length >= 3) {
    const selectorStart = performance.now();
    const selectedWorkTypes = await selectWorkTypes(records, apiKey, onLog);
    filteredHierarchy = getFilteredHierarchy(selectedWorkTypes);
    const selectorTime = performance.now() - selectorStart;
    const fullSize = JSON.stringify(formatHierarchyForPrompt()).length;
    const filteredSize = JSON.stringify(filteredHierarchy).length;
    onLog?.(`[PROFILER] Selector: ${formatDuration(selectorTime)}, hierarchy ${fullSize} -> ${filteredSize} chars (${((1 - filteredSize/fullSize) * 100).toFixed(1)}% reduction)`, "info");
  }

  const prepStartTime = performance.now();
  const inputs = records.map(r => ({
    inlineData: {
      data: extractBase64Data(r.base64),
      mimeType: r.mimeType
    }
  }));
  const prepTime = performance.now() - prepStartTime;
  onLog?.(`[PROFILER] Image prep: ${formatDuration(prepTime)}`, "info");

  const systemPrompt = getSystemInstruction(appMode, instruction, filteredHierarchy);

  // Context relay: Build context hint from previously analyzed photos in this batch
  let contextHint = "";
  const previousResults: AIAnalysisResult[] = [];

  // We'll update this as we process, for now initialize empty

  const prompt = `
    Analyze these ${records.length} photos.
    For each photo, output the JSON object matching the schema.
    Order must match the input order.
    
    **CONTEXT RELAY**: If you cannot clearly determine the station (貂ｬ轤ｹ) or variety (遞ｮ蛻･) from a photo, 
    but the previous photo had these values and the current photo appears to be from the same location/work type,
    you may inherit those values. However, always prioritize explicit information visible in the current photo.
    
    Photo FileNames for reference:
    ${records.map(r => r.fileName).join(", ")}
  `;

  const schema: Schema = {
    type: Type.ARRAY,
    items: {
      type: Type.OBJECT,
      properties: {
        fileName: { type: Type.STRING },
        workType: { type: Type.STRING },
        variety: { type: Type.STRING },
        detail: { type: Type.STRING },
        station: { type: Type.STRING },
        remarks: { type: Type.STRING },
        description: { type: Type.STRING },
        hasBoard: { type: Type.BOOLEAN },
        detectedText: { type: Type.STRING }
      },
      required: ["fileName", "workType", "station", "description"]
    }
  };

  let attempt = 0;
  let modelToUse = PRIMARY_MODEL;

  while (attempt < MAX_RETRIES) {
    // Check if analysis should be aborted
    if (shouldAbort?.()) {
      onLog?.("Analysis aborted by user", "info");
      throw new Error("Analysis aborted by user");
    }

    try {
      // Use streaming to capture "reasoning" or partial output if possible
      // But for JSON mode, standard generation is safer. 
      // However, to get "reasoning", we need to ask for it in the prompt and parse it.
      // We will switch to generateContentStream to capture text as it comes in.

      const apiStartTime = performance.now();
      let firstChunkTime: number | null = null;

      const result = await genAI.models.generateContentStream({
        model: modelToUse,
        contents: [
          { role: 'user', parts: [...inputs, { text: prompt }] }
        ],
        config: {
          systemInstruction: systemPrompt,
          responseMimeType: "application/json",
          responseSchema: schema,
          temperature: 0.1
        }
      });

      let fullText = "";
      let chunkCount = 0;
      for await (const chunk of result) {
        if (firstChunkTime === null) {
          firstChunkTime = performance.now() - apiStartTime;
          onLog?.(`[PROFILER] Time to first chunk: ${formatDuration(firstChunkTime)}`, "info");
        }
        chunkCount++;
        const chunkText = chunk.text;
        fullText += chunkText;

        // Try to extract "reasoning" from the partial JSON if it exists
        if (onReasoningStream) {
          // Look for "reasoning": "..." pattern
          const match = fullText.match(/"reasoning"\s*:\s*"([^"]*)/);
          if (match && match[1]) {
            onReasoningStream(match[1]);
          }
        }
      }

      const apiTime = performance.now() - apiStartTime;
      onLog?.(`[PROFILER] API stream complete: ${formatDuration(apiTime)} (${chunkCount} chunks, ${fullText.length} chars)`, "info");

      const text = fullText;

      onLog?.("Gemini Raw Response", 'json', text);

      const parseStartTime = performance.now();
      let parsed: any;
      try {
        parsed = JSON.parse(text);
      } catch (e) {
        // Fallback: try to find JSON array in text
        const match = text.match(/\[.*\]/s);
        if (match) {
          parsed = JSON.parse(match[0]);
        } else {
          throw new Error("Invalid JSON response from AI");
        }
      }

      const parseTime = performance.now() - parseStartTime;

      if (!Array.isArray(parsed)) {
        // If single object, wrap in array
        parsed = [parsed];
      }

      // Validate against schema-ish
      const validResults: AIAnalysisResult[] = parsed.map((item: any) => ({
        fileName: item.fileName || "unknown",
        workType: item.workType || "",
        variety: item.variety || "",
        detail: item.detail || "",
        station: item.station || "",
        remarks: item.remarks || "",
        description: item.description || "",
        hasBoard: !!item.hasBoard,
        detectedText: item.detectedText || "",
        reasoning: item.reasoning || "" // Capture reasoning
      }));

      // Log individual results
      validResults.forEach(res => {
        onIndividualResult?.(res.fileName, res);
      });

      // Apply context relay: inherit station, variety, and workType from previous photos
      // This ensures continuity across sequential photos (e.g., 譛ｪ闊苓｣・Κ闊苓｣・ｷ･ persists)
      let lastKnownStation = "";
      let lastKnownVariety = "";
      let lastKnownWorkType = "";
      const finalResults = validResults.map((res, idx) => {
        const targetRecord = records[idx];

        // Apply context relay for empty fields
        const station = res.station || lastKnownStation;
        const variety = res.variety || lastKnownVariety;
        const workType = res.workType || lastKnownWorkType;

        // Update context for next iteration
        if (res.station) lastKnownStation = res.station;
        if (res.variety) lastKnownVariety = res.variety;
        if (res.workType) lastKnownWorkType = res.workType;

        // Ensure fileName is from the original record to maintain order and correctness
        return { ...res, station, variety, workType, fileName: targetRecord.fileName };
      });

      const totalTime = performance.now() - batchStartTime;
      const perPhotoTime = totalTime / records.length;
      onLog?.(`[PROFILER] Batch complete: Total=${formatDuration(totalTime)}, Per photo=${formatDuration(perPhotoTime)}, Parse=${formatDuration(parseTime)}`, "success");

      return finalResults;

    } catch (error: any) {
      attempt++;
      const isQuotaError = error.message?.includes("429") || error.status === 429 || error.status === 503;

      onLog?.(`API Error (${modelToUse}) - Attempt ${attempt}/${MAX_RETRIES}`, "error", { message: error.message });

      if (attempt >= MAX_RETRIES) {
        throw error;
      }

      if (isQuotaError) {
        if (modelToUse === PRIMARY_MODEL) {
          modelToUse = FALLBACK_MODEL;
          onLog?.(`Rate Limit hit. Switching to Fallback Model: ${FALLBACK_MODEL}`, "info");
          await sleep(RETRY_DELAY_MS);
        } else {
          await sleep(RETRY_DELAY_MS * 2);
        }
      } else {
        await sleep(RETRY_DELAY_MS);
      }
    }
  }

  throw new Error("Max retries exceeded");
};


//===============================================================================
// FILE: services/spatialPairingService.ts
//===============================================================================
import { GoogleGenAI } from "@google/genai";
import { PhotoRecord } from "../types";
import { extractBase64Data } from "../utils/imageUtils";

const PRIMARY_MODEL = "gemini-3-pro-preview"; // 高精度モデルを使用

/**
 * 座標ベースの景観要素抽出とペアリングサービス
 * より厳密な空間的特徴の一致を判定
 */

interface LandmarkFeature {
  type: 'building' | 'pole' | 'sign' | 'fence' | 'wall' | 'tree' | 'road_edge';
  position: {
    x: number;  // 0-100 (左端を0、右端を100とする相対座標)
    y: number;  // 0-100 (上端を0、下端を100とする相対座標)
  };
  size: {
    width: number;  // 0-100 (画像幅に対する相対サイズ)
    height: number; // 0-100 (画像高さに対する相対サイズ)
  };
  description: string;
  confidence: number;
}

interface SpatialAnalysis {
  fileName: string;
  landmarks: LandmarkFeature[];
  viewpoint: {
    direction: 'north' | 'south' | 'east' | 'west' | 'unknown';
    elevation: 'ground' | 'elevated' | 'aerial';
    fov: 'narrow' | 'normal' | 'wide'; // 視野角
  };
  groundCondition: 'unpaved' | 'paved' | 'under_construction';
  signature: string; // 空間的特徴のハッシュ値
}

/**
 * 座標ベースで景観要素を抽出
 */
export const extractSpatialFeatures = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<SpatialAnalysis[]> => {

  const genAI = new GoogleGenAI({ apiKey });
  onLog?.('座標ベースの景観要素を抽出中...', 'info');

  const inputs = records.map(r => ({
    fileName: r.fileName,
    image: {
      inlineData: {
        data: extractBase64Data(r.base64),
        mimeType: r.mimeType
      }
    }
  }));

  const prompt = `
あなたは建設現場の定点撮影写真の空間解析の専門家です。

各写真について、固定された景観要素（ランドマーク）を座標ベースで正確に抽出してください。

【重要な指示】
1. 画像を100x100のグリッドとして扱い、各要素の位置を座標で表現
2. 恒久的な構造物のみを抽出（一時的な物は除外）
3. 同じ場所から撮影された写真は、ランドマークの座標がほぼ一致するはず

【抽出する要素】
- 建物（屋根の形状、色、窓の配置も記録）
- 電柱・電線（位置と本数）
- 標識・看板
- フェンス・塀（材質と高さ）
- 擁壁・段差
- 道路の縁石
- 特徴的な樹木

【地面状態の判定（重要）】
- "unpaved": 未舗装（砂利、土、雑草、ひび割れたアスファルト）
- "paved": 舗装完了（新しいアスファルト、きれいな白線）
- "under_construction": 工事中間状態
  * 瀝青安定処理路盤工の完成状態（灰色の砂で一様に覆われている）
  * 下地処理完了状態
  * 中間舗装層

重要: 路面が一様に灰色の砂や砕石で覆われている場合は "under_construction" と判定してください。

【出力形式（JSON）】
{
  "analyses": [
    {
      "fileName": "xxx.jpg",
      "landmarks": [
        {
          "type": "building/pole/sign/fence/wall/tree/road_edge",
          "position": {"x": 0-100, "y": 0-100},
          "size": {"width": 0-100, "height": 0-100},
          "description": "詳細な説明（例：青い屋根の2階建て住宅）",
          "confidence": 0.0-1.0
        }
      ],
      "viewpoint": {
        "direction": "推定される撮影方向",
        "elevation": "ground/elevated",
        "fov": "narrow/normal/wide"
      },
      "groundCondition": "unpaved/paved/under_construction",
      "signature": "ランドマークの配置を表す一意の文字列"
    }
  ]
}

【座標の例】
- 左端の電柱: x=10, y=20
- 中央の建物: x=50, y=30, width=30, height=40
- 右端のフェンス: x=85, y=50

必ず各要素の正確な座標を記録してください。
`;

  const parts: any[] = [{ text: prompt }];
  inputs.forEach(input => {
    parts.push(input.image);
    parts.push({ text: `[${input.fileName}]\n` });
  });

  try {
    const result = await genAI.models.generateContent({
      model: PRIMARY_MODEL,
      contents: [{ role: 'user', parts }],
      config: {
        responseMimeType: "application/json",
        temperature: 0.1 // 低温度で一貫性を保つ
      }
    });

    const response = JSON.parse(result.text);
    onLog?.(`${response.analyses.length}枚の写真から空間特徴を抽出しました`, 'success');
    return response.analyses;

  } catch (error: any) {
    onLog?.('空間特徴の抽出に失敗しました', 'error');
    throw error;
  }
};

/**
 * 空間的特徴の類似度を計算
 */
const calculateSpatialSimilarity = (
  analysis1: SpatialAnalysis,
  analysis2: SpatialAnalysis
): number => {

  let totalScore = 0;
  let matchedLandmarks = 0;

  // 各ランドマークについて最も近いものを探す
  analysis1.landmarks.forEach(landmark1 => {
    let minDistance = Infinity;
    let bestMatch: LandmarkFeature | null = null;

    analysis2.landmarks.forEach(landmark2 => {
      // 同じタイプのランドマークのみ比較
      if (landmark1.type === landmark2.type) {
        // ユークリッド距離を計算
        const distance = Math.sqrt(
          Math.pow(landmark1.position.x - landmark2.position.x, 2) +
          Math.pow(landmark1.position.y - landmark2.position.y, 2)
        );

        if (distance < minDistance) {
          minDistance = distance;
          bestMatch = landmark2;
        }
      }
    });

    // 距離が15以内なら同じランドマークと見なす（画角の変化を考慮）
    if (bestMatch && minDistance < 15) {
      matchedLandmarks++;
      // サイズの類似度も考慮（より寛容に）
      const sizeSimilarity = 1 - (
        Math.abs(landmark1.size.width - bestMatch.size.width) +
        Math.abs(landmark1.size.height - bestMatch.size.height)
      ) / 300; // 200から300に緩和
      totalScore += sizeSimilarity;
    }
  });

  // ランドマークの一致率を計算（平均値を使用してより寛容に）
  const avgLandmarks = (analysis1.landmarks.length + analysis2.landmarks.length) / 2;
  const matchRate = matchedLandmarks / avgLandmarks;

  // 視点の一致も考慮（重要度を下げる）
  const viewpointMatch =
    analysis1.viewpoint.direction === analysis2.viewpoint.direction ? 0.1 : 0;

  // 基本スコアを高めに設定
  return Math.min(1.0, matchRate * 0.9 + viewpointMatch);
};

/**
 * 座標ベースのペアリング
 */
export const createSpatialPairs = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<Array<{
  before: PhotoRecord,
  after: PhotoRecord,
  similarity: number,
  matchedLandmarks: string[]
}>> => {

  // 1. 空間特徴を抽出
  const analyses = await extractSpatialFeatures(records, apiKey, onLog);

  // 2. 分析結果をレコードにマッピング
  const analyzedRecords = records.map(record => {
    const analysis = analyses.find(a => a.fileName === record.fileName);
    return { record, analysis };
  }).filter(item => item.analysis !== undefined);

  // 3. 類似度行列を作成
  const similarityMatrix: number[][] = [];
  for (let i = 0; i < analyzedRecords.length; i++) {
    similarityMatrix[i] = [];
    for (let j = 0; j < analyzedRecords.length; j++) {
      if (i === j) {
        similarityMatrix[i][j] = 0;
      } else {
        similarityMatrix[i][j] = calculateSpatialSimilarity(
          analyzedRecords[i].analysis!,
          analyzedRecords[j].analysis!
        );
      }
    }
  }

  // 4. 類似度の高いペアをグループ化
  const groups: number[][] = [];
  const used = new Set<number>();

  for (let i = 0; i < analyzedRecords.length; i++) {
    if (used.has(i)) continue;

    const group = [i];
    used.add(i);

    for (let j = i + 1; j < analyzedRecords.length; j++) {
      if (used.has(j)) continue;

      // 類似度が0.6以上なら同じグループ（画角の変化を許容）
      if (similarityMatrix[i][j] > 0.6) {
        group.push(j);
        used.add(j);
      }
    }

    if (group.length >= 2) {
      groups.push(group);
    }
  }

  // 5. 各グループからペアを作成
  const pairs: Array<{
    before: PhotoRecord,
    after: PhotoRecord,
    similarity: number,
    matchedLandmarks: string[]
  }> = [];

  groups.forEach((group, groupIndex) => {
    const groupRecords = group.map(idx => analyzedRecords[idx]);

    // 日付でソート（古い順）
    groupRecords.sort((a, b) => (a.record.date || 0) - (b.record.date || 0));

    // 地面の状態で分類
    const unpaved = groupRecords.filter(r =>
      r.analysis?.groundCondition === 'unpaved'
    );
    const paved = groupRecords.filter(r =>
      r.analysis?.groundCondition === 'paved'
    );
    const underConstruction = groupRecords.filter(r =>
      r.analysis?.groundCondition === 'under_construction'
    );

    let beforeRecord: typeof groupRecords[0] | null = null;
    let afterRecord: typeof groupRecords[0] | null = null;

    // ケース1: unpaved と paved が明確に分かれている場合
    if (unpaved.length > 0 && paved.length > 0) {
      beforeRecord = unpaved[0];
      afterRecord = paved[paved.length - 1];
    }
    // ケース2: unpaved と under_construction の組み合わせ
    // （瀝青安定処理など、中間的な完成状態）
    else if (unpaved.length > 0 && underConstruction.length > 0) {
      beforeRecord = unpaved[0];
      afterRecord = underConstruction[underConstruction.length - 1];
    }
    // ケース3: under_construction と paved の組み合わせ
    else if (underConstruction.length > 0 && paved.length > 0) {
      beforeRecord = underConstruction[0];
      afterRecord = paved[paved.length - 1];
    }
    // ケース4: 地面状態による分類が失敗した場合のフォールバック
    // 単純に最初と最後をペアにする
    else if (groupRecords.length >= 2) {
      beforeRecord = groupRecords[0];
      afterRecord = groupRecords[groupRecords.length - 1];
      onLog?.(`警告: グループ${groupIndex + 1}は地面状態で分類できないため、日付で分割しました`, 'error');
    }

    if (beforeRecord && afterRecord && beforeRecord !== afterRecord) {
      // マッチしたランドマークのリスト
      const matchedLandmarks: string[] = [];
      beforeRecord.analysis?.landmarks.forEach(landmark => {
        afterRecord!.analysis?.landmarks.forEach(landmark2 => {
          if (landmark.type === landmark2.type) {
            const distance = Math.sqrt(
              Math.pow(landmark.position.x - landmark2.position.x, 2) +
              Math.pow(landmark.position.y - landmark2.position.y, 2)
            );
            if (distance < 15) {
              matchedLandmarks.push(
                `${landmark.type}: ${landmark.description} (座標: ${landmark.position.x}, ${landmark.position.y})`
              );
            }
          }
        });
      });

      pairs.push({
        before: beforeRecord.record,
        after: afterRecord.record,
        similarity: similarityMatrix[
          analyzedRecords.indexOf(beforeRecord)
        ][analyzedRecords.indexOf(afterRecord)],
        matchedLandmarks
      });
    }
  });

  onLog?.(`${pairs.length}組の空間的に一致するペアを作成しました`, 'success');

  // デバッグ情報を出力
  pairs.forEach((pair, idx) => {
    onLog?.(`ペア${idx + 1}: 類似度${(pair.similarity * 100).toFixed(1)}%`, 'info');
    pair.matchedLandmarks.forEach(landmark => {
      onLog?.(`  - ${landmark}`, 'info');
    });
  });

  return pairs;
};

//===============================================================================
// FILE: services/optimizedSpatialPairingService.ts
//===============================================================================
import { GoogleGenAI } from "@google/genai";
import { PhotoRecord } from "../types";
import { extractBase64Data } from "../utils/imageUtils";

const PRIMARY_MODEL = "gemini-3-pro-preview";
const FAST_MODEL = "gemini-1.5-flash"; // 高速モデル

/**
 * 最適化された景観ペアリングサービス
 * 高速化のための改善:
 * 1. バッチ処理の最適化
 * 2. 並列処理の活用
 * 3. キャッシュの活用
 * 4. 軽量モデルでの前処理
 */

interface LandmarkFeature {
  type: 'building' | 'pole' | 'sign' | 'fence' | 'wall' | 'tree' | 'road_edge';
  position: { x: number; y: number };
  size: { width: number; height: number };
  description: string;
  confidence: number;
}

interface SpatialAnalysis {
  fileName: string;
  landmarks: LandmarkFeature[];
  viewpoint: {
    direction: 'north' | 'south' | 'east' | 'west' | 'unknown';
    elevation: 'ground' | 'elevated' | 'aerial';
    fov: 'narrow' | 'normal' | 'wide';
  };
  groundCondition: 'unpaved' | 'paved' | 'under_construction';
  signature: string;
  cachedHash?: string; // キャッシュ用のハッシュ
}

// グローバルキャッシュ（セッション中は維持）
const spatialCache = new Map<string, SpatialAnalysis>();

/**
 * ファイルからハッシュを生成（キャッシュキー用）
 */
const generateFileHash = (fileName: string, base64: string): string => {
  // ファイル名とbase64の最初の100文字でハッシュ生成（簡易版）
  return `${fileName}_${base64.substring(0, 100).replace(/[^a-zA-Z0-9]/g, '')}`;
};

/**
 * 高速な前処理（軽量モデルで基本分類）
 */
const quickClassifyImages = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<Map<string, 'before' | 'after' | 'unknown'>> => {

  const genAI = new GoogleGenAI({ apiKey });
  const classification = new Map<string, 'before' | 'after' | 'unknown'>();

  // ファイル名から推測できるものは即座に分類
  records.forEach(record => {
    if (record.fileName.toLowerCase().includes('before') ||
        record.fileName.toLowerCase().includes('着手前')) {
      classification.set(record.fileName, 'before');
    } else if (record.fileName.toLowerCase().includes('after') ||
               record.fileName.toLowerCase().includes('竣工') ||
               record.fileName.toLowerCase().includes('完了')) {
      classification.set(record.fileName, 'after');
    }
  });

  // 未分類の画像のみAIで判定（軽量モデル使用）
  const unclassified = records.filter(r => !classification.has(r.fileName));

  if (unclassified.length > 0) {
    onLog?.(`${unclassified.length}枚を高速分類中...`, 'info');

    const prompt = `
写真のファイル名と内容から着手前/竣工を判定してください。
簡潔にJSON形式で回答:
{
  "classifications": {
    "ファイル名": "before|after|unknown"
  }
}`;

    const parts: any[] = [{ text: prompt }];
    unclassified.slice(0, 5).forEach(record => { // 最大5枚ずつ処理
      parts.push({
        inlineData: {
          data: extractBase64Data(record.base64),
          mimeType: record.mimeType
        }
      });
      parts.push({ text: record.fileName });
    });

    try {
      const result = await genAI.models.generateContent({
        model: FAST_MODEL, // 軽量モデル使用
        contents: [{ role: 'user', parts }],
        config: {
          responseMimeType: "application/json",
          temperature: 0.1,
          maxOutputTokens: 1000 // 出力を制限
        }
      });

      const response = JSON.parse(result.text);
      Object.entries(response.classifications).forEach(([fileName, type]) => {
        classification.set(fileName, type as 'before' | 'after' | 'unknown');
      });
    } catch (error) {
      onLog?.('高速分類に失敗、詳細分析にフォールバック', 'error');
    }
  }

  return classification;
};

/**
 * 並列バッチ処理で空間特徴を抽出
 */
export const extractSpatialFeaturesOptimized = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<SpatialAnalysis[]> => {

  const genAI = new GoogleGenAI({ apiKey });
  const analyses: SpatialAnalysis[] = [];

  // キャッシュチェック
  const uncachedRecords: PhotoRecord[] = [];
  records.forEach(record => {
    const hash = generateFileHash(record.fileName, record.base64);
    if (spatialCache.has(hash)) {
      analyses.push(spatialCache.get(hash)!);
      onLog?.(`${record.fileName} はキャッシュから取得`, 'info');
    } else {
      uncachedRecords.push(record);
    }
  });

  if (uncachedRecords.length === 0) {
    onLog?.('すべてキャッシュから取得しました', 'success');
    return analyses;
  }

  onLog?.(`${uncachedRecords.length}枚の空間特徴を抽出中...`, 'info');

  // バッチサイズを最適化（大きすぎるとタイムアウト、小さすぎると遅い）
  const OPTIMAL_BATCH_SIZE = 4;
  const batches = [];
  for (let i = 0; i < uncachedRecords.length; i += OPTIMAL_BATCH_SIZE) {
    batches.push(uncachedRecords.slice(i, i + OPTIMAL_BATCH_SIZE));
  }

  // 簡略化されたプロンプト（必要最小限の情報のみ要求）
  const prompt = `
建設現場写真の空間解析。各写真の主要ランドマーク（建物、電柱、フェンス等）の座標と地面状態を抽出。

出力JSON:
{
  "analyses": [
    {
      "fileName": "xxx.jpg",
      "landmarks": [
        {
          "type": "building|pole|fence|wall",
          "position": {"x": 0-100, "y": 0-100},
          "size": {"width": 10, "height": 10},
          "description": "簡潔な説明",
          "confidence": 0.8
        }
      ],
      "groundCondition": "unpaved|paved|under_construction",
      "signature": "L1B2F3"
    }
  ]
}`;

  // 各バッチを並列処理
  const batchPromises = batches.map(async (batch, batchIndex) => {
    const parts: any[] = [{ text: prompt }];
    batch.forEach(record => {
      parts.push({
        inlineData: {
          data: extractBase64Data(record.base64),
          mimeType: record.mimeType
        }
      });
      parts.push({ text: `[${record.fileName}]` });
    });

    try {
      const result = await genAI.models.generateContent({
        model: PRIMARY_MODEL,
        contents: [{ role: 'user', parts }],
        config: {
          responseMimeType: "application/json",
          temperature: 0.1,
          maxOutputTokens: 2000 // 出力トークンを制限
        }
      });

      const response = JSON.parse(result.text);

      // キャッシュに保存
      response.analyses.forEach((analysis: SpatialAnalysis) => {
        const record = batch.find(r => r.fileName === analysis.fileName);
        if (record) {
          const hash = generateFileHash(record.fileName, record.base64);
          analysis.cachedHash = hash;
          spatialCache.set(hash, analysis);
        }
      });

      onLog?.(`バッチ${batchIndex + 1}/${batches.length}完了`, 'info');
      return response.analyses;

    } catch (error: any) {
      onLog?.(`バッチ${batchIndex + 1}失敗: ${error.message}`, 'error');
      return [];
    }
  });

  // すべてのバッチの結果を待つ
  const batchResults = await Promise.all(batchPromises);
  const newAnalyses = batchResults.flat();

  onLog?.(`${newAnalyses.length}枚の空間特徴を抽出完了`, 'success');
  return [...analyses, ...newAnalyses];
};

/**
 * 高速な類似度計算（簡略化版）
 */
const calculateSpatialSimilarityFast = (
  analysis1: SpatialAnalysis,
  analysis2: SpatialAnalysis
): number => {

  // 地面状態が同じ場合は低スコア
  if (analysis1.groundCondition === analysis2.groundCondition) {
    return 0.2;
  }

  let matchedCount = 0;
  const maxDistance = 15; // 許容距離

  // より高速な比較アルゴリズム
  const landmarks2Map = new Map<string, LandmarkFeature[]>();
  analysis2.landmarks.forEach(lm => {
    if (!landmarks2Map.has(lm.type)) {
      landmarks2Map.set(lm.type, []);
    }
    landmarks2Map.get(lm.type)!.push(lm);
  });

  analysis1.landmarks.forEach(lm1 => {
    const candidates = landmarks2Map.get(lm1.type) || [];
    for (const lm2 of candidates) {
      const distance = Math.sqrt(
        Math.pow(lm1.position.x - lm2.position.x, 2) +
        Math.pow(lm1.position.y - lm2.position.y, 2)
      );
      if (distance < maxDistance) {
        matchedCount++;
        break; // 最初の一致で次へ
      }
    }
  });

  const avgLandmarks = (analysis1.landmarks.length + analysis2.landmarks.length) / 2;
  return avgLandmarks > 0 ? matchedCount / avgLandmarks : 0;
};

/**
 * 最適化されたペアリング
 */
export const createSpatialPairsOptimized = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<Array<{
  before: PhotoRecord,
  after: PhotoRecord,
  similarity: number,
  matchedLandmarks: string[]
}>> => {

  // 1. 高速前処理
  const quickClassification = await quickClassifyImages(records, apiKey, onLog);

  // 2. 明らかなbefore/afterグループ分け
  const likelyBefore = records.filter(r =>
    quickClassification.get(r.fileName) === 'before' ||
    r.fileName.match(/^\d{8}_\d{6}/)); // 日付形式は着手前の可能性大

  const likelyAfter = records.filter(r =>
    quickClassification.get(r.fileName) === 'after' ||
    r.fileName.match(/^P\d{7}/)); // P番号は竣工の可能性大

  // 3. 空間特徴を並列抽出
  const [beforeAnalyses, afterAnalyses] = await Promise.all([
    extractSpatialFeaturesOptimized(likelyBefore, apiKey, onLog),
    extractSpatialFeaturesOptimized(likelyAfter, apiKey, onLog)
  ]);

  // 4. 高速ペアリング
  const pairs: Array<{
    before: PhotoRecord,
    after: PhotoRecord,
    similarity: number,
    matchedLandmarks: string[]
  }> = [];

  const used = new Set<string>();

  beforeAnalyses.forEach((beforeAnalysis, beforeIdx) => {
    let bestMatch: { analysis: SpatialAnalysis, record: PhotoRecord, similarity: number } | null = null;

    afterAnalyses.forEach((afterAnalysis, afterIdx) => {
      if (used.has(afterAnalysis.fileName)) return;

      const similarity = calculateSpatialSimilarityFast(beforeAnalysis, afterAnalysis);

      if (similarity > 0.6 && (!bestMatch || similarity > bestMatch.similarity)) {
        bestMatch = {
          analysis: afterAnalysis,
          record: likelyAfter[afterIdx],
          similarity
        };
      }
    });

    if (bestMatch) {
      used.add(bestMatch.analysis.fileName);

      // マッチしたランドマークのリスト（簡略版）
      const matchedLandmarks = beforeAnalysis.landmarks
        .filter(lm => lm.confidence > 0.7)
        .map(lm => `${lm.type}: ${lm.description}`)
        .slice(0, 3); // 最大3つまで

      pairs.push({
        before: likelyBefore[beforeIdx],
        after: bestMatch.record,
        similarity: bestMatch.similarity,
        matchedLandmarks
      });
    }
  });

  onLog?.(`${pairs.length}組のペアを高速作成しました`, 'success');

  return pairs;
};

/**
 * キャッシュのクリア
 */
export const clearSpatialCache = (): void => {
  spatialCache.clear();
  console.log('空間キャッシュをクリアしました');
};

/**
 * キャッシュ統計の取得
 */
export const getCacheStats = (): { size: number, entries: string[] } => {
  return {
    size: spatialCache.size,
    entries: Array.from(spatialCache.keys())
  };
};

//===============================================================================
// FILE: services/smartFlowService.ts
//===============================================================================
import { GoogleGenAI } from "@google/genai";
import { PhotoRecord, AIAnalysisResult } from "../types";
import { extractBase64Data } from "../utils/imageUtils";
import { createSpatialPairs } from "./spatialPairingService";

const PRIMARY_MODEL = "gemini-2.5-flash";
const DETECTION_MODEL = "gemini-2.5-flash"; // Fast model for initial detection

/**
 * Smart Flow Service
 * 写真の種類を自動判定して最適な処理フローに振り分ける
 */

/**
 * Step 1: 写真セットの種類を判定
 * 黒板あり（詳細解析必要） or 景観写真（ペアリングのみ）
 */
export const detectPhotoType = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<'construction_with_board' | 'landscape_pairing'> => {

  const genAI = new GoogleGenAI({ apiKey });
  onLog?.('写真タイプを判定中...', 'info');

  // サンプル写真を3枚程度選択（全部見る必要はない）
  const samples = records.slice(0, Math.min(3, records.length));

  const inputs = samples.map(r => ({
    inlineData: {
      data: extractBase64Data(r.base64),
      mimeType: r.mimeType
    }
  }));

  const prompt = `
建設現場の写真を分析してください。

工事黒板の判定基準：
- 明確な黒板（黒/白/緑の板）に文字が書かれている
- 工事名、測点、日付などの情報が記載されている板
- 電子黒板（タブレット等）も含む
- 通常は作業員が持つか、地面に立てかけてある

黒板がない場合：
- 景観のみの写真（道路、建物、電柱などの風景）
- 定点撮影の着手前・完了後の記録写真

重要な注意点：
- 地面の測点マーキングや番号は黒板ではない
- 一般的な標識や看板は黒板ではない
- ゴミ収集案内板などは黒板ではない
- 背景にある白い看板や掲示板は黒板ではない
- 工事黒板は通常、写真の前景に明確に配置される

工事黒板と判定するには以下の全てが必要：
1. 明確な板状の物体（黒、白、緑色のいずれか）
2. 工事関連の情報（工事名、日付、測点等）が読める
3. 意図的に写真に含めた配置（前景または中央）

複数枚ある場合、1枚でも上記の基準を全て満たす工事黒板があれば"WITH_BOARD"と判定。
それ以外は全て"LANDSCAPE"と判定。

出力（JSONのみ）:
{"type": "WITH_BOARD" または "LANDSCAPE", "confidence": "high/medium/low", "reason": "判定理由"}
`;

  try {
    const result = await genAI.models.generateContent({
      model: DETECTION_MODEL,
      contents: [{ role: 'user', parts: [{ text: prompt }, ...inputs] }],
      config: {
        responseMimeType: "application/json",
        temperature: 0.1
      }
    });

    const detection = JSON.parse(result.text);
    onLog?.(`写真タイプ: ${detection.type === 'WITH_BOARD' ? '黒板あり' : '景観のみ'} (確信度: ${detection.confidence})`, 'success');

    // 判定理由も表示
    if (detection.reason) {
      onLog?.(`判定理由: ${detection.reason}`, 'info');
    }

    // 低確信度の場合は景観モードにフォールバック
    if (detection.confidence === 'low' && detection.type === 'WITH_BOARD') {
      onLog?.('確信度が低いため、景観写真モードを使用します', 'info');
      return 'landscape_pairing';
    }

    return detection.type === 'WITH_BOARD' ? 'construction_with_board' : 'landscape_pairing';

  } catch (error) {
    onLog?.('写真タイプの判定に失敗。デフォルトモードで処理します', 'error');
    return 'construction_with_board'; // フォールバック
  }
};

/**
 * Step 2A: 景観写真用の最適化フロー（座標ベースペアリング）
 */
export const processLandscapePhotos = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<{ pairs: Array<{ before: PhotoRecord, after: PhotoRecord, sceneId: string }> }> => {

  onLog?.('座標ベースの景観写真ペアリング処理を開始', 'info');

  try {
    // 座標ベースの厳密なペアリングを使用
    const spatialPairs = await createSpatialPairs(records, apiKey, onLog);

    // フォーマットを統一
    const pairs = spatialPairs.map((pair, index) => ({
      before: pair.before,
      after: pair.after,
      sceneId: `S${index + 1}_${Math.floor(pair.similarity * 100)}`
    }));

    onLog?.(`${pairs.length}組の空間的に一致するペアを作成しました`, 'success');

    // 類似度が低いペアに警告
    spatialPairs.forEach((pair, idx) => {
      if (pair.similarity < 0.8) {
        onLog?.(`注意: ペア${idx + 1}の類似度が低い (${(pair.similarity * 100).toFixed(1)}%)`, 'error');
      }
    });

    return { pairs };

  } catch (error: any) {
    onLog?.('座標ベースペアリングに失敗。フォールバック処理を実行', 'error');

    // フォールバック: 従来の簡易ペアリング
    return fallbackSimplePairing(records, apiKey, onLog);
  }
};

/**
 * フォールバック用の簡易ペアリング
 */
const fallbackSimplePairing = async (
  records: PhotoRecord[],
  apiKey: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<{ pairs: Array<{ before: PhotoRecord, after: PhotoRecord, sceneId: string }> }> => {

  const genAI = new GoogleGenAI({ apiKey });
  onLog?.('フォールバック: 簡易ペアリング処理', 'info');

  // 日付でソートして、前半を着手前、後半を完了と仮定
  const sorted = [...records].sort((a, b) => (a.date || 0) - (b.date || 0));
  const midPoint = Math.floor(sorted.length / 2);

  const beforePhotos = sorted.slice(0, midPoint);
  const afterPhotos = sorted.slice(midPoint);

  const pairs: Array<{ before: PhotoRecord, after: PhotoRecord, sceneId: string }> = [];

  // 単純にインデックスでペアリング
  const pairCount = Math.min(beforePhotos.length, afterPhotos.length);
  for (let i = 0; i < pairCount; i++) {
    pairs.push({
      before: beforePhotos[i],
      after: afterPhotos[i],
      sceneId: `FALLBACK_${i + 1}`
    });
  }

  onLog?.(`フォールバック処理で${pairs.length}組のペアを作成`, 'error');
  return { pairs };
};

/**
 * Step 2B: 黒板あり写真用の従来フロー（詳細解析）
 */
export const processConstructionPhotos = async (
  records: PhotoRecord[],
  apiKey: string,
  instruction: string,
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<PhotoRecord[]> => {

  // 従来の詳細解析処理
  // analyzePhotoBatchを呼び出す
  onLog?.('黒板付き写真の詳細解析を開始', 'info');

  // ここは既存のanalyzePhotoBatchロジックを使用
  // 工種、測点、備考などを抽出

  return records; // 解析済みのrecordsを返す
};

/**
 * メインの自動振り分け処理
 */
export const processPhotosWithSmartFlow = async (
  records: PhotoRecord[],
  apiKey: string,
  instruction: string = "",
  onLog?: (msg: string, type: 'info' | 'success' | 'error') => void
): Promise<{
  type: 'paired' | 'analyzed',
  pairs?: Array<{ before: PhotoRecord, after: PhotoRecord, sceneId: string }>,
  photos?: PhotoRecord[]
}> => {

  // Step 1: 写真タイプを判定
  const photoType = await detectPhotoType(records, apiKey, onLog);

  // Step 2: タイプに応じた処理
  if (photoType === 'landscape_pairing') {
    // 景観写真：ペアリングのみ
    const result = await processLandscapePhotos(records, apiKey, onLog);
    return {
      type: 'paired',
      pairs: result.pairs
    };
  } else {
    // 黒板あり：従来の詳細解析
    const analyzedPhotos = await processConstructionPhotos(records, apiKey, instruction, onLog);
    return {
      type: 'analyzed',
      photos: analyzedPhotos
    };
  }
};

//===============================================================================
// FILE: components/ConsolePanel.tsx
//===============================================================================
import React, { useEffect, useRef, useState } from 'react';
import { Terminal, ChevronDown, Send, Loader2 } from 'lucide-react';
import { LogEntry } from '../types';

interface ConsolePanelProps {
  logs: LogEntry[];
  isOpen: boolean;
  isProcessing?: boolean;
  onToggle: () => void;
  onClear: () => void;
  onSendInstruction?: (instruction: string) => void;
}

const ConsolePanel: React.FC<ConsolePanelProps> = ({
  logs,
  isOpen,
  isProcessing = false,
  onToggle,
  onClear,
  onSendInstruction
}) => {
  const scrollRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);
  const [inputValue, setInputValue] = useState('');
  const [commandHistory, setCommandHistory] = useState<string[]>([]);
  const [historyIndex, setHistoryIndex] = useState(-1);

  useEffect(() => {
    if (isOpen && scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [logs, isOpen]);

  useEffect(() => {
    if (isOpen && inputRef.current) {
      inputRef.current.focus();
    }
  }, [isOpen]);

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    const trimmed = inputValue.trim();
    if (!trimmed || !onSendInstruction) return;

    onSendInstruction(trimmed);
    setCommandHistory(prev => [trimmed, ...prev].slice(0, 50));
    setInputValue('');
    setHistoryIndex(-1);
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
    if (e.key === 'ArrowUp') {
      e.preventDefault();
      if (commandHistory.length > 0) {
        const newIndex = Math.min(historyIndex + 1, commandHistory.length - 1);
        setHistoryIndex(newIndex);
        setInputValue(commandHistory[newIndex]);
      }
    } else if (e.key === 'ArrowDown') {
      e.preventDefault();
      if (historyIndex > 0) {
        const newIndex = historyIndex - 1;
        setHistoryIndex(newIndex);
        setInputValue(commandHistory[newIndex]);
      } else if (historyIndex === 0) {
        setHistoryIndex(-1);
        setInputValue('');
      }
    }
  };

  if (!isOpen) {
    return (
      <button
        onClick={onToggle}
        className="fixed bottom-4 right-4 z-[150] bg-black/80 text-green-400 p-3 rounded-full shadow-xl hover:bg-black transition-all border border-green-900 flex items-center gap-2"
        title="Show API Console"
      >
        <Terminal className="w-5 h-5" />
        {logs.length > 0 && (
          <span className="bg-red-500 text-white text-[10px] font-bold px-1.5 rounded-full absolute -top-1 -right-1">
            {logs.length}
          </span>
        )}
      </button>
    );
  }

  return (
    <div className="fixed bottom-0 left-0 w-full h-[25vh] z-[150] flex flex-col shadow-2xl animate-in slide-in-from-bottom-10 duration-300">
      <div className="bg-gray-900 text-gray-300 px-4 py-2 flex justify-between items-center border-t border-gray-700">
        <div className="flex items-center gap-2">
          <Terminal className="w-4 h-4 text-green-500" />
          <span className="text-xs font-mono font-bold">AI CONSOLE</span>
          <span className="text-[10px] bg-gray-800 px-2 py-0.5 rounded text-gray-400">
            {logs.length} events
          </span>
          {isProcessing && (
            <span className="text-[10px] bg-amber-600 px-2 py-0.5 rounded text-white flex items-center gap-1 animate-pulse">
              <Loader2 className="w-3 h-3 animate-spin" /> Processing...
            </span>
          )}
        </div>
        <div className="flex gap-2">
          <button onClick={onClear} className="text-xs hover:text-white px-2 py-1 rounded hover:bg-gray-800 transition-colors">
            Clear
          </button>
          <button onClick={onToggle} className="text-gray-400 hover:text-white">
            <ChevronDown className="w-5 h-5" />
          </button>
        </div>
      </div>

      <div
        ref={scrollRef}
        className="flex-1 bg-black/95 overflow-y-auto p-4 font-mono text-xs space-y-3 border-t border-gray-800"
      >
        {logs.length === 0 && (
          <div className="text-gray-600 italic">No logs yet. Type an instruction below to start...</div>
        )}

        {logs.map((log, index) => (
          <div key={index} className="flex gap-2 items-start border-l-2 border-transparent hover:bg-gray-900/50 p-1 rounded">
            <span className="text-gray-500 flex-shrink-0 select-none">[{log.timestamp}]</span>
            <div className="flex-1 break-all whitespace-pre-wrap">
              <span className={
                log.type === 'error' ? 'text-red-400 font-bold' :
                log.type === 'success' ? 'text-green-400' :
                log.type === 'json' ? 'text-blue-300' : 'text-gray-300'
              }>
                {log.message}
              </span>

              {log.details && (
                <div className="mt-1 bg-gray-900 p-2 rounded text-amber-100/90 overflow-x-auto border border-gray-800">
                  {typeof log.details === 'object'
                    ? JSON.stringify(log.details, null, 2)
                    : String(log.details)
                  }
                </div>
              )}
            </div>
          </div>
        ))}
      </div>

      <form onSubmit={handleSubmit} className="bg-gray-900 border-t border-gray-700 px-4 py-2 flex gap-2 items-center">
        <span className="text-green-500 font-mono text-sm flex-shrink-0">$</span>
        <input
          ref={inputRef}
          type="text"
          value={inputValue}
          onChange={(e) => setInputValue(e.target.value)}
          onKeyDown={handleKeyDown}
          placeholder="追加指示を入力... (例: 全部舗装打換え工にして)"
          className="flex-1 bg-transparent text-green-400 font-mono text-sm outline-none placeholder-gray-600"
          disabled={!onSendInstruction}
        />
        <button
          type="submit"
          disabled={!inputValue.trim() || !onSendInstruction}
          className="p-1.5 bg-green-600 hover:bg-green-500 disabled:bg-gray-700 disabled:text-gray-500 text-white rounded transition-colors"
        >
          <Send className="w-4 h-4" />
        </button>
      </form>
    </div>
  );
};

export default ConsolePanel;


//===============================================================================
// FILE: components/LimitModal.tsx
//===============================================================================
import React from 'react';
import { ListFilter } from 'lucide-react';
import { TRANS } from '../utils/translations';

interface LimitModalProps {
  totalFiles: number;
  maxPhotos: number;
  selectionStart: number;
  selectionCount: number;
  lang: 'en' | 'ja';
  onStartChange: (val: number) => void;
  onCountChange: (val: number) => void;
  onCancel: () => void;
  onConfirm: () => void;
}

const LimitModal: React.FC<LimitModalProps> = ({
  totalFiles,
  maxPhotos,
  selectionStart,
  selectionCount,
  lang,
  onStartChange,
  onCountChange,
  onCancel,
  onConfirm
}) => {
  const txt = TRANS[lang];

  return (
    <div className="fixed inset-0 z-[200] bg-black/50 flex items-center justify-center p-4">
      <div className="bg-white rounded-xl shadow-2xl max-w-md w-full p-6 animate-in fade-in zoom-in duration-200">
        <div className="flex items-center gap-3 mb-4 text-amber-600">
          <ListFilter className="w-8 h-8" />
          <h3 className="text-xl font-bold">{txt.limitTitle}</h3>
        </div>
        <p className="text-gray-600 mb-6">{txt.limitDesc(totalFiles)}</p>
        <div className="space-y-4 mb-8">
          <div>
            <label className="block text-sm font-bold text-gray-700 mb-1">{txt.startLabel}</label>
            <input 
              type="number" 
              min={1} 
              max={totalFiles}
              value={selectionStart}
              onChange={(e) => onStartChange(parseInt(e.target.value) || 1)}
              className="w-full border border-gray-300 rounded-lg p-3 text-lg font-mono focus:ring-2 focus:ring-amber-500 outline-none"
            />
          </div>
          <div>
            <label className="block text-sm font-bold text-gray-700 mb-1">{txt.rangeLabel}</label>
            <input 
              type="number" 
              min={1} 
              max={maxPhotos}
              value={selectionCount}
              onChange={(e) => onCountChange(parseInt(e.target.value) || 1)}
              className="w-full border border-gray-300 rounded-lg p-3 text-lg font-mono focus:ring-2 focus:ring-amber-500 outline-none"
            />
          </div>
          <div className="bg-gray-100 p-3 rounded text-center text-sm font-bold text-gray-700">
            {txt.rangePreview(selectionStart, Math.min(totalFiles, selectionStart + selectionCount - 1))}
          </div>
        </div>
        <div className="flex gap-3">
          <button onClick={onCancel} className="flex-1 py-3 bg-gray-200 hover:bg-gray-300 text-gray-700 rounded-lg font-bold">{txt.btnCancel}</button>
          <button onClick={onConfirm} className="flex-1 py-3 bg-blue-600 hover:bg-blue-700 text-white rounded-lg font-bold shadow-md">{txt.btnProcess}</button>
        </div>
      </div>
    </div>
  );
};

export default LimitModal;

//===============================================================================
// FILE: components/PhotoAlbumView.tsx
//===============================================================================
import React, { useState, useEffect } from 'react';
import { createPortal } from 'react-dom';
import { PhotoRecord, AppMode, AIAnalysisResult } from '../types';
import { TRANS } from '../utils/translations';
import { Database, Trash2, Wand2 } from 'lucide-react';
import { LAYOUT_FIELDS } from '../utils/layoutConfig';

interface Props {
  records: PhotoRecord[];
  appMode: AppMode;
  lang: 'en' | 'ja';
  photosPerPage: 2 | 3;
  onUpdatePhoto: (fileName: string, field: keyof AIAnalysisResult, value: string) => void;
  onDeletePhoto?: (fileName: string) => void;
  onReanalyzePhoto?: (fileName: string) => void;
}

/**
 * A field that is an Input/Textarea on screen (for editing),
 * but becomes a plain Div in PDF mode (for proper text wrapping/rendering).
 */
const EditableField = ({
  value,
  onChange,
  multiline = false,
  align = 'left',
  textClass = "text-lg text-gray-900"
}: {
  value: string;
  onChange: (val: string) => void;
  multiline?: boolean;
  align?: 'left' | 'center';
  textClass?: string;
}) => {
  // Unified typography: text-lg, text-gray-900, tight leading
  const baseClass = `w-full h-full bg-transparent border-none outline-none focus:bg-yellow-50 focus:ring-1 focus:ring-amber-300 hover:bg-black/5 rounded-sm transition-colors leading-tight font-normal block ${textClass}`;
  const alignClass = align === 'center' ? 'text-center' : 'text-left';
  // Minimal padding to fit text-lg in h-[28px] rows
  const paddingClass = multiline ? 'p-1' : 'px-1 py-0.5';

  return (
    <div className="relative w-full h-full group overflow-hidden">
      {/* Screen Mode: Editable Input */}
      <div className="pdf-hidden w-full h-full">
        {multiline ? (
          <textarea
            value={value}
            onChange={(e) => onChange(e.target.value)}
            className={`${baseClass} resize-none [&::-webkit-scrollbar]:hidden ${alignClass} ${paddingClass}`}
          />
        ) : (
          <input
            type="text"
            value={value}
            onChange={(e) => onChange(e.target.value)}
            className={`${baseClass} ${alignClass} ${paddingClass}`}
          />
        )}
      </div>

      {/* PDF/Print Mode: Static Text */}
      <div className={`pdf-visible hidden w-full h-full leading-tight break-words whitespace-pre-wrap font-normal ${alignClass} ${paddingClass} ${textClass}`}>
        {value}
      </div>
    </div>
  );
};

interface InfoRowProps {
  label: string;
  value: string;
  className?: string; // Handles height and borders
  onChange: (val: string) => void;
  align?: 'left' | 'center';
  multiline?: boolean;
  readOnly?: boolean;
  hideLabel?: boolean; // New prop to toggle label visibility
  textClass?: string;
  children?: React.ReactNode;
}

const InfoRow: React.FC<InfoRowProps> = ({ label, value, className = "", onChange, align = 'left', multiline = false, readOnly = false, hideLabel = false, textClass, children }) => (
  // Use className for height control
  <div className={`flex border-b border-gray-300 last:border-b-0 box-border w-full ${className}`}>
    {/* Label: Fixed width w-12 (48px) - Only render if not hidden */}
    {!hideLabel && (
      <div className={`w-12 flex justify-center text-lg text-gray-900 font-normal flex-shrink-0 leading-tight px-0.5 text-center select-none bg-gray-50/50 border-r border-gray-300 ${multiline ? 'items-start pt-1' : 'items-center'}`}>
        {label}
      </div>
    )}
    {/* Content Area */}
    <div className="flex-1 relative min-w-0 bg-white h-full overflow-hidden">
      {readOnly ? (
        <div className="w-full h-full px-1 py-0.5 flex items-center justify-between text-lg text-gray-900 leading-tight font-normal">
          <span className="truncate">{value}</span>
          {children}
        </div>
      ) : (
        <EditableField
          value={value}
          onChange={onChange}
          multiline={multiline}
          align={align as 'left' | 'center'}
          textClass={textClass}
        />
      )}
    </div>
  </div>
);

type ContextMenuState = {
  x: number;
  y: number;
  targetFileName: string;
} | null;

const PhotoAlbumView: React.FC<Props> = ({ records, appMode, lang, photosPerPage, onUpdatePhoto, onDeletePhoto, onReanalyzePhoto }) => {
  const txt = TRANS[lang];
  const totalPages = Math.ceil(records.length / photosPerPage);
  const [contextMenu, setContextMenu] = useState<ContextMenuState>(null);

  useEffect(() => {
    const handleClickOutside = () => setContextMenu(null);
    window.addEventListener('click', handleClickOutside);
    window.addEventListener('resize', handleClickOutside); // Close on resize too
    return () => {
      window.removeEventListener('click', handleClickOutside);
      window.removeEventListener('resize', handleClickOutside);
    };
  }, []);

  const handleContextMenu = (e: React.MouseEvent, fileName: string) => {
    e.preventDefault();
    setContextMenu({
      x: e.clientX,
      y: e.clientY,
      targetFileName: fileName
    });
  };

  const executeDelete = () => {
    if (contextMenu && onDeletePhoto) {
      onDeletePhoto(contextMenu.targetFileName);
      setContextMenu(null);
    }
  };

  const isTwoUp = photosPerPage === 2;

  // Fields Config
  // 3-up: All Fields
  // 2-up: Only Remarks, Station (in that order)
  const visibleFields = isTwoUp
    ? [
      LAYOUT_FIELDS.find(f => f.key === 'remarks')!,
      LAYOUT_FIELDS.find(f => f.key === 'station')!
    ].filter(Boolean)
    : LAYOUT_FIELDS;

  return (
    <div id="album-content" className="w-full">
      {Array.from({ length: totalPages }).map((_, pageIndex) => (
        <div key={pageIndex} className="sheet-preview px-12 py-6 mb-8 relative flex flex-col box-border h-[297mm]">

          {/* Page Header */}
          <div className="flex justify-between items-end mb-2 w-full flex-shrink-0">
            <h1 className="text-xl font-bold text-gray-900 border-b-2 border-gray-900 leading-none pb-1 px-1">
              {appMode === 'construction' ? '工事写真帳' : 'Photo Album'}
            </h1>
            <div className="text-sm font-bold text-gray-800">
              Page <span className="text-lg">{pageIndex + 1}</span>
            </div>
          </div>

          {/* Main Content Border Box - Flex 1 ensures it fills the page */}
          <div className="flex flex-col flex-1 border border-gray-400 bg-white min-h-0">
            {Array.from({ length: photosPerPage }).map((_, slotIndex) => {
              const photoIndex = pageIndex * photosPerPage + slotIndex;
              const record = records[photoIndex];

              // Dynamic Layout Classes

              // Slot Container
              // 3-up: Row Layout, 33% Height
              // 2-up: Col Layout, 50% Height
              const slotClass = isTwoUp
                ? "flex-1 border-b border-gray-300 last:border-b-0 flex flex-col box-border min-h-0 hover:bg-gray-50 transition-colors h-[50%]"
                : "flex-1 border-b border-gray-300 last:border-b-0 flex flex-row box-border min-h-0 hover:bg-gray-50 transition-colors h-[33.33%]";

              // Image Container
              // 3-up: 65% width, Right Border, Normal Padding
              // 2-up: 100% width, Flex-1 (Takes remaining height), Bottom Border, Minimal Padding (0.5) to maximize image
              const imageContainerClass = isTwoUp
                ? "w-full flex-1 border-r-0 border-b border-gray-300 flex items-center justify-center bg-white relative overflow-hidden group cursor-context-menu p-0.5"
                : "w-[65%] border-r border-gray-300 flex items-center justify-center bg-white relative overflow-hidden group cursor-context-menu";

              // Info Container
              // 3-up: 35% width
              // 2-up: 100% width, Auto Height (fits content), minimal padding
              const infoContainerClass = isTwoUp
                ? "w-full h-auto bg-white flex flex-col justify-start py-1 px-4 gap-1"
                : "w-[35%] flex flex-col h-full bg-white";

              if (!record) {
                return <div key={`empty-${slotIndex}`} className={slotClass}></div>;
              }

              return (
                <div
                  key={record.fileName}
                  className={slotClass}
                  onContextMenu={(e) => handleContextMenu(e, record.fileName)}
                >
                  {/* Image Section */}
                  <div className={imageContainerClass}>
                    <img src={record.base64} alt={record.fileName} className="max-w-full max-h-full object-contain" />

                    {record.fromCache && (
                      <div className="absolute top-2 left-2 bg-green-100/90 text-green-800 px-2 py-1 rounded shadow-sm border border-green-300 flex items-center gap-1.5 z-10 pointer-events-none opacity-80 group-hover:opacity-100 transition-opacity">
                        <Database className="w-4 h-4" />
                        <span className="text-xs font-bold font-sans">Cached</span>
                      </div>
                    )}
                  </div>

                  {/* Info Section */}
                  <div className={infoContainerClass}>
                    {visibleFields.map((field) => {
                      // Resolve value
                      let val = "";
                      if (field.key === 'date') {
                        val = record.date
                          ? new Date(record.date).toLocaleString('ja-JP', { year: 'numeric', month: '2-digit', day: '2-digit', hour: '2-digit', minute: '2-digit' })
                          : '';
                      } else {
                        val = record.analysis ? (record.analysis[field.key as keyof AIAnalysisResult] as string || "") : "";
                      }

                      // Extra UI (Date Cache icon) - Only shows in 3-up since date is hidden in 2-up
                      const extraUI = (!isTwoUp && field.key === 'date' && record.fromCache) ? (
                        <div className="flex items-center gap-1 text-[10px] text-green-600 font-bold bg-green-50 px-1 rounded border border-green-200" title="Restored from local cache">
                          <Database className="w-3 h-3" />
                        </div>
                      ) : null;

                      // Determine height class dynamically
                      let dynamicHeightClass = field.heightClass;
                      let dynamicTextClass = undefined;
                      if (isTwoUp) {
                        // In 2-up vertical mode - unified text styling for station and remarks
                        dynamicHeightClass = 'h-[30px] flex-shrink-0 border-none'; // 高さを20pxから30pxに増加
                        dynamicTextClass = 'text-sm text-gray-900 font-medium'; // 統一されたテキストスタイル
                      } else {
                        // 3-up Logic (Original)
                        if (field.key === 'description') {
                          dynamicHeightClass = 'min-h-0 border-b-0 flex-1'; // Fill remaining vertical space
                        } else {
                          dynamicHeightClass = `${field.heightClass} flex-shrink-0`;
                        }
                      }

                      return (
                        <InfoRow
                          key={field.id}
                          label={txt[field.labelKey as keyof typeof txt] as string}
                          value={val}
                          className={dynamicHeightClass}
                          onChange={(v) => field.key !== 'date' && onUpdatePhoto(record.fileName, field.key as keyof AIAnalysisResult, v)}
                          readOnly={field.readOnly}
                          multiline={field.multiline}
                          hideLabel={isTwoUp} // Hide label in 2-up mode
                          align={isTwoUp ? 'center' : 'left'} // Center text in 2-up mode
                          textClass={dynamicTextClass}
                        >
                          {extraUI}
                        </InfoRow>
                      );
                    })}
                  </div>
                </div>
              );
            })}
          </div>
        </div>
      ))}

      {/* Custom Context Menu using Portal to escape CSS Transforms */}
      {contextMenu && createPortal(
        <div
          className="fixed z-[9999] bg-white rounded-lg shadow-xl border border-gray-200 py-1 min-w-[150px] animate-in fade-in zoom-in duration-100"
          style={{ top: contextMenu.y, left: contextMenu.x }}
          onClick={(e) => e.stopPropagation()}
        >
          <div className="px-3 py-1.5 border-b border-gray-100 text-xs text-gray-500 font-bold bg-gray-50">
            {lang === 'ja' ? '操作' : 'Action'}
          </div>
          <button
            onClick={() => {
              if (contextMenu && onReanalyzePhoto) {
                onReanalyzePhoto(contextMenu.targetFileName);
                setContextMenu(null);
              }
            }}
            className="w-full text-left px-4 py-2 text-sm text-blue-600 hover:bg-blue-50 flex items-center gap-2"
          >
            <Wand2 className="w-4 h-4" />
            {lang === 'ja' ? 'この画像を再解析' : 'Re-analyze Photo'}
          </button>
          <button
            onClick={executeDelete}
            className="w-full text-left px-4 py-2 text-sm text-red-600 hover:bg-red-50 flex items-center gap-2"
          >
            <Trash2 className="w-4 h-4" />
            {lang === 'ja' ? '削除する' : 'Delete Photo'}
          </button>
        </div>,
        document.body
      )}

    </div>
  );
};

export default PhotoAlbumView;

//===============================================================================
// FILE: components/SimplePairingMode.tsx
//===============================================================================
import React, { useState } from 'react';
import { Upload, Camera } from 'lucide-react';

interface SimplePairingModeProps {
  onPairingComplete: (pairs: any[]) => void;
}

/**
 * シンプルなペアリング専用モード
 * 個別解析をスキップして、直接ペアリング処理を行う
 */
const SimplePairingMode: React.FC<SimplePairingModeProps> = ({ onPairingComplete }) => {
  const [isProcessing, setIsProcessing] = useState(false);
  const [uploadedFiles, setUploadedFiles] = useState<File[]>([]);

  const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = Array.from(e.target.files || []);
    setUploadedFiles(prev => [...prev, ...files]);
  };

  const handleDirectPairing = async () => {
    setIsProcessing(true);

    try {
      // 1. 画像を準備（base64エンコード）
      const photoData = await Promise.all(
        uploadedFiles.map(async (file) => {
          const base64 = await fileToBase64(file);
          return {
            fileName: file.name,
            base64,
            mimeType: file.type,
            date: file.lastModified
          };
        })
      );

      // 2. 一括でペアリング処理
      // シーン識別と着手前/完了の判定を同時に行う
      const response = await fetch('/api/pairing', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          photos: photoData,
          mode: 'construction_pairing'
        })
      });

      const pairs = await response.json();

      // 3. ペアリング結果を返す
      onPairingComplete(pairs);

    } catch (error) {
      console.error('Pairing failed:', error);
    } finally {
      setIsProcessing(false);
    }
  };

  const fileToBase64 = (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => resolve(reader.result as string);
      reader.onerror = error => reject(error);
    });
  };

  return (
    <div className="p-4">
      <h2 className="text-2xl font-bold mb-4">
        工事写真ペアリングモード
      </h2>

      <div className="border-2 border-dashed border-gray-300 rounded-lg p-8 text-center">
        <Camera className="w-16 h-16 mx-auto mb-4 text-gray-400" />

        <p className="mb-4 text-gray-600">
          着手前と完了後の写真をまとめてアップロードしてください
        </p>

        <label className="cursor-pointer">
          <input
            type="file"
            multiple
            accept="image/*"
            onChange={handleFileUpload}
            className="hidden"
          />
          <div className="inline-flex items-center px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700">
            <Upload className="w-5 h-5 mr-2" />
            写真を選択
          </div>
        </label>
      </div>

      {uploadedFiles.length > 0 && (
        <div className="mt-4">
          <p className="text-sm text-gray-600 mb-2">
            {uploadedFiles.length}枚の写真がアップロードされました
          </p>

          <button
            onClick={handleDirectPairing}
            disabled={isProcessing}
            className="px-4 py-2 bg-green-600 text-white rounded hover:bg-green-700 disabled:opacity-50"
          >
            {isProcessing ? 'ペアリング中...' : 'ペアリングを開始'}
          </button>
        </div>
      )}

      {isProcessing && (
        <div className="mt-4 p-4 bg-blue-50 rounded">
          <p className="text-blue-800">
            写真を解析してペアを作成しています...
          </p>
          <p className="text-sm text-blue-600 mt-2">
            • 同じ場所の識別
            • 着手前/完了の判定
            • ペアの作成
          </p>
        </div>
      )}
    </div>
  );
};

export default SimplePairingMode;

//===============================================================================
// FILE: components/UploadView.tsx
//===============================================================================
import React, { useRef, useState, useEffect } from 'react';
import { TRANS } from '../utils/translations';
import { PhotoRecord, AppMode } from '../types';
import { Upload, FileUp, HardHat, Camera, MessageSquare, Trash2, Key, Check, Database, Zap } from 'lucide-react';

interface UploadViewProps {
  lang: 'en' | 'ja';
  isProcessing: boolean;
  photos: PhotoRecord[];
  appMode: AppMode;
  apiKey: string;
  setApiKey: (key: string) => void;
  setAppMode: (mode: AppMode) => void;
  onStartProcessing: (files: File[], instruction: string, useCache: boolean) => void;
  onResume: () => void;
  onCloseProject: () => void;
  onExportJson: () => void;
  onImportJson: (e: React.ChangeEvent<HTMLInputElement>) => void;
  onClearCache?: () => void;
  onShowPreview?: () => void;
}

const STORAGE_KEY_INSTRUCTION = 'gemini_last_upload_instruction';

const UploadView: React.FC<UploadViewProps> = ({
  lang,
  isProcessing,
  photos,
  appMode,
  apiKey,
  setApiKey,
  setAppMode,
  onStartProcessing,
  onResume,
  onCloseProject,
  onExportJson,
  onImportJson,
  onClearCache,
  onShowPreview
}) => {
  const txt = TRANS[lang];
  const fileInputRef = useRef<HTMLInputElement>(null);
  const fileInputImportRef = useRef<HTMLInputElement>(null);
  const [isDragging, setIsDragging] = useState(false);
  const [instruction, setInstruction] = useState("");
  const [showKeyInput, setShowKeyInput] = useState(!apiKey);
  const [useCache, setUseCache] = useState(true); // Default to True

  // Restore instruction from local storage on mount
  useEffect(() => {
    const saved = localStorage.getItem(STORAGE_KEY_INSTRUCTION);
    if (saved) {
      setInstruction(saved);
    }
  }, []);

  // Save instruction to local storage on change
  useEffect(() => {
    localStorage.setItem(STORAGE_KEY_INSTRUCTION, instruction);
  }, [instruction]);

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    if (!isProcessing && apiKey) setIsDragging(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
  };

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault();
    setIsDragging(false);
    if (isProcessing || !apiKey) return;

    if (e.dataTransfer.files && e.dataTransfer.files.length > 0) {
      onStartProcessing(Array.from(e.dataTransfer.files), instruction, useCache);
    }
  };

  const handleFileInputChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files.length > 0) {
      onStartProcessing(Array.from(e.target.files), instruction, useCache);
    }
    // Reset input so the same file can be selected again if needed
    if (fileInputRef.current) fileInputRef.current.value = '';
  };

  const handleClick = () => {
    if (!isProcessing && apiKey) {
      fileInputRef.current?.click();
    }
  };

  const handleKeySave = () => {
    if (apiKey.trim()) {
      setShowKeyInput(false);
    }
  };

  return (
    <div
      className={`min-h-screen w-full flex flex-col transition-colors duration-300 relative
        ${isDragging ? 'bg-blue-50' : 'bg-white'}
      `}
      onDragOver={handleDragOver}
      onDragLeave={handleDragLeave}
      onDrop={handleDrop}
    >
      {/* --- HEADER --- */}
      <div className="absolute top-0 left-0 w-full p-6 flex justify-between items-center z-10">
        <h1 className="text-gray-700 font-bold tracking-tight text-xl flex items-center gap-2">
          {appMode === 'construction' ? <HardHat className="w-6 h-6 text-amber-500" /> : <FileUp className="w-5 h-5" />}
          {txt.appTitle}
        </h1>
        <button
          onClick={() => setShowKeyInput(!showKeyInput)}
          className={`flex items-center gap-2 text-sm font-medium px-3 py-1.5 rounded-full transition-colors ${!apiKey ? 'bg-red-100 text-red-600 animate-pulse' : 'bg-gray-100 text-gray-500 hover:text-gray-900'}`}
        >
          <Key className="w-4 h-4" />
          {apiKey ? "API Key Set" : "Set API Key"}
        </button>
      </div>

      {/* --- MAIN INTERACTION AREA --- */}
      <div className="flex-1 flex flex-col items-center justify-center relative w-full max-w-2xl mx-auto px-4">

        {showKeyInput || !apiKey ? (
          <div className="w-full max-w-md bg-white p-8 rounded-2xl shadow-xl border border-gray-100 animate-in fade-in zoom-in duration-300 z-30">
            <div className="flex flex-col items-center mb-6">
              <div className="bg-amber-100 p-3 rounded-full mb-3">
                <Key className="w-8 h-8 text-amber-600" />
              </div>
              <h2 className="text-xl font-bold text-gray-800">Gemini API Key Required</h2>
              <p className="text-gray-500 text-center text-sm mt-2">
                This app requires a Google Gemini API Key to analyze photos. <br />
                The key is stored locally in your browser.
              </p>
            </div>
            <div className="space-y-4">
              <input
                type="password"
                value={apiKey}
                onChange={(e) => setApiKey(e.target.value)}
                placeholder="Paste your API Key here (AIza...)"
                className="w-full border border-gray-300 rounded-lg p-3 focus:ring-2 focus:ring-amber-500 outline-none font-mono text-sm"
              />
              <button
                onClick={handleKeySave}
                disabled={!apiKey.trim()}
                className="w-full bg-amber-500 hover:bg-amber-600 text-white font-bold py-3 rounded-lg shadow disabled:opacity-50 disabled:cursor-not-allowed transition-colors flex items-center justify-center gap-2"
              >
                <Check className="w-5 h-5" /> Save & Continue
              </button>
              <div className="text-center">
                <a href="https://aistudio.google.com/app/apikey" target="_blank" rel="noreferrer" className="text-xs text-blue-500 hover:underline">
                  Get an API Key from Google AI Studio
                </a>
              </div>
            </div>
          </div>
        ) : (
          /* The Trigger */
          <div
            onClick={handleClick}
            className="group cursor-pointer flex flex-col items-center justify-center p-10 md:p-16 z-20 rounded-3xl transition-all duration-300 hover:bg-gray-50 w-full"
          >
            {/* ICON CONTAINER */}
            <div className={`mb-6 transition-transform duration-300 ease-out p-6 rounded-full bg-gray-100 group-hover:bg-blue-100 group-hover:scale-110 ${isDragging ? 'scale-125 bg-blue-200' : ''}`}>
              <Upload
                className={`w-16 h-16 text-gray-400 group-hover:text-blue-600 transition-colors ${isDragging ? 'text-blue-600' : ''}`}
                strokeWidth={1.5}
              />
            </div>

            {/* MAIN TEXT */}
            <span className="text-2xl md:text-3xl font-bold text-gray-700 group-hover:text-gray-900 transition-colors tracking-tight text-center">
              {isDragging ? txt.dropHere : txt.putPhotos}
            </span>
            <span className="mt-3 text-sm text-gray-400 group-hover:text-gray-500 text-center">
              {appMode === 'construction' ? '工事黒板を自動認識します' : 'Click or Drop photos here'}
            </span>

            {/* HIDDEN INPUT */}
            <input
              type="file"
              ref={fileInputRef}
              onChange={handleFileInputChange}
              className="hidden"
              multiple
              accept="image/*"
            />
          </div>
        )}

        {/* --- SETTINGS / INSTRUCTION INPUT --- */}
        {!showKeyInput && apiKey && (
          <div className="w-full max-w-md mt-6 z-20 animate-in fade-in slide-in-from-bottom-4 duration-500 space-y-3">
            {/* Use Cache Checkbox */}
            <div
              className="flex items-center gap-2 px-3 py-2 bg-gray-50 rounded-lg border border-gray-200 cursor-pointer hover:bg-white transition-colors group"
              onClick={() => setUseCache(!useCache)}
            >
              <div className={`w-5 h-5 rounded border flex items-center justify-center transition-colors ${useCache ? 'bg-green-600 border-green-600' : 'bg-white border-gray-400'}`}>
                {useCache && <Check className="w-3.5 h-3.5 text-white" />}
              </div>
              <div className="flex flex-col">
                <span className="text-sm font-bold text-gray-700 select-none flex items-center gap-2">
                  <Database className="w-4 h-4 text-green-600" />
                  {lang === 'ja' ? 'キャッシュを利用（高速化）' : 'Use Cache (Restore previous)'}
                </span>
                <span className="text-[10px] text-gray-400 pl-6">
                  {lang === 'ja' ? '解析済みの写真を復元し、API消費を抑えます' : 'Restore analyzed photos to save API quota'}
                </span>
              </div>
            </div>

            <div className="relative group">
              <div className="absolute inset-y-0 left-0 pl-3 pt-3 pointer-events-none">
                <MessageSquare className="h-5 w-5 text-gray-400 group-focus-within:text-blue-500 transition-colors" />
              </div>
              <textarea
                value={instruction}
                onChange={(e) => setInstruction(e.target.value)}
                onClick={(e) => e.stopPropagation()} // Prevent triggering upload
                placeholder={lang === 'ja'
                  ? "AIへの指示（任意）: 例「工種は全て『舗装工』にして」「場所は東京駅」"
                  : "Custom Instruction (Optional): e.g., 'Categorize all as Kitchen'"}
                className="block w-full pl-10 pr-3 py-3 border border-gray-300 rounded-xl leading-5 bg-white text-gray-900 placeholder-gray-500 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 sm:text-sm resize-none shadow-sm transition-shadow h-20"
              />
            </div>
          </div>
        )}

        {/* Processing Indicator */}
        {isProcessing && (
          <div className="absolute inset-0 bg-white/90 z-50 flex flex-col items-center justify-center backdrop-blur-sm rounded-xl">
            <div className="w-16 h-16 border-4 border-gray-200 border-t-blue-600 rounded-full animate-spin mb-6"></div>
            <h2 className="text-xl font-bold text-gray-800 animate-pulse">{txt.analyzing}</h2>
            <p className="text-gray-500 mt-2 text-sm">AI is processing your photos...</p>
            {onShowPreview && (
              <button
                onClick={onShowPreview}
                className="mt-4 px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white rounded-lg font-bold text-sm"
              >
                Show Preview
              </button>
            )}
          </div>
        )}

      </div>

      {/* --- FOOTER (Data Management) --- */}
      <div className="absolute bottom-0 w-full p-6 flex justify-between items-end z-10 text-xs font-medium text-gray-400">

        {/* Mode Switcher */}
        <div className="flex gap-2 bg-gray-100 p-1 rounded-lg">
          <button
            onClick={(e) => { e.stopPropagation(); setAppMode('construction'); }}
            className={`px-3 py-1.5 rounded flex items-center gap-2 transition-all ${appMode === 'construction' ? 'bg-white text-gray-800 shadow-sm font-bold' : 'text-gray-400 hover:text-gray-600'}`}
          >
            <HardHat className="w-3 h-3" /> {txt.modeConstruction}
          </button>
          <button
            onClick={(e) => { e.stopPropagation(); setAppMode('general'); }}
            className={`px-3 py-1.5 rounded flex items-center gap-2 transition-all ${appMode === 'general' ? 'bg-white text-gray-800 shadow-sm font-bold' : 'text-gray-400 hover:text-gray-600'}`}
          >
            <Camera className="w-3 h-3" /> {txt.modeGeneral}
          </button>
        </div>

        <div className="flex gap-4 items-center">
          {photos.length > 0 && (
            <button onClick={onResume} className="hover:text-gray-800 transition-colors border-b border-transparent hover:border-gray-800 pb-0.5">
              {txt.resumeLabel}
            </button>
          )}
          <span className="w-px bg-gray-300 mx-1 h-4"></span>
          <button onClick={onExportJson} className="hover:text-gray-800 transition-colors">
            Backup (JSON)
          </button>
          <button onClick={() => fileInputImportRef.current?.click()} className="hover:text-gray-800 transition-colors">
            Restore (JSON)
          </button>
          {onClearCache && (
            <>
              <span className="w-px bg-gray-300 mx-1 h-4"></span>
              <button onClick={onClearCache} className="hover:text-red-600 transition-colors flex items-center gap-1" title="Delete stored AI analysis results">
                <Trash2 className="w-3 h-3" /> Clear Cache
              </button>
            </>
          )}
          <input type="file" ref={fileInputImportRef} onChange={onImportJson} className="hidden" accept=".json" />
        </div>
      </div>

    </div>
  );
};

export default UploadView;

//===============================================================================
// FILE: components/RefineModal.tsx
//===============================================================================
import React, { useState, useEffect, useRef } from 'react';
import { Wand2, Save, PlusCircle, Edit2, CheckSquare, Square, Trash2, X, Play, Download, Upload, Tag, Lightbulb, Search, Library, RefreshCw } from 'lucide-react';
import { TRANS } from '../utils/translations';
import { AnalysisRule, getRules, saveRule, deleteRule, exportRulesToJson, importRulesFromJson } from '../utils/storage';
import { PhotoRecord } from '../types';

// Declare saveAs
declare const saveAs: any;

interface RefineModalProps {
  lang: 'en' | 'ja';
  photos: PhotoRecord[]; // Current photos to analyze context
  onClose: () => void;
  onRunAnalysis: (instruction: string, batchSize: number) => void;
}

const STORAGE_KEY_PROMPT = 'gemini_last_refine_prompt';

const PRESET_RULES: Partial<AnalysisRule>[] = [
  {
    name: "安全管理重点 (Safety Focus)",
    instruction: "Describe safety measures in detail. Mention safety cones, helmets, barricades, and signage visible in the 'Description' field.",
    tags: ["安全", "保安", "Safety"]
  },
  {
    name: "機材・機械抽出 (Equipment List)",
    instruction: "List all construction machinery (excavators, rollers, dump trucks) visible in the photo in the 'Description' or 'Remarks'.",
    tags: ["機械", "重機", "Equipment"]
  },
  {
    name: "黒板情報厳守 (Strict Blackboard)",
    instruction: "Do NOT infer Station or Work Type from visual context. Only extract text that is clearly legible on the blackboard. If illegible, leave blank.",
    tags: ["黒板", "OCR", "Strict"]
  },
  {
    name: "英語出力 (English Output)",
    instruction: "Translate all output fields (Work Type, Remarks, Description) into English.",
    tags: ["翻訳", "English"]
  }
];

const RefineModal: React.FC<RefineModalProps> = ({ lang, photos, onClose, onRunAnalysis }) => {
  const txt = TRANS[lang];
  const [customPrompt, setCustomPrompt] = useState("");
  const [ruleName, setRuleName] = useState("");
  const [ruleTags, setRuleTags] = useState(""); // Comma separated tags
  const [selectedRuleId, setSelectedRuleId] = useState<string | null>(null); 
  const [checkedRuleIds, setCheckedRuleIds] = useState<string[]>([]); 
  const [savedRules, setSavedRules] = useState<AnalysisRule[]>([]);
  const [batchSize, setBatchSize] = useState(6);
  const [autoMatchedCount, setAutoMatchedCount] = useState(0);
  const [searchTerm, setSearchTerm] = useState("");
  const fileInputRef = useRef<HTMLInputElement>(null);

  useEffect(() => {
    // 1. Restore last used prompt from storage
    const lastPrompt = localStorage.getItem(STORAGE_KEY_PROMPT) || "";
    if (lastPrompt) {
      setCustomPrompt(lastPrompt);
    }

    // 2. Load rules and auto-match
    getRules().then(rules => {
      setSavedRules(rules);
      
      // Only auto-fill if prompt is empty to avoid overwriting user's ongoing work
      if (!lastPrompt) {
        autoSelectRules(rules);
      } else {
        // Still calculate match count for notification
        const count = countMatches(rules);
        setAutoMatchedCount(count);
      }
    });
  }, []); // Run once on mount

  // Save prompt to storage whenever it changes
  useEffect(() => {
    localStorage.setItem(STORAGE_KEY_PROMPT, customPrompt);
  }, [customPrompt]);

  const countMatches = (rules: AnalysisRule[]): number => {
    const contextText = photos.map(p => 
      `${p.fileName} ${p.analysis?.workType || ''} ${p.analysis?.remarks || ''} ${p.analysis?.description || ''}`
    ).join(' ').toLowerCase();

    let count = 0;
    rules.forEach(rule => {
      if (!rule.tags || rule.tags.length === 0) return;
      const isMatch = rule.tags.some(tag => {
        const cleanTag = tag.trim().toLowerCase();
        return cleanTag && contextText.includes(cleanTag);
      });
      if (isMatch) count++;
    });
    return count;
  };

  // "Smart" Auto-Selection Logic
  const autoSelectRules = (rules: AnalysisRule[]) => {
    // Gather context from current photos
    const contextText = photos.map(p => 
      `${p.fileName} ${p.analysis?.workType || ''} ${p.analysis?.remarks || ''} ${p.analysis?.description || ''}`
    ).join(' ').toLowerCase();

    const matchedIds: string[] = [];
    
    rules.forEach(rule => {
      if (!rule.tags || rule.tags.length === 0) return;
      
      // Check if any tag matches the context
      const isMatch = rule.tags.some(tag => {
        const cleanTag = tag.trim().toLowerCase();
        return cleanTag && contextText.includes(cleanTag);
      });

      if (isMatch) {
        matchedIds.push(rule.id);
      }
    });

    if (matchedIds.length > 0) {
      setCheckedRuleIds(matchedIds);
      setAutoMatchedCount(matchedIds.length);
      
      // Construct initial prompt from matched rules
      const combinedInstruction = rules
        .filter(r => matchedIds.includes(r.id))
        .map(r => r.instruction)
        .join('\n\n');
      setCustomPrompt(combinedInstruction);
    }
  };

  const handleSaveRule = async (autoName?: string) => {
    const promptToSave = customPrompt.trim();
    if (!promptToSave) return;
    
    const nameToSave = ruleName.trim() || autoName;
    if (!nameToSave) return;

    // Process tags
    const tagsArray = ruleTags.split(/,|、/).map(t => t.trim()).filter(t => t.length > 0);

    const id = selectedRuleId || Date.now().toString();
    const newRule: AnalysisRule = {
      id: id,
      name: nameToSave,
      instruction: promptToSave,
      tags: tagsArray
    };

    await saveRule(newRule);
    setSavedRules(prev => {
      if (selectedRuleId) {
        return prev.map(r => r.id === selectedRuleId ? newRule : r);
      }
      return [...prev, newRule];
    });
    
    // Reset edit state
    handleResetForm();
  };

  const handleDeleteRule = async (id: string) => {
    await deleteRule(id);
    setSavedRules(prev => prev.filter(r => r.id !== id));
    if (selectedRuleId === id) {
      handleResetForm();
    }
    if (checkedRuleIds.includes(id)) {
      setCheckedRuleIds(prev => prev.filter(cid => cid !== id));
    }
  };

  const handleLoadPresets = async () => {
    if (!confirm(lang === 'ja' ? "おすすめルールを追加しますか？" : "Add recommended rules?")) return;
    
    for (const preset of PRESET_RULES) {
      // Check for duplicates by name
      if (!savedRules.some(r => r.name === preset.name)) {
        const newRule: AnalysisRule = {
          id: Date.now().toString() + Math.random().toString().slice(2, 5),
          name: preset.name!,
          instruction: preset.instruction!,
          tags: preset.tags
        };
        await saveRule(newRule);
      }
    }
    const updatedRules = await getRules();
    setSavedRules(updatedRules);
  };

  const handleToggleRule = (rule: AnalysisRule) => {
    const isChecked = checkedRuleIds.includes(rule.id);
    let newCheckedIds: string[];
    let newPrompt = customPrompt;

    if (isChecked) {
      newCheckedIds = checkedRuleIds.filter(id => id !== rule.id);
      // Try to remove text (simple check)
      if (newPrompt.includes(rule.instruction)) {
         newPrompt = newPrompt.replace(rule.instruction, "").trim();
      }
    } else {
      newCheckedIds = [...checkedRuleIds, rule.id];
      // Append if not already present
      if (!newPrompt.includes(rule.instruction)) {
         newPrompt = newPrompt ? newPrompt + "\n\n" + rule.instruction : rule.instruction;
      }
    }
    
    // Clean up newlines
    newPrompt = newPrompt.replace(/\n{3,}/g, '\n\n').trim();

    setCheckedRuleIds(newCheckedIds);
    setCustomPrompt(newPrompt);
    
    if (selectedRuleId && selectedRuleId !== rule.id) {
      handleResetForm();
    }
  };

  const handleSelectRuleForEdit = (e: React.MouseEvent, rule: AnalysisRule) => {
    e.stopPropagation();
    setCheckedRuleIds([]); // Clear composition when editing
    setCustomPrompt(rule.instruction);
    setRuleName(rule.name);
    setRuleTags(rule.tags?.join(", ") || "");
    setSelectedRuleId(rule.id);
  };

  const handleResetForm = () => {
    setCustomPrompt("");
    setRuleName("");
    setRuleTags("");
    setSelectedRuleId(null);
    setCheckedRuleIds([]);
    setAutoMatchedCount(0);
  };

  const handleExportRules = () => {
    if (savedRules.length === 0) return;
    const jsonStr = exportRulesToJson(savedRules);
    const blob = new Blob([jsonStr], { type: 'application/json' });
    saveAs(blob, `construction_ai_rules_${new Date().toISOString().slice(0, 10)}.json`);
  };

  const handleImportRules = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (!e.target.files || e.target.files.length === 0) return;
    const file = e.target.files[0];
    const reader = new FileReader();
    reader.onload = async (ev) => {
      try {
        const importedRules = importRulesFromJson(ev.target?.result as string);
        for (const rule of importedRules) {
          await saveRule(rule);
        }
        const updatedRules = await getRules();
        setSavedRules(updatedRules);
        alert(lang === 'ja' ? `${importedRules.length}件のルールをインポートしました。` : `Imported ${importedRules.length} rules.`);
      } catch (err) {
        alert(lang === 'ja' ? "ルールの読み込みに失敗しました。" : "Failed to import rules.");
      } finally {
        if (fileInputRef.current) fileInputRef.current.value = '';
      }
    };
    reader.readAsText(file);
  };

  const handleRunClick = async () => {
    if (!customPrompt.trim()) return;

    if (!ruleName.trim() && !selectedRuleId) {
      // Auto-generate name logic...
      let autoName = customPrompt.split(/[。\n]/)[0].substring(0, 20);
      if (customPrompt.length > 20) autoName += "...";
      await handleSaveRule(autoName);
    } else if (ruleName.trim()) {
      await handleSaveRule();
    }

    onRunAnalysis(customPrompt, batchSize);
  };

  const handleReanalyzeAll = () => {
    if (confirm(lang === 'ja' 
      ? "現在表示中のすべての写真を再解析しますか？\n手動で修正した箇所は維持されますが、それ以外の項目は最新のAIロジックで上書きされます。" 
      : "Re-analyze all photos?\nManual edits will be preserved, but other fields will be overwritten by the latest AI logic.")) {
       onRunAnalysis("__REANALYZE__", batchSize);
    }
  };

  // Filter rules based on search
  const filteredRules = savedRules.filter(r => 
    searchTerm === "" || 
    r.name.toLowerCase().includes(searchTerm.toLowerCase()) || 
    r.tags?.some(t => t.toLowerCase().includes(searchTerm.toLowerCase()))
  );

  return (
    <div className="fixed inset-0 z-[200] bg-black/50 flex items-center justify-center p-4">
      <div className="bg-white rounded-xl shadow-2xl max-w-lg w-full p-6 animate-in fade-in zoom-in duration-200 max-h-[90vh] overflow-y-auto flex flex-col">
         <div className="flex items-center gap-3 mb-2 text-purple-600">
            <Wand2 className="w-8 h-8" />
            <h3 className="text-xl font-bold">{txt.refineTitle}</h3>
         </div>
         <p className="text-gray-600 text-sm mb-4">{txt.refineDesc}</p>

         {/* Batch Size Slider */}
         <div className="mb-4 bg-blue-50 p-3 rounded-lg border border-blue-100">
            <div className="flex justify-between items-center mb-1">
              <label className="text-xs font-bold text-blue-800">Batch Size (Speed vs Quality)</label>
              <span className="text-xs font-mono bg-white px-2 py-0.5 rounded border border-blue-200">{batchSize} photos/req</span>
            </div>
            <input 
              type="range" 
              min="1" 
              max="15" 
              value={batchSize} 
              onChange={(e) => setBatchSize(parseInt(e.target.value))}
              className="w-full h-2 bg-blue-200 rounded-lg appearance-none cursor-pointer"
            />
            <div className="flex justify-between text-[10px] text-gray-500 mt-1">
               <span>1 (Slow, Precise)</span>
               <span>15 (Fast)</span>
            </div>
         </div>

         {/* Instruction Input */}
         <div className="mb-4">
           <textarea
             value={customPrompt}
             onChange={(e) => setCustomPrompt(e.target.value)}
             placeholder={txt.refinePlaceholder}
             className="w-full h-32 border border-gray-300 rounded-lg p-3 text-base bg-white text-gray-900 placeholder-gray-500 focus:ring-2 focus:ring-purple-500 outline-none resize-none font-mono text-sm"
           />
         </div>

         {/* Rule Management Section */}
         <div className="mb-6 bg-gray-50 p-4 rounded-lg border border-gray-200">
            <div className="flex justify-between items-center mb-2">
              <label className="flex items-center gap-2 font-bold text-gray-700 text-sm">
                 <Save className="w-4 h-4" /> {txt.saveRuleLabel}
              </label>
              {selectedRuleId ? (
                <button onClick={handleResetForm} className="text-xs flex items-center gap-1 text-red-600 hover:text-red-800 font-bold bg-red-50 px-2 py-1 rounded border border-red-200">
                  <X className="w-3 h-3" /> {txt.cancelEdit}
                </button>
              ) : (
                <button onClick={handleResetForm} className="text-xs flex items-center gap-1 text-gray-500 hover:text-gray-700 font-bold bg-white px-2 py-1 rounded border border-gray-200">
                   <PlusCircle className="w-3 h-3" /> {txt.newRule}
                </button>
              )}
            </div>
            
            <div className="flex flex-col gap-2">
              <input 
                type="text" 
                value={ruleName}
                onChange={(e) => setRuleName(e.target.value)}
                placeholder={txt.ruleNamePlaceholder}
                className="w-full border border-gray-300 rounded p-2 text-sm focus:ring-2 focus:ring-purple-500 outline-none"
              />
              <div className="flex gap-2">
                 <div className="flex-1 relative">
                    <Tag className="w-4 h-4 text-gray-400 absolute left-2 top-2.5" />
                    <input 
                      type="text" 
                      value={ruleTags}
                      onChange={(e) => setRuleTags(e.target.value)}
                      placeholder={lang === 'ja' ? "タグ（カンマ区切り：舗装, 完了, 例外...）" : "Tags (comma separated: Paving, Done...)"}
                      className="w-full border border-gray-300 rounded p-2 pl-8 text-sm focus:ring-2 focus:ring-purple-500 outline-none"
                    />
                 </div>
                 <button 
                  onClick={() => handleSaveRule()}
                  disabled={!customPrompt.trim()}
                  className="px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white text-sm font-bold rounded shadow disabled:opacity-50 flex items-center gap-2 whitespace-nowrap"
                >
                  {selectedRuleId ? txt.btnUpdateRule : txt.btnSaveRule}
                </button>
              </div>
            </div>
         </div>

         {/* Saved Rules List Header */}
         <div className="mb-2 flex flex-col gap-2">
           <div className="flex justify-between items-center">
              <h4 className="text-sm font-bold text-gray-700">{txt.savedRulesTitle}</h4>
              <button 
                onClick={handleLoadPresets}
                className="text-xs flex items-center gap-1 text-blue-600 hover:text-blue-800 bg-blue-50 px-2 py-1 rounded border border-blue-200 transition-colors"
              >
                <Library className="w-3 h-3" /> {txt.loadPreset}
              </button>
           </div>
           
           {/* Search Bar */}
           <div className="relative">
             <Search className="w-4 h-4 text-gray-400 absolute left-2 top-2.5" />
             <input 
               type="text" 
               value={searchTerm}
               onChange={(e) => setSearchTerm(e.target.value)}
               placeholder={txt.searchPlaceholder}
               className="w-full pl-8 pr-2 py-2 text-sm border border-gray-200 rounded-lg focus:ring-1 focus:ring-purple-400 outline-none bg-gray-50"
             />
           </div>

           {autoMatchedCount > 0 && (
              <div className="text-xs font-bold text-amber-600 bg-amber-50 px-2 py-1 rounded flex items-center gap-1 animate-pulse">
                 <Lightbulb className="w-3 h-3" /> {lang === 'ja' ? `AIが ${autoMatchedCount}件 推奨中` : `AI suggests ${autoMatchedCount} rules`}
              </div>
            )}
         </div>

         {/* Saved Rules List Body */}
         <div className="mb-4 flex-1 min-h-0 flex flex-col border border-gray-100 rounded p-1 bg-gray-50/50">
           {filteredRules.length === 0 ? (
             <div className="p-4 text-center text-gray-400 text-xs italic">
               {savedRules.length === 0 ? txt.noRulesYet : "No matching rules found."}
             </div>
           ) : (
             <div className="space-y-2 overflow-y-auto pr-1 max-h-40">
               {filteredRules.map(rule => {
                 const isChecked = checkedRuleIds.includes(rule.id);
                 const isEditing = selectedRuleId === rule.id;
                 const hasTags = rule.tags && rule.tags.length > 0;
                 return (
                  <div 
                    key={rule.id} 
                    onClick={() => handleToggleRule(rule)}
                    className={`flex items-center justify-between p-2 rounded border group cursor-pointer transition-all ${
                      isEditing 
                        ? 'bg-purple-100 border-purple-400 ring-1 ring-purple-400' 
                        : isChecked 
                          ? 'bg-blue-50 border-blue-200' 
                          : 'bg-white border-gray-200 hover:border-purple-300'
                    }`}
                  >
                    <div className="flex items-center gap-3 flex-1 min-w-0">
                       <div className="text-gray-500 hover:text-blue-600 flex-shrink-0">
                         {isChecked ? <CheckSquare className="w-5 h-5 text-blue-600" /> : <Square className="w-5 h-5" />}
                       </div>
                       <div className="flex flex-col truncate">
                          <span className={`text-sm font-medium truncate ${isChecked ? 'text-blue-800 font-bold' : 'text-gray-700'}`}>
                            {rule.name}
                          </span>
                          {hasTags && (
                             <div className="flex gap-1 overflow-hidden">
                                {rule.tags!.map(tag => (
                                   <span key={tag} className="text-[10px] bg-gray-100 text-gray-500 px-1 rounded border border-gray-200 truncate max-w-[60px]">{tag}</span>
                                ))}
                             </div>
                          )}
                       </div>
                    </div>
                    
                    <div className="flex items-center gap-1 pl-2">
                      <button 
                         onClick={(e) => handleSelectRuleForEdit(e, rule)}
                         className={`p-2 rounded-full hover:bg-purple-100 transition-colors ${isEditing ? 'text-purple-600 bg-purple-100' : 'text-gray-400'}`}
                         title="Edit"
                      >
                         <Edit2 className="w-4 h-4" />
                      </button>
                      <button 
                        onClick={(e) => { e.stopPropagation(); handleDeleteRule(rule.id); }}
                        className="p-2 text-gray-400 hover:text-red-500 hover:bg-red-50 rounded-full transition-colors"
                        title="Delete"
                      >
                        <Trash2 className="w-4 h-4" />
                      </button>
                    </div>
                  </div>
                 );
               })}
             </div>
           )}
         </div>

         {/* Footer Actions */}
         <div className="flex justify-between items-center pt-2 pb-4 border-b border-gray-100 mb-4">
            <div className="text-xs text-gray-400 font-bold uppercase tracking-wide">Data Options</div>
            <div className="flex gap-2">
               <button onClick={handleExportRules} disabled={savedRules.length === 0} className="text-xs flex items-center gap-1 text-gray-500 hover:text-gray-700 px-2 py-1 bg-gray-100 rounded disabled:opacity-50">
                 <Download className="w-3 h-3" /> JSON
               </button>
               <button onClick={() => fileInputRef.current?.click()} className="text-xs flex items-center gap-1 text-gray-500 hover:text-gray-700 px-2 py-1 bg-gray-100 rounded">
                 <Upload className="w-3 h-3" /> Import
               </button>
               <input type="file" ref={fileInputRef} className="hidden" accept=".json" onChange={handleImportRules} />
            </div>
         </div>
         
         {/* Re-analyze Button */}
         <div className="mb-4">
            <button 
              onClick={handleReanalyzeAll}
              className="w-full py-2 bg-amber-100 hover:bg-amber-200 text-amber-900 border border-amber-300 rounded-lg text-sm font-bold flex items-center justify-center gap-2 transition-colors"
            >
              <RefreshCw className="w-4 h-4" /> {txt.btnReanalyzeAll}
            </button>
         </div>

         <div className="flex gap-3">
           <button onClick={onClose} className="flex-1 py-3 bg-gray-200 hover:bg-gray-300 text-gray-700 rounded-lg font-bold transition-colors">{txt.btnCancel}</button>
           <button 
             onClick={handleRunClick} 
             disabled={!customPrompt.trim()}
             className="flex-[2] py-3 bg-blue-600 hover:bg-blue-700 text-white rounded-lg font-bold shadow-md disabled:opacity-50 flex items-center justify-center gap-2 transition-all transform hover:scale-[1.02]"
           >
             <Play className="w-5 h-5 fill-current" /> {txt.btnRefine}
           </button>
         </div>
      </div>
    </div>
  );
};

export default RefineModal;

//===============================================================================
// FILE: components/PreviewView.tsx
//===============================================================================

import React, { useState, useRef, useEffect } from 'react';
import { FileText, Loader2, Download, Printer, AlertCircle, ZoomIn, Maximize, Home, Wand2, X, Database, FileArchive, Layers, GitCompare, CalendarClock } from 'lucide-react';
import { TRANS } from '../utils/translations';
import { PhotoRecord, ProcessingStats, AppMode, AIAnalysisResult, LogEntry } from '../types';
import PhotoAlbumView from './PhotoAlbumView';
import ConsolePanel from './ConsolePanel';
import { generateZip } from '../utils/zipGenerator';

// Declare html2pdf and saveAs
declare const html2pdf: any;
declare const saveAs: any;

const A4_WIDTH_PX = 794;

interface PreviewViewProps {
  lang: 'en' | 'ja';
  photos: PhotoRecord[];
  stats: ProcessingStats;
  appMode: AppMode;
  isProcessing: boolean;
  currentStep: string;
  errorMsg: string | null;
  successMsg: string | null;
  logs: LogEntry[];
  initialLayout?: 2 | 3;
  onClearLogs: () => void;
  onGoHome: () => void;
  onCloseProject: () => void;
  onRefine: () => void;
  onExportExcel: (photosPerPage: 2 | 3) => void;
  onUpdatePhoto: (fileName: string, field: keyof AIAnalysisResult, value: string) => void;
  onDeletePhoto: (fileName: string) => void;
  onAutoPair: () => void;
  onSortByDate: () => void;
  onSendInstruction?: (instruction: string) => void;
}

const PreviewView: React.FC<PreviewViewProps> = ({
  lang,
  photos,
  stats,
  appMode,
  isProcessing,
  currentStep,
  errorMsg,
  successMsg,
  logs,
  initialLayout = 3,
  onClearLogs,
  onGoHome,
  onCloseProject,
  onRefine,
  onExportExcel,
  onUpdatePhoto,
  onDeletePhoto,
  onAutoPair,
  onSortByDate,
  onSendInstruction
}) => {
  const txt = TRANS[lang];
  const [scale, setScale] = useState(1);
  const [isFitMode, setIsFitMode] = useState(true);
  const [isGeneratingPdf, setIsGeneratingPdf] = useState(false);
  const [isGeneratingZip, setIsGeneratingZip] = useState(false);
  const [showConsole, setShowConsole] = useState(true); // Default to True
  const [photosPerPage, setPhotosPerPage] = useState<2 | 3>(initialLayout);
  const previewContainerRef = useRef<HTMLDivElement>(null);

  // Sync photosPerPage if initialLayout changes (e.g. after auto-pair finishes)
  useEffect(() => {
    setPhotosPerPage(initialLayout);
  }, [initialLayout]);

  // Auto-Calculate Scale for Mobile
  useEffect(() => {
    const handleResize = () => {
      if (!previewContainerRef.current) return;
      const containerWidth = previewContainerRef.current.clientWidth;
      const availableWidth = containerWidth - 32;
      if (isFitMode) {
        const newScale = availableWidth < A4_WIDTH_PX ? availableWidth / A4_WIDTH_PX : 1;
        setScale(newScale);
      } else {
        setScale(1);
      }
    };
    window.addEventListener('resize', handleResize);
    handleResize(); 
    return () => window.removeEventListener('resize', handleResize);
  }, [isFitMode]);

  const handleDownloadPDF = () => {
    if (typeof html2pdf === 'undefined') {
      alert("PDF library not loaded.");
      return;
    }

    setIsGeneratingPdf(true);
    const element = document.getElementById('album-content');
    if (element) element.classList.add('pdf-mode');

    const filename = `construction_album_${new Date().toISOString().slice(0, 10)}.pdf`;

    const opt = {
      margin: 0,
      filename: filename,
      image: { type: 'jpeg', quality: 1.0 },
      html2canvas: { scale: 3, useCORS: true, logging: false },
      jsPDF: { unit: 'mm', format: 'a4', orientation: 'portrait' },
      pagebreak: { mode: 'css', after: '.sheet-preview' }
    };

    html2pdf().set(opt).from(element).output('blob').then((blob: Blob) => {
      saveAs(blob, filename);
      const url = URL.createObjectURL(blob);
      window.open(url, '_blank');
      setIsGeneratingPdf(false);
      if (element) element.classList.remove('pdf-mode');
    }).catch((err: any) => {
      console.error(err);
      setIsGeneratingPdf(false);
      if (element) element.classList.remove('pdf-mode');
      alert(txt.pdfError);
    });
  };

  const handleDownloadZip = async () => {
    if (photos.length === 0) return;
    setIsGeneratingZip(true);
    try {
      const blob = await generateZip(photos);
      const filename = `electronic_delivery_${new Date().toISOString().slice(0, 10)}.zip`;
      saveAs(blob, filename);
    } catch (e) {
      console.error(e);
      alert("Failed to generate ZIP.");
    } finally {
      setIsGeneratingZip(false);
    }
  };

  const handleAutoPairClick = () => {
    // Automatically switch to 2-up view for pairs as it's the intended layout for before/after
    if (photosPerPage !== 2) {
      setPhotosPerPage(2);
    }
    onAutoPair();
  };

  const hasPhotosWithBoard = photos.some(p => p.analysis?.hasBoard);
  return (
    <div className="fixed inset-0 z-[100] bg-gray-200 overflow-hidden flex flex-col">
      <div className="sticky top-0 z-[101] bg-slate-800 text-white p-3 shadow-md flex justify-between items-center">
         <div className="flex items-center gap-2 md:gap-4 overflow-hidden">
           
           <div className="flex gap-2 text-xs md:text-sm bg-slate-700 px-2 py-1 rounded-lg flex-shrink 0 whitespace-nowrap items-center">
              <span className="text-slate-300">{txt.total}: {stats.total}</span>
              <span className="text-green-400">{txt.done}: {stats.success}</span>
              {stats.cached > 0 && (
                 <span className="text-green-300 flex items-center gap-1 border-l border-slate-600 pl-2 font-bold animate-in fade-in">
                    <Database className="w-3 h-3" /> Cached: {stats.cached}
                 </span>
              )}
              {isProcessing && <span className="text-amber-300 animate-pulse flex items-center gap-1 border-l border-slate-600 pl-2"><Loader2 className="w-3 h-3 animate-spin"/> {currentStep.split('(')[0]}</span>}
           </div>
         </div>

         <div className="flex gap-2 items-center">


            {/* Refine Button */}
            <button 
              onClick={onRefine}
              className="p-2 bg-purple-600 hover:bg-purple-500 rounded text-white shadow-lg shadow-purple-900/20 mr-2"
              disabled={isProcessing}
              title={txt.refineTitle}
            >
              <Wand2 className="w-4 h-4" />
            </button>



            <button onClick={onGoHome} className="p-2 bg-slate-700 hover:bg-blue-600 rounded text-slate-300 hover:text-white transition-colors" title={txt.backHome}>
              <Home className="w-4 h-4" />
            </button>

            {/* Layout Switcher - show when photos have boards */}
            {hasPhotosWithBoard && (
              <div className="flex bg-slate-700 rounded overflow-hidden ml-2">
                <button
                  onClick={() => setPhotosPerPage(2)}
                  className={`px-3 py-2 text-xs font-medium transition-colors ${
                    photosPerPage === 2 ? "bg-amber-500 text-white" : "text-slate-300 hover:bg-slate-600"
                  }`}
                  title="2枚/ページ"
                >
                  2枚
                </button>
                <button
                  onClick={() => setPhotosPerPage(3)}
                  className={`px-3 py-2 text-xs font-medium transition-colors ${
                    photosPerPage === 3 ? "bg-amber-500 text-white" : "text-slate-300 hover:bg-slate-600"
                  }`}
                  title="3枚/ページ"
                >
                  3枚
                </button>
              </div>
            )}

            <div className="flex gap-1 ml-1">
              <button onClick={() => onExportExcel(photosPerPage)} disabled={isProcessing} className="p-2 md:px-4 md:py-2 bg-green-600 hover:bg-green-700 text-white rounded text-sm font-bold shadow-sm flex items-center gap-2" title={txt.exportExcel}>
                  <Download className="w-4 h-4" /> <span className="hidden md:inline">{txt.exportExcel}</span>
              </button>
              
              {appMode === 'construction' && (
                <button onClick={handleDownloadZip} disabled={isGeneratingZip || isProcessing} className="p-2 md:px-4 md:py-2 bg-blue-500 hover:bg-blue-600 rounded text-sm font-bold text-white shadow-sm flex items-center gap-2" title="Electronic Delivery (XML/ZIP)">
                  {isGeneratingZip ? <Loader2 className="w-4 h-4 animate-spin" /> : <FileArchive className="w-4 h-4" />} <span className="hidden md:inline">XML/ZIP</span>
                </button>
              )}

              <button onClick={handleDownloadPDF} disabled={isGeneratingPdf || isProcessing} className="p-2 md:px-4 md:py-2 bg-red-600 hover:bg-red-700 rounded text-sm font-bold text-white shadow-sm flex items-center gap-2" title={txt.exportPDF}>
                {isGeneratingPdf ? <Loader2 className="w-4 h-4 animate-spin" /> : <Printer className="w-4 h-4" />} <span className="hidden md:inline">{isGeneratingPdf ? "..." : txt.exportPDF}</span>
              </button>
            </div>
         </div>
      </div>
      
      {errorMsg && (
         <div className="absolute top-20 left-1/2 transform -translate-x-1/2 z-[102] bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded shadow-lg flex items-center gap-2 max-w-[90vw]">
           <AlertCircle className="w-5 h-5 flex-shrink-0" /> <span className="text-sm font-medium break-words">{errorMsg}</span>
         </div>
      )}
      
      {successMsg && (
         <div className="absolute top-32 left-1/2 transform -translate-x-1/2 z-[102] bg-green-100 border border-green-400 text-green-700 px-4 py-3 rounded shadow-lg flex items-center gap-2 max-w-[90vw] animate-in fade-in slide-in-from-top-4">
           <Database className="w-5 h-5 flex-shrink-0" /> <span className="text-sm font-medium break-words">{successMsg}</span>
         </div>
      )}

      <div id="print-area" ref={previewContainerRef} className="flex-1 p-4 md:p-8 flex flex-col items-center overflow-auto bg-gray-200 w-full relative">
         <div style={{ transform: `scale(${scale})`, transformOrigin: 'top center', marginBottom: scale < 1 ? `-${(1 - scale) * 50}%` : '0', minWidth: '210mm' }}>
            <PhotoAlbumView 
              records={photos} 
              appMode={appMode} 
              lang={lang} 
              photosPerPage={photosPerPage}
              onUpdatePhoto={onUpdatePhoto}
              onDeletePhoto={onDeletePhoto}
            />
         </div>
         
         {/* Console Panel Component */}
         <ConsolePanel 
           logs={logs}
           isOpen={showConsole}
           onToggle={() => setShowConsole(!showConsole)}
           onClear={onClearLogs}
           isProcessing={isProcessing}
           onSendInstruction={onSendInstruction}
         />
      </div>
    </div>
  );
};

export default PreviewView;


//===============================================================================
// FILE: App.tsx
//===============================================================================
﻿
import React, { useState, useEffect } from 'react';
import { PhotoRecord, ProcessingStats, AIAnalysisResult, AppMode, LogEntry } from './types';
import { processImageForAI, getPhotoDate } from './utils/imageUtils';
import { analyzePhotoBatch, identifyTargetPhotos, normalizeDataConsistency, assignSceneIds, refinePairContext } from './services/geminiService';
import { processPhotosWithSmartFlow } from './services/smartFlowService';
import { generateExcel } from './utils/excelGenerator';
import { saveProjectData, loadProjectData, clearProjectData, getCachedAnalysis, cacheAnalysis, exportDataToJson, importDataFromJson, clearAnalysisCache } from './utils/storage';
import { fsCache } from './utils/fileSystemCache';
import { TRANS } from './utils/translations';

// Components
import UploadView from './components/UploadView';
import PreviewView from './components/PreviewView';
import LimitModal from './components/LimitModal';
import RefineModal from './components/RefineModal';

// Declare saveAs for export
declare const saveAs: any;

const DEFAULT_BATCH_SIZE = 3;
const MAX_PHOTOS = 30;
const LOCAL_STORAGE_KEY = 'gemini_api_key';

type PendingFile = { file: File, date: number };

export default function App() {
  // API Key Management: Env -> LocalStorage -> Empty
  const [apiKey, setApiKey] = useState<string>(() => {
    return process.env.API_KEY || localStorage.getItem(LOCAL_STORAGE_KEY) || "";
  });

  const [photos, setPhotos] = useState<PhotoRecord[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [currentStep, setCurrentStep] = useState<string>("");
  const [stats, setStats] = useState<ProcessingStats>({ total: 0, processed: 0, success: 0, failed: 0, cached: 0 });
  const [errorMsg, setErrorMsg] = useState<string | null>(null);
  const [successMsg, setSuccessMsg] = useState<string | null>(null);
  const [showPreview, setShowPreview] = useState(false);
  const [isStorageLoaded, setIsStorageLoaded] = useState(false);
  const [appMode, setAppMode] = useState<AppMode>('construction');
  const [initialLayout, setInitialLayout] = useState<2 | 3>(3); // Default to 3-up

  // Console Logs
  const [logs, setLogs] = useState<LogEntry[]>([]);

  // Modals
  const [pendingFiles, setPendingFiles] = useState<PendingFile[] | null>(null);
  const [selectionStart, setSelectionStart] = useState(1);
  const [selectionCount, setSelectionCount] = useState(MAX_PHOTOS);
  const [showRefineModal, setShowRefineModal] = useState(false);
  // Store initial instruction if files are pending selection
  const [pendingInstruction, setPendingInstruction] = useState<string>("");
  const [pendingUseCache, setPendingUseCache] = useState<boolean>(true);

  // Active instruction management - tracks the currently effective instruction
  // Priority: refinementInstruction > initialInstruction
  const [initialInstruction, setInitialInstruction] = useState<string>("");
  const [activeInstruction, setActiveInstruction] = useState<string>("");

  // Language
  const [lang, setLang] = useState<'en' | 'ja'>('en');
  const txt = TRANS[lang];

  // File System Cache
  const [fsCacheEnabled, setFsCacheEnabled] = useState(false);
  const [fsCacheStats, setFsCacheStats] = useState<{ totalFiles: number; lastUpdated: string } | null>(null);

  // Analysis Abort Control
  const [shouldAbortAnalysis, setShouldAbortAnalysis] = useState(false);

  // Detect Language
  useEffect(() => {
    if (navigator.language.startsWith('ja')) setLang('ja');
  }, []);

  // Save API Key to local storage when updated
  useEffect(() => {
    if (apiKey) {
      localStorage.setItem(LOCAL_STORAGE_KEY, apiKey);
    }
  }, [apiKey]);

  // Load data
  useEffect(() => {
    const initLoad = async () => {
      try {
        // File System Cache 縺ｮ蠕ｩ蜈・ｒ隧ｦ縺ｿ繧・        if (fsCache.isAvailable()) {
          const restored = await fsCache.restoreHandle();
          if (restored) {
            setFsCacheEnabled(true);
            const stats = fsCache.getStats();
            setFsCacheStats(stats);
            addLog("File system cache restored from previous session.", 'success');
          }
        }

        const savedPhotos = await loadProjectData();
        if (savedPhotos && savedPhotos.length > 0) {
          setPhotos(savedPhotos);
          const success = savedPhotos.filter(p => p.status === 'done').length;
          const failed = savedPhotos.filter(p => p.status === 'error').length;
          const cached = savedPhotos.filter(p => p.fromCache).length;
          setStats({ total: savedPhotos.length, processed: success + failed, success, failed, cached });
          setShowPreview(true); // Restore view if data exists
          addLog("Restored previous session data.", 'success');
        }
      } catch (err) {
        console.error("Failed to load session", err);
      } finally {
        setIsStorageLoaded(true);
      }
    };
    initLoad();
  }, []);

  // Auto-Save
  useEffect(() => {
    if (!isStorageLoaded) return;
    const timer = setTimeout(() => {
      if (photos.length > 0) {
        saveProjectData(photos).catch(console.error);
      }
    }, 500); // Reduced to 500ms for snappier saves
    return () => clearTimeout(timer);
  }, [photos, isStorageLoaded]);

  // ESC Key Listener for Analysis Interruption
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape' && isProcessing) {
        setShouldAbortAnalysis(true);
        addLog("ESC pressed - aborting analysis...", 'info');
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [isProcessing]);

  // --- Helpers ---

  const addLog = (message: string, type: LogEntry['type'] = 'info', details?: any) => {
    const timestamp = new Date().toLocaleTimeString('ja-JP', { hour12: false });
    setLogs(prev => [...prev, { timestamp, message, type, details }]);
  };

  const logIndividualResult = (fileName: string, result: AIAnalysisResult) => {
    const summary = [
      `萄 ${fileName}`,
      result.workType && `蟾･遞ｮ: ${result.workType}`,
      result.variety && `遞ｮ蛻･: ${result.variety}`,
      result.detail && `邏ｰ蛻･: ${result.detail}`,
      result.station && `貂ｬ轤ｹ: ${result.station}`,
      result.remarks && `蛯呵・ ${result.remarks}`,
    ].filter(Boolean).join(' | ');

    addLog(summary, 'success', result);
  };

  const clearLogs = () => setLogs([]);

  // 繝励Ο繝ｳ繝励ヨ縺九ｉ貂ｬ轤ｹ蜷阪ｒ謚ｽ蜃ｺ縺吶ｋ蜈ｱ騾夐未謨ｰ
  const extractLocationName = (prompt: string): string => {
    // 繝代ち繝ｼ繝ｳ1: 縲梧ｸｬ轤ｹ縺ｯ縲・・→縺吶ｋ縲阪梧ｸｬ轤ｹ繧偵・・↓邨ｱ荳縲阪↑縺ｩ
    const sokuten1 = prompt.match(/貂ｬ轤ｹ[縺ｯ繧綻荳蠕九↓?([^縺ｨ縺ｫ縲√・n]+?)(?:[縺ｨ縺ｫ](?:邨ｱ荳|縺吶ｋ)|$)/);
    if (sokuten1) {
      return sokuten1[1].trim();
    }

    // 繝代ち繝ｼ繝ｳ2: 縲梧ｸｬ轤ｹ・壹・・阪梧ｸｬ轤ｹ:縲・・・    const sokuten2 = prompt.match(/貂ｬ轤ｹ[・・]\s*([^縲√・n]+)/);
    if (sokuten2) {
      return sokuten2[1].trim();
    }

    // 繝代ち繝ｼ繝ｳ3: 縲後・・ｻ倩ｿ代阪後・・慍轤ｹ縲阪↑縺ｩ繧貞性繧陦後ｒ謗｢縺・    const locationPattern = prompt.match(/([^縲√・n]*(?:莉倩ｿ掃蝨ｰ轤ｹ|蝨ｰ蛹ｺ|荳∫岼)[^縲√・n]*)/);
    if (locationPattern) {
      // 荳崎ｦ√↑蜑榊ｾ後ｒ蜑企勁
      const location = locationPattern[1]
        .replace(/^.*(?:貂ｬ轤ｹ[縺ｯ繧綻|蝣ｴ謇[縺ｯ繧綻|菴咲ｽｮ[縺ｯ繧綻|荳蠕九↓)/, '')
        .replace(/(?:[縺ｨ縺ｫ](?:邨ｱ荳|縺吶ｋ)|縺ｧ縺處縺ｧ縺ゅｋ).*$/, '')
        .trim();
      if (location) return location;
    }

    // 繝代ち繝ｼ繝ｳ4: 譛蛻昴・陦後ｒ蜿門ｾ暦ｼ医ヵ繧ｩ繝ｼ繝ｫ繝舌ャ繧ｯ・・    const lines = prompt.split('\n').filter(line => line.trim().length > 0);
    if (lines.length > 0) {
      const firstLine = lines[0].trim();
      // 縲後・・ｷ･莠九阪↑縺ｩ繧帝勁蜴ｻ
      const cleanedLine = firstLine.replace(/蟾･莠・*$/, '').trim();
      if (cleanedLine) {
        return cleanedLine.substring(0, 30);
      }
    }

    return '迴ｾ蝣ｴ';
  };

  // --- Logic Controllers ---

  // File System Cache 髢｢騾｣
  const handleSelectCacheFolder = async () => {
    if (!fsCache.isAvailable()) {
      setErrorMsg("File System Access API is not supported in this browser.");
      return;
    }

    try {
      const selected = await fsCache.selectDirectory();
      if (selected) {
        setFsCacheEnabled(true);
        await fsCache.saveHandle(); // 繝上Φ繝峨Ν繧剃ｿ晏ｭ・        const stats = fsCache.getStats();
        setFsCacheStats(stats);
        setSuccessMsg("Cache folder selected successfully!");
        addLog("File system cache enabled", 'success');
      }
    } catch (error) {
      console.error("Failed to select cache folder:", error);
      setErrorMsg("Failed to select cache folder. Please try again.");
    }
  };

  const handleClearFileSystemCache = async () => {
    if (!fsCacheEnabled) return;

    const confirmMsg = "Clear all file system cache?\n(This will remove all cached analysis results from the selected folder)";
    if (window.confirm(confirmMsg)) {
      await fsCache.clearCache();
      const stats = fsCache.getStats();
      setFsCacheStats(stats);
      setSuccessMsg("File system cache cleared!");
      addLog("File system cache cleared", 'info');
    }
  };

  const handleCloseProject = async () => {
    if (window.confirm(txt.resetConfirm)) {
      setPhotos([]);
      setStats({ total: 0, processed: 0, success: 0, failed: 0, cached: 0 });
      setErrorMsg(null);
      setSuccessMsg(null);
      setShowPreview(false);
      setPendingFiles(null);
      clearLogs();
      await clearProjectData();
    }
  };

  const handleClearCache = async () => {
    const msg = lang === 'ja'
      ? "隗｣譫先ｸ医∩縺ｮ繧ｭ繝｣繝・す繝･繝・・繧ｿ繧貞炎髯､縺励∪縺吶°・歃n・育樟蝨ｨ陦ｨ遉ｺ荳ｭ縺ｮ繝・・繧ｿ縺ｯ豸医∴縺ｾ縺帙ｓ縺後∵ｬ｡蝗樔ｻ･髯阪・隗｣譫舌〒API縺御ｽｿ逕ｨ縺輔ｌ縺ｾ縺呻ｼ・
      : "Clear analysis cache?\n(Current view is not affected, but next analysis will use API)";

    if (window.confirm(msg)) {
      await clearAnalysisCache();
      setStats(prev => ({ ...prev, cached: 0 }));
      setPhotos(prev => prev.map(p => ({ ...p, fromCache: false })));
      alert(lang === 'ja' ? "繧ｭ繝｣繝・す繝･繧貞炎髯､縺励∪縺励◆縲・ : "Cache cleared.");
      addLog("Cache cleared by user.", 'info');
    }
  };

  const handleDeletePhoto = (fileName: string) => {
    if (window.confirm(lang === 'ja' ? "縺薙・蜀咏悄繧貞炎髯､縺励※繧ゅｈ繧阪＠縺・〒縺吶°・・ : "Are you sure you want to delete this photo?")) {
      const updatedPhotos = photos.filter(p => p.fileName !== fileName);
      setPhotos(updatedPhotos);

      // Re-calculate stats
      const success = updatedPhotos.filter(p => p.status === 'done').length;
      const failed = updatedPhotos.filter(p => p.status === 'error').length;
      const cached = updatedPhotos.filter(p => p.fromCache).length;
      setStats({ total: updatedPhotos.length, processed: success + failed, success, failed, cached });
      addLog(`Deleted photo: ${fileName}`, 'info');
    }
  };

  const handleUpdatePhoto = (fileName: string, field: keyof AIAnalysisResult, value: string) => {
    setPhotos(prev => prev.map(p => {
      if (p.fileName === fileName && p.analysis) {
        // Track which fields are manually edited
        const editedFields = p.analysis.editedFields ? [...p.analysis.editedFields] : [];
        if (!editedFields.includes(field as string)) {
          editedFields.push(field as string);
        }

        const updatedAnalysis: AIAnalysisResult = {
          ...p.analysis,
          [field]: value,
          editedFields: editedFields
        };

        // Update persistent cache immediately so future loads reflect manual edits
        cacheAnalysis(p, updatedAnalysis).catch(e => console.error("Cache update failed", e));

        return {
          ...p,
          analysis: updatedAnalysis
        };
      }
      return p;
    }));
  };

  const handleResume = () => {
    setShowPreview(true);
  };

  // --- Sorting Logic ---

  const normalizeStationName = (raw: string | undefined): string => {
    if (!raw) return "";
    let s = raw.trim();
    if (!s) return "";
    s = s.replace(/[・・・枉/g, r => String.fromCharCode(r.charCodeAt(0) - 0xFEE0));
    s = s.replace(/\s+/g, "");
    // Remove "No." "NO" prefixes to match just the number if possible, or normalize valid prefixes
    if (/^(no|number|nu|nm)[^a-z]/i.test(s)) {
      s = s.replace(/^(no|number|nu|nm)\.?/i, "No.");
    }
    return s.toUpperCase();
  };

  const getPhaseScore = (r: PhotoRecord): number => {
    // Use AI determined phase if available
    if (r.analysis?.phase === 'before') return 0;
    if (r.analysis?.phase === 'status') return 1;
    if (r.analysis?.phase === 'after') return 2;

    // Fallback to text heuristics
    const text = ((r.analysis?.remarks || "") + (r.analysis?.variety || "") + (r.analysis?.workType || "")).toLowerCase();
    if (text.includes("逹謇句燕") || text.includes("before") || text.includes("pre")) return 0;
    if (text.includes("螳御ｺ・) || text.includes("遶｣蟾･") || text.includes("after") || text.includes("done")) return 2;
    return 1;
  };

  /**
   * Sorts photos based on Scene ID or Station.
   * This is the "Loose" sort used for initial display.
   */
  const sortPhotosLogical = (records: PhotoRecord[]): PhotoRecord[] => {
    const groups: { [key: string]: PhotoRecord[] } = {};
    const orphans: PhotoRecord[] = [];

    records.forEach(r => {
      let key = r.analysis?.sceneId;
      if (!key) {
        const station = normalizeStationName(r.analysis?.station);
        if (station && station !== "UNKNOWN") {
          key = "STATION_" + station;
        }
      }

      if (key) {
        if (!groups[key]) groups[key] = [];
        groups[key].push(r);
      } else {
        orphans.push(r);
      }
    });

    const sortGroup = (group: PhotoRecord[]) => {
      return group.sort((a, b) => {
        const scoreA = getPhaseScore(a);
        const scoreB = getPhaseScore(b);
        if (scoreA !== scoreB) return scoreA - scoreB;
        return (a.date || 0) - (b.date || 0);
      });
    };

    Object.keys(groups).forEach(key => {
      groups[key] = sortGroup(groups[key]);
    });

    const groupKeys = Object.keys(groups).sort((keyA, keyB) => {
      const groupA = groups[keyA];
      const groupB = groups[keyB];
      const maxDateA = Math.max(...groupA.map(r => r.date || 0));
      const maxDateB = Math.max(...groupB.map(r => r.date || 0));
      return maxDateA - maxDateB;
    });

    const sorted: PhotoRecord[] = [];
    groupKeys.forEach(key => {
      sorted.push(...groups[key]);
    });
    sorted.push(...orphans.sort((a, b) => (a.date || 0) - (b.date || 0)));

    return sorted;
  };

  /**
   * Proper Before-After Pairing for Construction Photos
   * Strategy:
   * 1. Group by SceneID/Station (location-based)
   * 2. Within each group, identify before and after photos
   * 3. Create actual pairs (before, after) for layout
   * 4. Arrange pairs in sequence for proper page layout
   */
  const arrangePairsStrictly = (records: PhotoRecord[]): { sorted: PhotoRecord[], pairCount: number, omittedCount: number } => {
    const groups: { [key: string]: PhotoRecord[] } = {};
    let omittedCount = 0;

    // 1. Grouping by scene or station
    records.forEach(r => {
      let key = r.analysis?.sceneId;
      if (!key) {
        const station = normalizeStationName(r.analysis?.station);
        if (station && station !== "UNKNOWN") {
          key = "STATION_" + station;
        }
      }

      if (key) {
        if (!groups[key]) groups[key] = [];
        groups[key].push(r);
      } else {
        // Photos without grouping are tracked but may be omitted from pairs
        omittedCount++;
      }
    });

    const pairs: PhotoRecord[][] = [];
    const groupKeys = Object.keys(groups);

    // Sort group keys for consistent ordering
    groupKeys.sort();

    groupKeys.forEach(key => {
      const group = groups[key];

      // Need at least 2 photos for a pair
      if (group.length < 2) {
        omittedCount += group.length;
        return;
      }

      // Sort by date within each group
      group.sort((a, b) => {
        if (a.date && b.date) return a.date - b.date;
        return (a.fileName || "").localeCompare(b.fileName || "");
      });

      // Identify before and after photos based on phase or position
      let beforePhoto: PhotoRecord | null = null;
      let afterPhoto: PhotoRecord | null = null;

      // First, try to find explicitly marked photos
      group.forEach(photo => {
        const remarks = photo.analysis?.remarks || "";
        const phase = photo.analysis?.phase;

        if (!beforePhoto && (phase === 'before' || remarks.includes("逹謇句燕") || remarks.includes("譁ｽ蟾･蜑・))) {
          beforePhoto = photo;
          if (photo.analysis) photo.analysis.phase = 'before';
        } else if (!afterPhoto && (phase === 'after' || remarks.includes("螳御ｺ・) || remarks.includes("螳梧・") || remarks.includes("遶｣蟾･"))) {
          afterPhoto = photo;
          if (photo.analysis) photo.analysis.phase = 'after';
        }
      });

      // If not found explicitly, use first and last
      if (!beforePhoto) {
        beforePhoto = group[0];
        if (beforePhoto.analysis) beforePhoto.analysis.phase = 'before';
      }
      if (!afterPhoto && group.length > 1) {
        afterPhoto = group[group.length - 1];
        if (afterPhoto.analysis) afterPhoto.analysis.phase = 'after';
      }

      // Create the pair if both photos exist
      if (beforePhoto && afterPhoto && beforePhoto !== afterPhoto) {
        pairs.push([beforePhoto, afterPhoto]);

        // Count omitted middle photos
        const usedPhotos = new Set([beforePhoto.fileName, afterPhoto.fileName]);
        group.forEach(photo => {
          if (!usedPhotos.has(photo.fileName)) {
            omittedCount++;
          }
        });
      } else {
        // Can't form a proper pair
        omittedCount += group.length;
      }
    });

    // Sort pairs by the date of the after photo (construction completion order)
    pairs.sort((a, b) => {
      const dateA = a[1].date || 0;
      const dateB = b[1].date || 0;
      return dateA - dateB;
    });

    // Flatten pairs into alternating before-after sequence
    const sorted: PhotoRecord[] = [];
    pairs.forEach(pair => {
      sorted.push(pair[0]); // before
      sorted.push(pair[1]); // after
    });

    return { sorted, pairCount: pairs.length, omittedCount };
  };

  /**
   * Hybrid Pairing with Persistence
   */
  const handleAutoPair = async () => {
    if (!apiKey) {
      alert(txt.permissionError);
      return;
    }

    setIsProcessing(true);
    setCurrentStep(txt.pairingProcessing);

    try {
      const records = [...photos];

      // 1. Separate: Already Paired vs Needs Pairing
      const needsAI: PhotoRecord[] = [];
      const hasStation: PhotoRecord[] = [];
      const alreadyPaired: PhotoRecord[] = [];

      records.forEach(r => {
        if (r.analysis?.sceneId && r.analysis.sceneId.startsWith("AI_S")) {
          alreadyPaired.push(r);
        } else {
          const station = normalizeStationName(r.analysis?.station);
          if (station && station !== "UNKNOWN") {
            hasStation.push(r);
          } else {
            needsAI.push(r);
          }
        }
      });

      // 2. Assign Logical IDs to Station photos (Instant)
      const updatedHasStation = hasStation.map(r => {
        const station = normalizeStationName(r.analysis?.station);
        // Force logical pairing based on station name equality
        return {
          ...r,
          analysis: {
            ...r.analysis!,
            sceneId: `LOGICAL_${station}`,
            // Phase is actually irrelevant for grouping in strict mode, but good for display
            phase: ((r.analysis?.remarks || "").includes("逹謇句燕") ? 'before' : (r.analysis?.remarks || "").includes("螳御ｺ・) ? 'after' : 'status') as any
          }
        };
      });

      // 3. Process Visual Candidates (AI)
      let updatedVisual: PhotoRecord[] = [...alreadyPaired];

      if (needsAI.length > 1) {
        try {
          // Use Gemini 3 Pro to group by visual anchors
          const assignments = await assignSceneIds(needsAI, apiKey, addLog);
          const assignmentMap = new Map(assignments.map(a => [a.fileName, a]));

          const processedAI = needsAI.map(r => {
            const assign = assignmentMap.get(r.fileName);
            if (assign) {
              return {
                ...r,
                analysis: {
                  ...r.analysis!,
                  sceneId: `AI_${assign.sceneId}`,
                  phase: assign.phase,
                  visualAnchors: assign.visualAnchors
                }
              };
            }
            return r;
          });

          updatedVisual = [...updatedVisual, ...processedAI];
          addLog(`Visual pairing created anchors for ${assignments.length} photos.`, 'success');

        } catch (e) {
          console.error("Visual pairing failed", e);
          addLog("Visual pairing failed - falling back to timestamp sort.", 'error');
          updatedVisual = [...updatedVisual, ...needsAI];
        }
      } else {
        updatedVisual = [...updatedVisual, ...needsAI];
      }

      // 4. Merge and Save to Cache
      const allUpdated = [...updatedHasStation, ...updatedVisual];

      allUpdated.forEach(r => {
        if (r.analysis) {
          cacheAnalysis(r, r.analysis).catch(console.error);
        }
      });

      // 5. Create before-after pairs
      const { sorted, pairCount, omittedCount } = arrangePairsStrictly(allUpdated);

      setPhotos(sorted);
      setSuccessMsg(lang === 'ja'
        ? `${pairCount}邨・・逹謇句燕-遶｣蟾･繝壹い繧剃ｽ懈・縺励∪縺励◆${omittedCount > 0 ? `・・{omittedCount}譫壹・髯､螟厄ｼ荏 : ''}`
        : `Created ${pairCount} before-after pairs${omittedCount > 0 ? ` (${omittedCount} photos omitted)` : ''}`);

    } catch (err: any) {
      console.error(err);
      setErrorMsg("Pairing failed: " + err.message);
      addLog("Pairing fatal error", 'error', err);
    } finally {
      setIsProcessing(false);
      setCurrentStep("");
    }
  };

  const handleSmartSort = () => {
    // Just sort by logical station/date without the strict pairing requirement
    const sorted = sortPhotosLogical([...photos]);
    setPhotos(sorted);
    setSuccessMsg(lang === 'ja' ? "貂ｬ轤ｹ繝ｻ繧ｷ繝ｼ繝ｳ諠・ｱ縺ｫ蝓ｺ縺･縺・※荳ｦ縺ｳ譖ｿ縺医∪縺励◆" : "Sorted by Scene & Phase");
  };

  // --- Pipeline Steps ---

  const handleStartProcessing = async (files: File[], userInstruction: string, useCache: boolean) => {
    if (!files || files.length === 0) return;

    // 1. Initial Validation
    if (files.length > MAX_PHOTOS) {
      const pending: PendingFile[] = [];
      for (const f of files) {
        pending.push({ file: f, date: await getPhotoDate(f) });
      }
      pending.sort((a, b) => a.date - b.date);
      setPendingFiles(pending);
      setSelectionCount(Math.min(pending.length, MAX_PHOTOS));
      setPendingInstruction(userInstruction);
      setPendingUseCache(useCache);
      return;
    }

    setPendingInstruction(userInstruction);
    setPendingUseCache(useCache);
    await startAnalysisPipeline(files, userInstruction, useCache);
  };

  const confirmLimitSelection = () => {
    if (!pendingFiles) return;
    const startIndex = selectionStart - 1;
    const selected = pendingFiles.slice(startIndex, startIndex + selectionCount).map(p => p.file);
    setPendingFiles(null);
    startAnalysisPipeline(selected, pendingInstruction, pendingUseCache);
  };

  const startAnalysisPipeline = async (files: File[], instruction: string, useCache: boolean) => {
    setIsProcessing(true);
    setShouldAbortAnalysis(false); // Reset abort flag
    setErrorMsg(null);
    setSuccessMsg(null);
    clearLogs();

    // Store initial instruction as active
    setInitialInstruction(instruction);
    setActiveInstruction(instruction);
    addLog(`[INSTRUCTION] Initial: "${instruction.substring(0, 50)}${instruction.length > 50 ? '...' : ''}"`, 'info');

    try {
      // 1. Prepare Records & Check Cache
      setCurrentStep(lang === 'ja' ? "逕ｻ蜒上ｒ貅門ｙ荳ｭ..." : "Preparing images...");

      const newRecords: PhotoRecord[] = [];
      let cachedCount = 0;

      for (const file of files) {
        const date = await getPhotoDate(file);
        const tempRecord: PhotoRecord = {
          fileName: file.name,
          base64: '',
          mimeType: file.type,
          fileSize: file.size,
          lastModified: file.lastModified,
          originalFile: file,
          status: 'pending',
          date: date,
          fromCache: false
        };

        let cachedAnalysis: AIAnalysisResult | null = null;
        if (useCache) {
          cachedAnalysis = await getCachedAnalysis(file);
        }

        if (cachedAnalysis) {
          const { base64, mimeType } = await processImageForAI(file);
          // 繧ｭ繝｣繝・す繝･縺輔ｌ縺溷・譫千ｵ先棡縺ｫ貂ｬ轤ｹ蜷阪ｒ霑ｽ蜉
          const locationName = extractLocationName(instruction);
          newRecords.push({
            ...tempRecord,
            base64,
            mimeType,
            analysis: {
              ...cachedAnalysis,
              station: locationName  // 繝励Ο繝ｳ繝励ヨ縺九ｉ謚ｽ蜃ｺ縺励◆貂ｬ轤ｹ蜷阪ｒ霑ｽ蜉
            },
            status: 'done',
            fromCache: true
          });
          cachedCount++;
        } else {
          const { base64, mimeType } = await processImageForAI(file);
          newRecords.push({
            ...tempRecord,
            base64,
            mimeType,
            status: 'pending',
            fromCache: false
          });
        }
      }

      if (cachedCount > 0) {
        addLog(txt.cacheHit(cachedCount), 'success');
      }

      // Initial Sort (Logical - using cached sceneIds if available)
      const initialSorted = sortPhotosLogical(newRecords);
      setPhotos(initialSorted);
      setStats({ total: initialSorted.length, processed: cachedCount, success: cachedCount, failed: 0, cached: cachedCount });
      setShowPreview(true);

      // 2. Smart Flow: 蜀咏悄繧ｿ繧､繝励ｒ閾ｪ蜍募愛螳壹＠縺ｦ譛驕ｩ縺ｪ蜃ｦ逅・ｒ驕ｸ謚・      const pendingPhotos = initialSorted.filter(p => p.status === 'pending');

      if (pendingPhotos.length > 0) {
        addLog(`${pendingPhotos.length}譫壹・譁ｰ縺励＞蜀咏悄繧貞・逅・＠縺ｾ縺兪, 'info');

        // 繧ｹ繝槭・繝医ヵ繝ｭ繝ｼ縺ｧ蜃ｦ逅・        const result = await processPhotosWithSmartFlow(
          pendingPhotos,
          apiKey,
          instruction,
          addLog
        );

        if (result.type === 'paired') {
          // 譎ｯ隕ｳ蜀咏悄繝｢繝ｼ繝会ｼ壹・繧｢繝ｪ繝ｳ繧ｰ螳御ｺ・          addLog('譎ｯ隕ｳ蜀咏悄繝｢繝ｼ繝峨〒蜃ｦ逅・＠縺ｾ縺励◆', 'success');

          // 繝励Ο繝ｳ繝励ヨ縺九ｉ貂ｬ轤ｹ蜷阪ｒ謚ｽ蜃ｺ・亥・騾夐未謨ｰ繧剃ｽｿ逕ｨ・・          const locationName = extractLocationName(instruction);

          // 繝壹い繧貞ｱ暮幕縺励※蜀咏悄繝ｪ繧ｹ繝医ｒ譖ｴ譁ｰ
          const updatedPhotos: PhotoRecord[] = [];
          result.pairs?.forEach(pair => {
            // analysis 縺悟ｭ伜惠縺励↑縺・ｴ蜷医・遨ｺ縺ｮ繧ｪ繝悶ず繧ｧ繧ｯ繝医ｒ蛻晄悄蛹・            const beforeAnalysis = pair.before.analysis || {
              fileName: pair.before.fileName,
              workType: '',
              variety: '',
              detail: '',
              station: '',
              remarks: '',
              description: '',
              hasBoard: false,
              detectedText: ''
            };

            const afterAnalysis = pair.after.analysis || {
              fileName: pair.after.fileName,
              workType: '',
              variety: '',
              detail: '',
              station: '',
              remarks: '',
              description: '',
              hasBoard: false,
              detectedText: ''
            };

            // before縺ｨafter縺ｫsceneId縺ｨphase繧剃ｻ倅ｸ弱∵ｸｬ轤ｹ蜷阪→蛯呵・ｒ霑ｽ蜉
            const beforePhoto = {
              ...pair.before,
              analysis: {
                ...beforeAnalysis,
                sceneId: pair.sceneId,
                phase: 'before' as const,
                station: locationName, // 貂ｬ轤ｹ蜷阪ｒ霑ｽ蜉
                remarks: '逹謇句燕' // 蛯呵・↓逹謇句燕繧定ｨ倩ｼ・              },
              status: 'done' as const
            };
            const afterPhoto = {
              ...pair.after,
              analysis: {
                ...afterAnalysis,
                sceneId: pair.sceneId,
                phase: 'after' as const,
                station: locationName, // 貂ｬ轤ｹ蜷阪ｒ霑ｽ蜉
                remarks: '遶｣蟾･' // 蛯呵・↓遶｣蟾･繧定ｨ倩ｼ・              },
              status: 'done' as const
            };
            updatedPhotos.push(beforePhoto, afterPhoto);
          });

          setPhotos(prev => {
            const unchanged = prev.filter(p => p.status !== 'pending');
            return [...unchanged, ...updatedPhotos];
          });

          setInitialLayout(2); // 2-up繝ｬ繧､繧｢繧ｦ繝医↓閾ｪ蜍募・繧頑崛縺・
        } else {
          // 鮟呈攸縺ゅｊ繝｢繝ｼ繝会ｼ壼ｾ捺擂縺ｮ隧ｳ邏ｰ隗｣譫・          const batchSize = DEFAULT_BATCH_SIZE;
          for (let i = 0; i < pendingPhotos.length; i += batchSize) {
            const batch = pendingPhotos.slice(i, i + batchSize);
            setCurrentStep(`${txt.analyzing} (${i + 1}/${pendingPhotos.length})`);

            try {
              const results = await analyzePhotoBatch(
                batch,
                instruction,
                batchSize,
                appMode,
                apiKey,
                addLog,
                logIndividualResult,
                () => shouldAbortAnalysis
              );

              const updatedBatch = batch.map(record => {
                const res = results.find(r => r.fileName === record.fileName);
                if (res) {
                  cacheAnalysis(record, res).catch(console.error);
                  return { ...record, analysis: res, status: 'done' as const };
                }
                return { ...record, status: 'error' as const };
              });

              setPhotos(prev => prev.map(p => {
                const updated = updatedBatch.find(u => u.fileName === p.fileName);
                return updated || p;
              }));
            } catch (e: any) {
              console.error("Batch failed", e);
              addLog(`Batch analysis failed: ${e.message}`, 'error');
              setPhotos(prev => prev.map(p => {
                if (batch.find(b => b.fileName === p.fileName)) {
                  return { ...p, status: 'error' as const };
                }
                return p;
              }));
            }
          }
        }
      }

      // 3. Normalize Consistency (Only for NEW records)
      const newlyAnalyzed = photos.filter(p => !p.fromCache && p.status === 'done');
      if (newlyAnalyzed.length > 0) {
        setCurrentStep("Finalizing data consistency...");
        const normalizedNew = await normalizeDataConsistency(newlyAnalyzed, apiKey, addLog);

        setPhotos(prev => prev.map(p => {
          const norm = normalizedNew.find(n => n.fileName === p.fileName);
          if (norm && norm.analysis) {
            cacheAnalysis(norm, norm.analysis).catch(console.error);
            return norm;
          }
          return p;
        }));
      }

      // 4. Final Sort (Logical)
      // This will use cached sceneIds from previous sessions if they exist!
      setPhotos(prev => sortPhotosLogical(prev));

      setSuccessMsg(txt.done);

    } catch (err: any) {
      console.error(err);
      setErrorMsg(err.message || "Unknown error occurred");
      addLog("Pipeline fatal error", 'error', err);
    } finally {
      setIsProcessing(false);
      setCurrentStep("");
    }
  };

// Console CLI instruction handler
  const handleConsoleInstruction = (instruction: string) => {
    addLog("User instruction: " + instruction, "info");
    handleRefineAnalysis(instruction, 6);
  };
  const handleRefineAnalysis = async (instruction: string, batchSize: number) => {
    setShowRefineModal(false);
    setIsProcessing(true);
    setCurrentStep("Refining analysis...");
    clearLogs();

    // Update active instruction (refinement takes priority)
    if (instruction && instruction !== "__REANALYZE__") {
      setActiveInstruction(instruction);
      addLog(`[INSTRUCTION] Refinement: "${instruction.substring(0, 50)}${instruction.length > 50 ? '...' : ''}"`, 'info');
      addLog(`[INSTRUCTION] Priority: Refinement > Initial`, 'info');
    }

    try {
      let targetFileNames: string[] = [];

      // Check if refinement instruction contains a station specification
      const refinementStation = extractLocationName(instruction);
      const hasStationOverride = instruction && instruction !== "__REANALYZE__" && 
        (instruction.includes('貂ｬ轤ｹ') || instruction.includes('莉倩ｿ・) || instruction.includes('蝨ｰ轤ｹ'));

      if (hasStationOverride) {
        addLog(`[INSTRUCTION] Station override detected: "${refinementStation}"`, 'info');
      }

      if (instruction === "__REANALYZE__") {
        targetFileNames = photos.map(p => p.fileName);
        addLog("Re-analyzing ALL photos.", 'info');
      } else {
        setCurrentStep(txt.identifyingTargets);
        targetFileNames = await identifyTargetPhotos(photos, instruction, apiKey, addLog);
      }

      if (targetFileNames.length === 0) {
        setSuccessMsg("No matching photos found to update.");
        setIsProcessing(false);
        return;
      }

      const targets = photos.filter(p => targetFileNames.includes(p.fileName));
      let updatedTargets: PhotoRecord[] = [];

      for (let i = 0; i < targets.length; i += batchSize) {
        const batch = targets.slice(i, i + batchSize);
        setCurrentStep(`${txt.analyzing} (${i + 1}/${targets.length})`);

        try {
          const results = await analyzePhotoBatch(
            batch,
            instruction === "__REANALYZE__" ? "" : instruction,
            batchSize,
            appMode,
            apiKey,
            addLog,
            logIndividualResult,
            () => shouldAbortAnalysis
          );

          const processedBatch = batch.map(record => {
            const res = results.find(r => r.fileName === record.fileName);
            if (res) {
              let finalAnalysis = res;

              // Preserve Edited Fields
              if (record.analysis?.editedFields) {
                finalAnalysis = { ...res, editedFields: record.analysis.editedFields };
                record.analysis.editedFields.forEach(field => {
                  // @ts-ignore
                  finalAnalysis[field] = record.analysis![field];
                });
              }
              // Preserve SceneID if it exists (so we don't break pairing)
              if (record.analysis?.sceneId) {
                finalAnalysis.sceneId = record.analysis.sceneId;
                finalAnalysis.phase = record.analysis.phase;
                finalAnalysis.visualAnchors = record.analysis.visualAnchors; // Preserve anchors
              }

              cacheAnalysis(record, finalAnalysis).catch(console.error);
              return { ...record, analysis: finalAnalysis, status: 'done' as const };
            }
            return record;
          });
          updatedTargets = [...updatedTargets, ...processedBatch];

        } catch (e: any) {
          addLog(`Refine batch failed: ${e.message}`, 'error');
          updatedTargets = [...updatedTargets, ...batch];
        }
      }

      // If refinement had station override, apply to ALL photos (including non-targets)
      let otherPhotos = photos.filter(p => !targetFileNames.includes(p.fileName));
      
      if (hasStationOverride && refinementStation) {
        addLog(`[INSTRUCTION] Applying station "${refinementStation}" to all ${otherPhotos.length + updatedTargets.length} photos`, 'info');
        
        // Update other photos with new station
        otherPhotos = otherPhotos.map(p => {
          if (p.analysis) {
            return {
              ...p,
              analysis: {
                ...p.analysis,
                station: refinementStation
              }
            };
          }
          return p;
        });

        // Also ensure updated targets have the station
        updatedTargets = updatedTargets.map(p => {
          if (p.analysis) {
            return {
              ...p,
              analysis: {
                ...p.analysis,
                station: refinementStation
              }
            };
          }
          return p;
        });
      }

      const merged = [...otherPhotos, ...updatedTargets];
      const sorted = sortPhotosLogical(merged);

      setPhotos(sorted);
      setSuccessMsg(`Updated ${updatedTargets.length} photos.${hasStationOverride ? ` Station set to "${refinementStation}"` : ''}`);

    } catch (e: any) {
      console.error(e);
      setErrorMsg("Refine failed: " + e.message);
      setShouldAbortAnalysis(false); // Reset abort flag
    }
  };

  const handleSingleReanalysis = async (fileName: string) => {
    setIsProcessing(true);
    setCurrentStep(`Re-analyzing ${fileName}...`);
    clearLogs();
    setShouldAbortAnalysis(false);

    try {
      const target = photos.find(p => p.fileName === fileName);
      if (!target) return;

      const results = await analyzePhotoBatch(
        [target],
        "", // Empty instruction for default analysis
        1, // batchSize
        appMode,
        apiKey,
        addLog,
        logIndividualResult,
        () => shouldAbortAnalysis,
        (reasoningText) => {
          setCurrentStep(`Thinking: ${reasoningText.slice(0, 100)}${reasoningText.length > 100 ? '...' : ''}`);
        }
      );

      if (results.length > 0) {
        const res = results[0];
        let finalAnalysis = res;

        // Preserve Edited Fields
        if (target.analysis?.editedFields) {
          finalAnalysis = { ...res, editedFields: target.analysis.editedFields };
          target.analysis.editedFields.forEach(field => {
            // @ts-ignore
            finalAnalysis[field] = target.analysis[field];
          });
        }

        setPhotos(prev => prev.map(p =>
          p.fileName === fileName
            ? { ...p, analysis: finalAnalysis, status: 'done' }
            : p
        ));

        if (res.reasoning) {
          addLog(`Reasoning for ${fileName}: ${res.reasoning}`, 'info');
          console.log(`[AI Reasoning] ${fileName}:`, res.reasoning);
        }

        addLog(`Re-analysis complete for ${fileName}`, 'success');
        setSuccessMsg("Photo re-analyzed successfully.");
      }
    } catch (err: any) {
      console.error(err);
      setErrorMsg(err.message || "Re-analysis failed");
      addLog("Re-analysis error", 'error', err);
    } finally {
      setIsProcessing(false);
      setCurrentStep("");
    }
  };

  // --- Render ---

  if (!showPreview) {
    return (
      <UploadView
        lang={lang}
        isProcessing={isProcessing}
        photos={photos}
        appMode={appMode}
        apiKey={apiKey}
        setApiKey={setApiKey}
        setAppMode={setAppMode}
        onStartProcessing={handleStartProcessing}
        onResume={handleResume}
        onCloseProject={handleCloseProject}
        onExportJson={() => {
          const json = exportDataToJson(photos);
          const blob = new Blob([json], { type: 'application/json' });
          saveAs(blob, `photo_archive_backup_${new Date().toISOString().slice(0, 10)}.json`);
        }}
        onImportJson={(e) => {
          if (!e.target.files || e.target.files.length === 0) return;
          const file = e.target.files[0];
          const reader = new FileReader();
          reader.onload = async (ev) => {
            try {
              const imported = importDataFromJson(ev.target?.result as string);
              setPhotos(imported);
              const success = imported.filter(p => p.status === 'done').length;
              setStats({ total: imported.length, processed: success, success, failed: 0, cached: 0 });
              saveProjectData(imported);
              setShowPreview(true);
            } catch (err) {
              alert("Invalid JSON file");
            }
          };
          reader.readAsText(file);
        }}
        onClearCache={handleClearCache}
        onShowPreview={() => setShowPreview(true)}
      />
    );
  }

  return (
    <>
      <PreviewView
        lang={lang}
        photos={photos}
        stats={stats}
        appMode={appMode}
        isProcessing={isProcessing}
        currentStep={currentStep}
        errorMsg={errorMsg}
        successMsg={successMsg}
        logs={logs}
        initialLayout={initialLayout}
        fsCacheEnabled={fsCacheEnabled}
        fsCacheStats={fsCacheStats}
        onClearLogs={clearLogs}
        onGoHome={() => { setShouldAbortAnalysis(true); setShowPreview(false); }}
        onCloseProject={handleCloseProject}
        onRefine={() => setShowRefineModal(true)}
        onExportExcel={generateExcel}
        onUpdatePhoto={handleUpdatePhoto}
        onDeletePhoto={handleDeletePhoto}
        onAutoPair={handleAutoPair}
        onSortByDate={handleSmartSort}
        onSendInstruction={handleConsoleInstruction}
        onSelectCacheFolder={handleSelectCacheFolder}
        onClearFileSystemCache={handleClearFileSystemCache}
        onReanalyzePhoto={handleSingleReanalysis}
      />

      {pendingFiles && (
        <LimitModal
          totalFiles={pendingFiles.length}
          maxPhotos={MAX_PHOTOS}
          selectionStart={selectionStart}
          selectionCount={selectionCount}
          lang={lang}
          onStartChange={setSelectionStart}
          onCountChange={(val) => setSelectionCount(Math.min(val, MAX_PHOTOS))}
          onCancel={() => setPendingFiles(null)}
          onConfirm={confirmLimitSelection}
        />
      )}

      {showRefineModal && (
        <RefineModal
          lang={lang}
          photos={photos}
          onClose={() => setShowRefineModal(false)}
          onRunAnalysis={handleRefineAnalysis}
        />
      )}
    </>
  );
}


//===============================================================================
// FILE: index.tsx
//===============================================================================
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';

const rootElement = document.getElementById('root');
if (!rootElement) {
  throw new Error("Could not find root element to mount to");
}

const root = ReactDOM.createRoot(rootElement);
root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);

